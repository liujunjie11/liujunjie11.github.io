<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LXiHa`Notes</title>
  
  <subtitle>The House Belong to Love and Freedom.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://liujunjie11.github.io/"/>
  <updated>2019-01-28T13:58:18.145Z</updated>
  <id>https://liujunjie11.github.io/</id>
  
  <author>
    <name>刘俊</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>润物细无声</title>
    <link href="https://liujunjie11.github.io/2019/01/28/%E6%B6%A6%E7%89%A9%E7%BB%86%E6%97%A0%E5%A3%B0/"/>
    <id>https://liujunjie11.github.io/2019/01/28/润物细无声/</id>
    <published>2019-01-28T13:13:04.000Z</published>
    <updated>2019-01-28T13:58:18.145Z</updated>
    
    <content type="html"><![CDATA[<p>这些天我自从回来了这边之后，趁着一些闲工夫看了一些自认为比较优秀的电视剧，其中感触极大的是《父母爱情》。这部剧真的是一部高质量的、优秀的电视剧，在看的过程中太过于饥渴难耐，满怀兴奋的熬夜看完了，看完之后更是犹意未尽，总是一味的再而再三的重复回味那些喜欢的片段，如今在写下的此时此刻也是不时的浮现那些片段，真的太喜欢这部剧了。</p><a id="more"></a><p>通过《父母爱情》这部剧的“洗礼”之后，重新认识了很多的东西，之前的我入戏太深，久久不能摆脱戏里的故事与我喜欢的主人公的影子，他们确实的让我不能开怀去接受这部剧已尽的现实…父母年代的平凡爱情、平淡生活的细无声、悲喜交加的小波澜…我太爱了，太爱这部剧了～</p><p>…</p><p>太久未曾在此更新我的感悟了，这与我变懒了不无关系。但是我从来没有像在上学期之前的一段时间里那么自在欢快了，之前的我为了毕业之后加紧自己的步伐，逼着自己做该做的工作与事情，其实仔细想想收获了许多，但是未曾像现在那么快乐、自在。我承认，刚刚过去的那个学期我变得有些松懈了，没有之前对于自己那么的严格要求了，我是有点松懈过度了，我确实也浪费了不少的时间。学时醒悟过来方恨时少啊，但是确实是我自找的。</p><p>我的规划在我的松懈之下变得不堪一击，零零散散的，现在我自己都有一些惊慌失措。我急须改变了。</p><p>…</p><p>现在的我会学着更多的去看待现有的一切了，我开始慢慢的更多的去阅读这个社会，阅读身边的生活及其中的人与事。我好久没有过感悟了，我变得安逸了，变得拖延了，变得好像没有梦想了…但是，我确实也对于一些事情较之从前看得开了，这些看得开的所有无意中好像变成我安逸度日的理由了。我明显的感觉到我一只脚陷入了生活的泥潭。</p><p>看街上小店小摊，路过的人山人海，生活真的像是一部人间剧，只不过少了一些精准紧致的配乐显得那么动人心弦，生活像是一部无声的人间剧。每个人自己的人生都是不一样的剧本。无论所谓的平凡与所谓的不平凡、所谓的伟大都好似显得微不足道，无声无息，生生不息，这就是生活的真谛。润物细无声，就是所有的平凡，也是所有的不平凡。</p><p>人生多数的“艰”与“难”在于那“良心”。它是一个人安生偷生的最好依据，无论生活有多难有多么不合意。亦正所谓人间正道是沧桑呐，也不无道理。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这些天我自从回来了这边之后，趁着一些闲工夫看了一些自认为比较优秀的电视剧，其中感触极大的是《父母爱情》。这部剧真的是一部高质量的、优秀的电视剧，在看的过程中太过于饥渴难耐，满怀兴奋的熬夜看完了，看完之后更是犹意未尽，总是一味的再而再三的重复回味那些喜欢的片段，如今在写下的此时此刻也是不时的浮现那些片段，真的太喜欢这部剧了。&lt;/p&gt;
    
    </summary>
    
      <category term="日记" scheme="https://liujunjie11.github.io/categories/%E6%97%A5%E8%AE%B0/"/>
    
      <category term="感悟" scheme="https://liujunjie11.github.io/categories/%E6%84%9F%E6%82%9F/"/>
    
    
      <category term="日记" scheme="https://liujunjie11.github.io/tags/%E6%97%A5%E8%AE%B0/"/>
    
      <category term="父母爱情" scheme="https://liujunjie11.github.io/tags/%E7%88%B6%E6%AF%8D%E7%88%B1%E6%83%85/"/>
    
  </entry>
  
  <entry>
    <title>所谓中国的精英？</title>
    <link href="https://liujunjie11.github.io/2018/11/28/%E6%89%80%E8%B0%93%E4%B8%AD%E5%9B%BD%E7%9A%84%E7%B2%BE%E8%8B%B1%EF%BC%9F/"/>
    <id>https://liujunjie11.github.io/2018/11/28/所谓中国的精英？/</id>
    <published>2018-11-28T07:56:58.000Z</published>
    <updated>2019-01-02T06:47:25.156Z</updated>
    
    <content type="html"><![CDATA[<p>我今日在一个技术群里看到了一些所谓“高学历”层次的人讨论各种社会问题并且津津乐道着。在这里我看到了一部分人的各种“娱乐精神”，活像是一个娱乐至死的时代的缩影，还有对于那些盲目迷信的一群人，在他们身上我看不到一个人的存在，像是一群只会迎合的瘪嘴小丑。</p><a id="more"></a><p>这是所谓的支撑着中国未来脊梁的精英们吗？我有些想讽刺性的嘲笑和想有意的去嘲弄一番，但是我忍住了，我和他们有不一样的想法，所以我控制住了自己，这样的人我见的太多了，我没有勇气去跟那些人去讨论一下自己内心的想法，因为我始终相信着明者自明，不明白的人或者是曾经明白过的而现在早已改变了自己的人是不会理解我想要说的意思的。人总是这样的，包括我自己有时也是这样的，大多数时候对于大多数人们来说这是难以察觉的，有的人可能一辈子也不会察觉到。其实到现在想了想，好像也没有什么好说的，人们因为经历的不同都会有自己的想法，但是，对于那些没有自我灵魂的人，我却是有些想要多此一举的。这是所谓的中国式精英吗？</p><p>如今的大多数人们会有一种拥有更高学历的人就是人上人的感觉，这就是一些无法看清问题本质的典型人群。这样的盲目迷信的人群在这个地方应有尽有。这是所谓的中国式精英吗？他们把社会上的恶习当做自己成长的经验，把社会上的各种悲剧当做津津乐道的剧本，进而的再把这些东西当做人生的真理去传授给予涉世未深的学弟学妹们，要求他们吸收并且像自己一样去乐意接受。最后走到了人生的一个段点，他们以为自己获得了升华，并且成为了真正的成熟的”大人“了。我感觉可笑的同时也感觉到可悲。为钱而读书，为钱舍命去奔波，为钱出卖自己的灵魂，这些对于如今的我是有些接受不了的。</p><p>人浮于事(世)。社会真的是最好的大学吗？还是一个吞没人性，违背人理道德的垃圾池？这是一个浮躁的大时代。而我现在在的地方还有那一群人被称为“中国精英”！我为自己和这个国家而不甘心，我没有能力去改变这个浮躁的现实，而这个国家却是在这一群所谓的精英手里，他们享受着这个国家最好的待遇与资源，但是本身却是一样的糜烂。</p><p>于我而言，中国所谓的“精英”不应该是这样的。至少的，他们应该有着自己的灵魂。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我今日在一个技术群里看到了一些所谓“高学历”层次的人讨论各种社会问题并且津津乐道着。在这里我看到了一部分人的各种“娱乐精神”，活像是一个娱乐至死的时代的缩影，还有对于那些盲目迷信的一群人，在他们身上我看不到一个人的存在，像是一群只会迎合的瘪嘴小丑。&lt;/p&gt;
    
    </summary>
    
      <category term="日记" scheme="https://liujunjie11.github.io/categories/%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="日记" scheme="https://liujunjie11.github.io/tags/%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>各种英语词性(基础语法)的学习以及入门学习日语的记录</title>
    <link href="https://liujunjie11.github.io/2018/11/24/%E5%90%84%E7%A7%8D%E8%8B%B1%E8%AF%AD%E8%AF%8D%E6%80%A7(%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95)%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%BB%A5%E5%8F%8A%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E8%AF%AD%E7%9A%84%E8%AE%B0%E5%BD%95/"/>
    <id>https://liujunjie11.github.io/2018/11/24/各种英语词性(基础语法)的学习以及入门学习日语的记录/</id>
    <published>2018-11-24T05:27:11.000Z</published>
    <updated>2019-01-02T06:47:38.834Z</updated>
    
    <content type="html"><![CDATA[<p>最近在一股劲的学习日语和英语，打算明年搞定日语N1考试以及托福去日本留学，读日本国立大学的研究生。</p><p>在此记录了我学习到的一些资源以及感想，因为目前是刚刚学习到不久，所以会根据需求不定时更新。</p><a id="more"></a><h1 id="英语词性的认识与学习"><a href="#英语词性的认识与学习" class="headerlink" title="英语词性的认识与学习"></a>英语词性的认识与学习</h1><p>因为在初一时没有好好的学习各种词性的意识，所以导致我一直以来的在这方面的欠缺，我这会打算好好学习一些基础知识了，我在YouTube上找到了一些特别适合我的资源，首先是英语的语法入门教学视频，里面有特别好的入门教学，通俗易懂：</p><iframe width="560" height="315" src="https://www.youtube.com/embed/EmNNRMXf1oc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><blockquote><p>这是一个系列教学，学完之后会学到很多以前没有认真学的基础知识，也就是词性的认识以及一些英语的基础入门学习。</p></blockquote><p><strong>一定要好好的学习各种词性是什么，该怎么用(老老实实认真做笔记)，因为在我学习日语的时候也会用到这个词性的理解，进而才能进阶学习。很重要！非常重要！因为如果理解了各种词性是什么，那么在学习日语(不仅仅是日语，包括各种语言)时就会学习的很快。</strong></p><p>另外学习英语语法本身就是很重要的，应当找几本经典的书籍看看研究一下。</p><h1 id="日语入门学习"><a href="#日语入门学习" class="headerlink" title="日语入门学习"></a>日语入门学习</h1><p>这个我是打算直接在明年考试N1的，所以我买了一些N1的备考书籍(<code>新完全掌握N1系列</code>)以及所谓的<code>蓝/红宝书</code>系列作为备考书籍选项，另外我也买了近几年来的N1真题考试试卷。为了激活那个<strong>中日标准日本语</strong>电子书我也买了全套的相关的书籍(为了激活码…)。<strong>以上这些都可以到淘宝买到。</strong></p><p>另外推荐在YouTube上的新东方日语教学，这个系列特别的通俗易懂，好好学就没什么问题：</p><ul><li>链接：<a href="https://www.youtube.com/watch?v=6OYluEuz1tU&amp;list=PL1vjT6bepDu03GYEcuy0z2_Bou-9bAbGb&amp;index=13" target="_blank" rel="external">新东方日语</a></li></ul><blockquote><p>这个系列也是非常的不错的，这个老师也是很专业滴，好好学，好好的入门没问题。</p></blockquote><p>另外还有一些推荐的YouTube日语入门教学视频：</p><ul><li><p><a href="https://www.youtube.com/watch?v=5voKwhASN7k&amp;index=8&amp;list=PLuNucubP18snvU3Zz8FXF-kACs5EPK4XU" target="_blank" rel="external">從零開始學日文系列～</a></p></li><li><p><a href="https://www.youtube.com/watch?v=MWDdsZ3Vemc&amp;list=PLycXmlzOfI4I-lFd1wH8EHEXFXpd56aro" target="_blank" rel="external">N1日语语法蓝宝书</a></p></li></ul><blockquote><p>也是非常不错的～</p></blockquote><h2 id="一些小的建议"><a href="#一些小的建议" class="headerlink" title="一些小的建议"></a>一些小的建议</h2><ol><li><p>关于五十音图可以先简要的过一遍就好，到时不懂再查，慢慢的就能都记住了，这样效率还是不错的。</p></li><li><p>下载一些APP配合学习，比如那个<code>中日标准日本语</code>的APP就不错。</p></li></ol><p>…</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在一股劲的学习日语和英语，打算明年搞定日语N1考试以及托福去日本留学，读日本国立大学的研究生。&lt;/p&gt;
&lt;p&gt;在此记录了我学习到的一些资源以及感想，因为目前是刚刚学习到不久，所以会根据需求不定时更新。&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://liujunjie11.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="资源分享" scheme="https://liujunjie11.github.io/categories/%E8%B5%84%E6%BA%90%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="学习笔记" scheme="https://liujunjie11.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="英语" scheme="https://liujunjie11.github.io/tags/%E8%8B%B1%E8%AF%AD/"/>
    
      <category term="日语" scheme="https://liujunjie11.github.io/tags/%E6%97%A5%E8%AF%AD/"/>
    
  </entry>
  
  <entry>
    <title>考研or工作，抉择与想法</title>
    <link href="https://liujunjie11.github.io/2018/11/19/%E8%80%83%E7%A0%94or%E5%B7%A5%E4%BD%9C%EF%BC%8C%E6%8A%89%E6%8B%A9%E4%B8%8E%E6%83%B3%E6%B3%95/"/>
    <id>https://liujunjie11.github.io/2018/11/19/考研or工作，抉择与想法/</id>
    <published>2018-11-19T05:10:14.000Z</published>
    <updated>2019-01-02T06:47:53.087Z</updated>
    
    <content type="html"><![CDATA[<p>不知不觉，大三上学期也过一大半了，我这几天一直在<code>考研</code>or<code>工作</code>之间进行一场自我的挣扎。</p><a id="more"></a><p>有时想的太多真的会成为人们进步的碍脚石。我为何要选择考研？必须得问自己的真心，必须得深入了解自己更加倾向于哪一方面！如果不了解自己需要什么，什么都不会，不如直接去考研待在学校寻找自我吧，还可以顺便学点知识应付未来的生计什么的。我是个自我了解很深的人，我选择工作，因为我更加倾向于喜欢毕业之后去工作。</p><p>如果我考研为了什么？我想过去日本留学，冷静下来想了一下发现自己只是想去体验日本的生活环境，另外成本太高，而且我也不愿去为了这个单独的目标去花更多的时间了，所以我放弃留学的打算。光光是成本不说，我想过去考研国内的大学，我冷静下来想了想，不过是自己的一些能力因素达不到理想中的那个样子罢了，而我现在还有时间！！学历真的重要吗？我通过参考了很多前辈的话，我冷静下来想了想，发现还是自身的能力不足的问题，焦虑的大多数时候只是能力不足的表现罢了，这时候就需要读书看书学习了。</p><p>再者，我其实不是喜欢考研的，只不过是想要个学历学位证书以及多一些的项目经验罢了，我的这个目的经过我的考虑之后，我有点接受不了，因为我为了这种东西而去花费一年时间去准备的话，或许不适合我的性格与选择。</p><p>学习是终身的，不是一时的。</p><p>一些事情理性考虑好之后，干，就完了！！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;不知不觉，大三上学期也过一大半了，我这几天一直在&lt;code&gt;考研&lt;/code&gt;or&lt;code&gt;工作&lt;/code&gt;之间进行一场自我的挣扎。&lt;/p&gt;
    
    </summary>
    
      <category term="日记" scheme="https://liujunjie11.github.io/categories/%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="日记" scheme="https://liujunjie11.github.io/tags/%E6%97%A5%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>MySQL语句疑惑记录</title>
    <link href="https://liujunjie11.github.io/2018/11/15/MySQL%E8%AF%AD%E5%8F%A5%E7%96%91%E6%83%91%E8%AE%B0%E5%BD%95/"/>
    <id>https://liujunjie11.github.io/2018/11/15/MySQL语句疑惑记录/</id>
    <published>2018-11-15T01:53:00.000Z</published>
    <updated>2019-01-02T06:48:06.106Z</updated>
    
    <content type="html"><![CDATA[<p>主要是记录一些比较有疑惑的语句，方便以后的查找以及回忆。</p><a id="more"></a><h1 id="LIMIT子句"><a href="#LIMIT子句" class="headerlink" title="LIMIT子句"></a>LIMIT子句</h1><blockquote><p> <strong>主要参考：<a href="https://www.yiibai.com/mysql/limit.html" target="_blank" rel="external">https://www.yiibai.com/mysql/limit.html</a></strong></p></blockquote><p>LIMIT子句语法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">SELECT </div><div class="line">    column1,column2,...</div><div class="line">FROM</div><div class="line">    table</div><div class="line">LIMIT offset , count;</div></pre></td></tr></table></figure><p>SQL我们来查看LIMIT子句参数：</p><p><code>offset</code>参数:指定要返回的第一行的偏移量。第一行的偏移量为0，而不是1。</p><p><code>count</code>:指定要返回的最大行数。</p><p>使用带有一个参数的LIMIT子句时，此参数将用于确定从结果集的开头返回的最大行数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">SELECT </div><div class="line">    column1,column2,...</div><div class="line">FROM</div><div class="line">    table</div><div class="line">LIMIT count;</div></pre></td></tr></table></figure><p>SQL上面的查询等同：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">SELECT </div><div class="line">    column1,column2,...</div><div class="line">FROM</div><div class="line">    table</div><div class="line">LIMIT 0 , count;</div></pre></td></tr></table></figure><h2 id="实例说明"><a href="#实例说明" class="headerlink" title="实例说明"></a>实例说明</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">mysql&gt; SELECT productCode, productName, buyprice</div><div class="line">FROM products</div><div class="line">ORDER BY buyprice DESC;</div><div class="line"></div><div class="line">+-------------+--------------------------------------+----------+</div><div class="line">| productCode | productName                          | buyprice |</div><div class="line">+-------------+--------------------------------------+----------+</div><div class="line">| S10_4962    | 1962 LanciaA Delta 16V               | 103.42   |</div><div class="line">| S18_2238    | 1998 Chrysler Plymouth Prowler       | 101.51   |</div><div class="line">| S10_1949    | 1952 Alpine Renault 1300             | 98.58    |</div><div class="line">| S24_3856    | 1956 Porsche 356A Coupe              | 98.3     |</div><div class="line">| S12_1108    | 2001 Ferrari Enzo                    | 95.59    |</div><div class="line">| S12_1099    | 1968 Ford Mustang                    | 95.34    |</div><div class="line">... ....</div><div class="line">+-------------+--------------------------------------+----------+</div><div class="line">110 rows in set</div></pre></td></tr></table></figure><p>默认语句为输出最前面的几行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">mysql&gt; SELECT customernumber, customername, creditlimit</div><div class="line">FROM customers</div><div class="line">ORDER BY creditlimit DESC</div><div class="line">LIMIT 5;</div><div class="line"></div><div class="line">相当于：</div><div class="line">mysql&gt; SELECT customernumber, customername, creditlimit</div><div class="line">FROM customers</div><div class="line">ORDER BY creditlimit DESC</div><div class="line">LIMIT 0, 5; #从第一个偏移量的指定开始向下输出指定行数的所有内容。</div><div class="line"></div><div class="line"></div><div class="line">+----------------+------------------------------+-------------+</div><div class="line">| customernumber | customername                 | creditlimit |</div><div class="line">+----------------+------------------------------+-------------+</div><div class="line">|            141 | Euro+ Shopping Channel       | 227600      |</div><div class="line">|            124 | Mini Gifts Distributors Ltd. | 210500      |</div><div class="line">|            298 | Vida Sport, Ltd              | 141300      |</div><div class="line">|            151 | Muscle Machine Inc           | 138500      |</div><div class="line">|            187 | AV Stores, Co.               | 136800      |</div><div class="line">+----------------+------------------------------+-------------+</div><div class="line">5 rows in set</div></pre></td></tr></table></figure><p>简要深入理解偏移量的作用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">mysql&gt; SELECT productCode, productName, buyprice FROM  products</div><div class="line">ORDER BY buyprice DESC</div><div class="line">LIMIT 1, 1; #偏移量从0开始，所以要指定从1开始，然后取一行记录，以行数为1的指定仅输出一行对应的内容。</div><div class="line"></div><div class="line">+-------------+--------------------------------+----------+</div><div class="line">| productCode | productName                    | buyprice |</div><div class="line">+-------------+--------------------------------+----------+</div><div class="line">| S18_2238    | 1998 Chrysler Plymouth Prowler | 101.51   |</div><div class="line">+-------------+--------------------------------+----------+</div><div class="line">1 row in set</div><div class="line"></div><div class="line"></div><div class="line">#如下几个深入理解</div><div class="line">mysql&gt; SELECT productCode, productName, buyprice FROM  products</div><div class="line">ORDER BY buyprice DESC</div><div class="line">LIMIT 0, 1; #这时指定第一行(偏移量默认为第一行取0)</div><div class="line"></div><div class="line">+-------------+--------------------------------+----------+</div><div class="line">| productCode | productName                    | buyprice |</div><div class="line">+-------------+--------------------------------+----------+</div><div class="line">| S10_4962    | 1962 LanciaA Delta 16V | 103.42   |</div><div class="line">+-------------+--------------------------------+----------+</div><div class="line">1 row in set</div><div class="line"></div><div class="line"></div><div class="line">mysql&gt; SELECT productCode, productName, buyprice FROM  products</div><div class="line">ORDER BY buyprice DESC</div><div class="line">LIMIT 0, 2; #从已指定第一行偏移量开始输出以此为基础的指定行数的以下所有内容</div><div class="line"></div><div class="line">+-------------+--------------------------------------+----------+</div><div class="line">| productCode | productName                          | buyprice |</div><div class="line">+-------------+--------------------------------------+----------+</div><div class="line">| S10_4962    | 1962 LanciaA Delta 16V               | 103.42   |</div><div class="line">| S18_2238    | 1998 Chrysler Plymouth Prowler       | 101.51   |</div><div class="line">+----------------+------------------------------+-------------+</div><div class="line">2 rows in set</div></pre></td></tr></table></figure><blockquote><p>总结：<code>offset</code>就是相当于一个定位，<code>count</code>就是要返回指定的最大行数。</p></blockquote><h1 id="ORDER-BY-ASC-DESC"><a href="#ORDER-BY-ASC-DESC" class="headerlink" title="ORDER BY ASC/DESC"></a>ORDER BY ASC/DESC</h1><p><code>ASC</code>:[A~Z], [1~N]…</p><p><code>DESC</code>:[Z~A}, [N~1]…</p><blockquote><p>A，B，…Z。Z相当于最大的。</p></blockquote><h1 id="经度-Longitude-纬度-Latitude"><a href="#经度-Longitude-纬度-Latitude" class="headerlink" title="经度(Longitude) 纬度(Latitude)"></a>经度(Longitude) 纬度(Latitude)</h1><p><code>经度(Longitude)</code>：<code>东经</code>，<code>西经</code>。</p><blockquote><p>东经正数，西经为负数。越大越靠东。</p></blockquote><p><code>纬度(Latitude)</code>：<code>南纬</code>，<code>北纬</code>。</p><blockquote><p>北纬为正数，南纬为负数。越大越靠北。</p></blockquote><p>方便记忆：东经，东北正。</p><p><strong>参考：<a href="https://baike.baidu.com/item/%E7%BB%8F%E7%BA%AC%E5%BA%A6" target="_blank" rel="external">https://baike.baidu.com/item/%E7%BB%8F%E7%BA%AC%E5%BA%A6</a></strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;主要是记录一些比较有疑惑的语句，方便以后的查找以及回忆。&lt;/p&gt;
    
    </summary>
    
      <category term="MySQL" scheme="https://liujunjie11.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="https://liujunjie11.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>MySQL学习资源与实践学习</title>
    <link href="https://liujunjie11.github.io/2018/11/13/MySQL%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%E4%B8%8E%E5%AE%9E%E8%B7%B5%E5%AD%A6%E4%B9%A0/"/>
    <id>https://liujunjie11.github.io/2018/11/13/MySQL学习资源与实践学习/</id>
    <published>2018-11-13T13:12:31.000Z</published>
    <updated>2019-01-02T06:48:16.491Z</updated>
    
    <content type="html"><![CDATA[<p>最近心血来潮想写几个SQL玩玩，在此会分享学习的书籍资源以及YouTube教程使用语法的实践项目，以及会进行一系列的简单实践。这里通过在YouTube上的一个大佬的视频来进行在线的实践即可。</p><iframe width="560" height="315" src="https://www.youtube.com/embed/xYMhPZ_L3fI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><blockquote><p>就是这个视频。</p></blockquote><p>可主要参考书籍<a href="https://pan.baidu.com/s/15hIkCroy2w7RvBdVH8LRmA" target="_blank" rel="external">疯狂Java讲义(李刚)</a>来进行学习，当然还有参考其他的经典书籍以备用学习，这类书籍很多，就不在此一一说明了。</p><blockquote><p>《疯狂Java讲义》书籍的配套资源地址：<a href="https://github.com/DoingLee" target="_blank" rel="external">https://github.com/DoingLee</a></p></blockquote><a id="more"></a><h1 id="MySQL学习"><a href="#MySQL学习" class="headerlink" title="MySQL学习"></a>MySQL学习</h1><p>这一部分由于一些基础性的基本知识在上面和下面的书籍中已经是多如牛毛了，我就不重复说明了，需要的自行下载去了解吧。可结合书中直接开始语法的学习！实际上几个实用性强的语句就那么几个。</p><h2 id="书籍资源分享"><a href="#书籍资源分享" class="headerlink" title="书籍资源分享"></a>书籍资源分享</h2><ul><li><p><a href="https://pan.baidu.com/s/1rZwbEXEV_GlGsN7UVZ5Z6Q" target="_blank" rel="external">MySQL必知必会.pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1pA9V9weH33j7ZiV6fFNU1Q" target="_blank" rel="external">SQL语法查询(W3school).pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1cglHK9k4VY1SSJsg_C2mWA" target="_blank" rel="external">MySQL完全教程.pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/14W7WJBoVnybd_r8pXQ6J4Q" target="_blank" rel="external">MySQL经典教程.pdf</a></p></li><li><p><a href="http://www.manongjc.com/article/1436.html" target="_blank" rel="external">码农教程</a></p></li></ul><blockquote><p>就这么多吧，都是网上的人们分享出来的。</p></blockquote><h2 id="网页在线学习"><a href="#网页在线学习" class="headerlink" title="网页在线学习"></a>网页在线学习</h2><ul><li><a href="https://sqlbolt.com" target="_blank" rel="external">sqlbolt</a></li></ul><blockquote><p>强烈推荐！还可在线实践(结合上面的视频一起来即可)。</p></blockquote><ul><li><p><a href="http://www.runoob.com/mysql/mysql-tutorial.html" target="_blank" rel="external">MySQL教程(菜鸟教程)</a></p></li><li><p><a href="https://m.w3cschool.cn/mysql/" target="_blank" rel="external">MySQL教程(w3cschool)</a></p></li><li><p><a href="https://www.yiibai.com/mysql/" target="_blank" rel="external">MySQL教程(易百教程)</a></p></li></ul><blockquote><p>相较于上面的书籍，在线教程更加的通俗易懂，可先通过这些入门简单认识一下以及学习语法，不懂的更深的部分可查看书籍即可。</p></blockquote><h2 id="YouTube上的资源"><a href="#YouTube上的资源" class="headerlink" title="YouTube上的资源"></a>YouTube上的资源</h2><ul><li><a href="https://www.youtube.com/results?search_query=mysql" target="_blank" rel="external">https://www.youtube.com/results?search_query=mysql</a></li></ul><blockquote><p>就这么简单～</p></blockquote><h1 id="实践学习"><a href="#实践学习" class="headerlink" title="实践学习"></a>实践学习</h1><p>强烈建议先根据视频学习！根据上面的YouTube教程结合<a href="https://sqlbolt.com" target="_blank" rel="external">sqlbolt</a>网站一步步来即可～若是英文看不懂，可结合上面的书籍资源以及在线资源查询即可。实践才是掌握一门语言的最快方法！</p><blockquote><p>有时根据网速快慢加载的数据库可能有点慢，等待一下即可。</p></blockquote><h3 id="实践网站："><a href="#实践网站：" class="headerlink" title="实践网站："></a>实践网站：</h3><ul><li><p><a href="https://sqlbolt.com/" target="_blank" rel="external">SQLbolt</a></p></li><li><p><a href="https://www.tutorialspoint.com/" target="_blank" rel="external">tutorialspoint</a></p></li><li><p><a href="https://www.w3schools.com/sql/sql_exercises.asp" target="_blank" rel="external">W3Schools</a></p></li><li><p><a href="https://www.codecademy.com/" target="_blank" rel="external">codecademy</a></p></li><li><p><a href="https://www.udemy.com/courses/search/?ref=home&amp;src=ukw&amp;q=mysql" target="_blank" rel="external">udemy</a></p></li></ul><h1 id="进阶好文章"><a href="#进阶好文章" class="headerlink" title="进阶好文章"></a>进阶好文章</h1><ul><li><p><a href="http://blog.codinglabs.org/articles/theory-of-mysql-index.html" target="_blank" rel="external">MySQL索引背后的数据结构及算法原理</a></p></li><li><p><a href="https://cloud.tencent.com/developer/article/1004475" target="_blank" rel="external">MySQL 开发实践 8 问</a></p></li><li><p><a href="https://juejin.im/post/5b4f710be51d45195c073912" target="_blank" rel="external">从I/O到索引的那些事</a></p></li><li><p><a href="https://juejin.im/post/5b8ba5dbe51d4538d63b9345" target="_blank" rel="external">从理论到实践，Mysql查询优化剖析</a></p></li></ul><blockquote><p>再者就是看书了。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近心血来潮想写几个SQL玩玩，在此会分享学习的书籍资源以及YouTube教程使用语法的实践项目，以及会进行一系列的简单实践。这里通过在YouTube上的一个大佬的视频来进行在线的实践即可。&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/xYMhPZ_L3fI&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;blockquote&gt;
&lt;p&gt;就是这个视频。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可主要参考书籍&lt;a href=&quot;https://pan.baidu.com/s/15hIkCroy2w7RvBdVH8LRmA&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;疯狂Java讲义(李刚)&lt;/a&gt;来进行学习，当然还有参考其他的经典书籍以备用学习，这类书籍很多，就不在此一一说明了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;《疯狂Java讲义》书籍的配套资源地址：&lt;a href=&quot;https://github.com/DoingLee&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/DoingLee&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="MySQL" scheme="https://liujunjie11.github.io/categories/MySQL/"/>
    
    
      <category term="MySQL" scheme="https://liujunjie11.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>学习计算机组成、计算机系统资源分享</title>
    <link href="https://liujunjie11.github.io/2018/11/13/%E5%AD%A6%E4%B9%A0%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E3%80%81%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E8%B5%84%E6%BA%90%E5%88%86%E4%BA%AB/"/>
    <id>https://liujunjie11.github.io/2018/11/13/学习计算机组成、计算机系统资源分享/</id>
    <published>2018-11-13T08:32:42.000Z</published>
    <updated>2019-01-02T06:48:25.253Z</updated>
    
    <content type="html"><![CDATA[<p>一直想写一些关于计算机的基础知识的，但是我又看到许多的优秀书籍以及优秀文章，我从其中也学习到了非常的东西，也解开了我的许多疑惑，在此感谢那些人们的付出～</p><p>回到正题，自己一直想写，但是由于时间问题以及质量不能保证…所以我打算将一些优秀的资源拿出来分享好了，也解决了自己的那块心头肉。</p><p>以下资源是我从网上收集到的，仅用于学习使用。</p><a id="more"></a><h1 id="云盘资源分享"><a href="#云盘资源分享" class="headerlink" title="云盘资源分享"></a>云盘资源分享</h1><ul><li><a href="https://pan.baidu.com/s/1Z9BcwV3fKGqwVXlLfU8B_g" target="_blank" rel="external">深入理解计算机系统（原书第三版）.pdf</a></li></ul><blockquote><p>一本非常好的书！！</p></blockquote><ul><li><p><a href="https://pan.baidu.com/s/1JIC9vxu1CnKgqBnfgrfEAw" target="_blank" rel="external">计算机组成.pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1LI2Cc9dFgAgBro_Tn7uKUA" target="_blank" rel="external">计算机操作系统（第3版）_汤小丹.pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1li3YCywQlfEMtRCkRdS1tQ" target="_blank" rel="external">计算机是怎么跑起来的.pdf</a></p></li></ul><blockquote><p>一本科普书吧，很简单，但是够用了。</p></blockquote><ul><li><p><a href="https://pan.baidu.com/s/1uDVuroObwbvuqlZWokE3dg" target="_blank" rel="external">计算机组成.pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1ix393Of_pPVnvAQZEdZumw" target="_blank" rel="external">Linux设备驱动程序(中文版第三版).pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1N6Y7faTYkmU7gyaXUv9YqA" target="_blank" rel="external">Linux内核完全注释.pdf</a></p></li><li><p><a href="https://pan.baidu.com/s/1jvuMLTCtrmytamVYtR2G7A" target="_blank" rel="external">深入Linux内核架构.pdf</a></p></li></ul><blockquote><p>以上都是网上收集的电子书，我个人平时喜欢看书，基本上都是电子书，有收集很多技术类的电子书，都是根据需求来收集的。</p></blockquote><h1 id="最近看到的相关的优秀文章"><a href="#最近看到的相关的优秀文章" class="headerlink" title="最近看到的相关的优秀文章"></a>最近看到的相关的优秀文章</h1><ul><li><p><a href="https://juejin.im/post/5b3c34e3e51d45190e34c680" target="_blank" rel="external">印象系列-理解进程的存在</a></p></li><li><p><a href="https://juejin.im/post/59eaf70ff265da432b49f6bc" target="_blank" rel="external">印象系列-磁盘和内存的基本认识</a></p></li><li><p><a href="https://juejin.im/post/59be20e6f265da06633d1648" target="_blank" rel="external">印象系列-linux内核启动过程</a></p></li><li><p><a href="https://juejin.im/post/5b4f710be51d45195c073912" target="_blank" rel="external">从I/O到索引的那些事</a></p></li></ul><blockquote><p>以上都是一个作者写的，最近在学习<code>MySQL</code>时无意中看到的，很好的文章。</p></blockquote><p>还是要多看书学习才行。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一直想写一些关于计算机的基础知识的，但是我又看到许多的优秀书籍以及优秀文章，我从其中也学习到了非常的东西，也解开了我的许多疑惑，在此感谢那些人们的付出～&lt;/p&gt;
&lt;p&gt;回到正题，自己一直想写，但是由于时间问题以及质量不能保证…所以我打算将一些优秀的资源拿出来分享好了，也解决了自己的那块心头肉。&lt;/p&gt;
&lt;p&gt;以下资源是我从网上收集到的，仅用于学习使用。&lt;/p&gt;
    
    </summary>
    
      <category term="资源分享" scheme="https://liujunjie11.github.io/categories/%E8%B5%84%E6%BA%90%E5%88%86%E4%BA%AB/"/>
    
      <category term="计算机基础" scheme="https://liujunjie11.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="资源分享" scheme="https://liujunjie11.github.io/tags/%E8%B5%84%E6%BA%90%E5%88%86%E4%BA%AB/"/>
    
      <category term="计算机基础" scheme="https://liujunjie11.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客图片外链从七牛云移至腾讯云</title>
    <link href="https://liujunjie11.github.io/2018/11/11/Hexo%E5%8D%9A%E5%AE%A2%E5%9B%BE%E7%89%87%E5%A4%96%E9%93%BE%E4%BB%8E%E4%B8%83%E7%89%9B%E4%BA%91%E7%A7%BB%E8%87%B3%E8%85%BE%E8%AE%AF%E4%BA%91/"/>
    <id>https://liujunjie11.github.io/2018/11/11/Hexo博客图片外链从七牛云移至腾讯云/</id>
    <published>2018-11-11T10:30:01.000Z</published>
    <updated>2019-01-08T08:17:14.217Z</updated>
    
    <content type="html"><![CDATA[<p>最近发现博客中的一些文章图片无法正常显示了，查看了一些文章之后，发现原来是测试域名失效了…我的图片存放了这么多…全都不能用了，妈蛋啊！</p><p>我研究了一下关于它的这个恢复的方法，需要实名不说了，还要我的网站备案，不可能的绝对不可能的，我要走了，再见了，七牛云！！</p><p>我要搬去腾讯云了。以下是我的记录。</p><a id="more"></a><h1 id="将七牛云的图片下载至本地"><a href="#将七牛云的图片下载至本地" class="headerlink" title="将七牛云的图片下载至本地"></a>将七牛云的图片下载至本地</h1><h2 id="过程操作"><a href="#过程操作" class="headerlink" title="过程操作"></a>过程操作</h2><p>具体需要用到<a href="https://developer.qiniu.com/kodo/tools/1302/qshell" target="_blank" rel="external">七牛云命令行工具(qshell)</a>，将曾经上传上去的图片批量下载到本地然后使用腾讯云再次慢慢整理即可…</p><ul><li>可参考官方介绍：<a href="http://songfeifeids.qiniuts.com/spjc/avthumb/batchdelete.mov.mp4" target="_blank" rel="external">使用 qshell 进行批量删除</a></li></ul><blockquote><p>由于我在七牛云上的图片有一部分可以显示，一部分无法显示，但是这个量真的太大了，我不打算一个一个替换了，之后的图片我就直接用腾讯云来充当图床好了…唉…心累。</p></blockquote><h1 id="关于在腾讯云的图床操作"><a href="#关于在腾讯云的图床操作" class="headerlink" title="关于在腾讯云的图床操作"></a>关于在腾讯云的图床操作</h1><p>可参考：</p><ul><li><a href="https://blog.csdn.net/a201577F0546/article/details/80146350" target="_blank" rel="external">使用腾讯云对象存储作为图床</a></li></ul><h1 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h1><p>我通过一个兄弟买了一个已备案的域名，在<a href="https://developer.qiniu.com/fusion/kb/1322/how-to-configure-cname-domain-name" target="_blank" rel="external">这里</a>跟着设置了一下，就OK了，接下来我需要将以前的在文件中域名更改为现在的就行了，图片就能正常显示出来了。为了更有效率的处理可以自己写个脚本或者是利用好一些编译软件替换掉域名即可：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-11-12%20%E4%B8%8B%E5%8D%886.57.30.png" alt=""></p><blockquote><p>我用的<em>Macdown</em>编译软件，平时用这个来写博客的。</p></blockquote><p>另外可以用公用的图床(以下为推荐的参考链接)：</p><ul><li><p><a href="https://sspai.com/post/40499" target="_blank" rel="external">https://sspai.com/post/40499</a></p></li><li><p><a href="https://blog.nfz.moe/archives/collection-of-image-hosting.html" target="_blank" rel="external">https://blog.nfz.moe/archives/collection-of-image-hosting.html</a></p></li></ul><blockquote><p>不过为了稳定，我是真的不想从来一遍了…文件太多了。所以我买了个备案的域名。</p></blockquote><h1 id="更新-1"><a href="#更新-1" class="headerlink" title="更新"></a>更新</h1><p>最近买的不久的备案域名被收回了…于是我决心从七牛云搬出来。以下是我的一些心得。</p><p><strong>需要先将七牛云的上的所有的文件下载下来，之后再将文件上传腾讯云上，之后更改一些外链链接即可万事大吉了！</strong></p><blockquote><p>具体步骤可参考：<a href="http://robotkang.cc/2018/11/pic/" target="_blank" rel="external">将图床从七牛云迁移到腾讯COS</a></p></blockquote><p>另外要补充的一些：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-01-02%20%E4%B8%8B%E5%8D%883.11.27.png" alt=""></p><blockquote><p>这是我摸索出来的正确的符合当下情况的<code>batch_download.conf</code>文件描述，空白表示全部下载的意识。</p></blockquote><p>另外这个基本的下载与使用的官方指导：<a href="https://developer.qiniu.com/kodo/tools/1302/qshell" target="_blank" rel="external">Mac上的七牛云命令行工具(qshell)使用</a></p><blockquote><p>但是单单看这个视频是不行的，还是出现了一些错误，比如：命令行根本运行不了！<strong>所以还需要参考下面的官方的API进行操作！！！！</strong></p></blockquote><ul><li><p><a href="https://github.com/qiniu/qshell" target="_blank" rel="external">qshell-Github</a></p></li><li><p><a href="https://developer.qiniu.com/kodo/tools/1302/qshell" target="_blank" rel="external">官方文档命令行工具(qshell)</a></p></li></ul><p>另外关于批量更改文字内容（尝试未成功…）可参考：</p><ul><li><a href="https://blog.csdn.net/lzyzuixin/article/details/7638979" target="_blank" rel="external">linux sed命令 批量替换文件内容的方法</a></li></ul><h2 id="注意-amp-提示"><a href="#注意-amp-提示" class="headerlink" title="注意&amp;提示"></a>注意&amp;提示</h2><p>使用的命令行如果出现错误一定看官方的文档进行修改重新来过！！以官方文档为准！！！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近发现博客中的一些文章图片无法正常显示了，查看了一些文章之后，发现原来是测试域名失效了…我的图片存放了这么多…全都不能用了，妈蛋啊！&lt;/p&gt;
&lt;p&gt;我研究了一下关于它的这个恢复的方法，需要实名不说了，还要我的网站备案，不可能的绝对不可能的，我要走了，再见了，七牛云！！&lt;/p&gt;
&lt;p&gt;我要搬去腾讯云了。以下是我的记录。&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://liujunjie11.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Hexo" scheme="https://liujunjie11.github.io/categories/Hexo/"/>
    
    
      <category term="教程笔记" scheme="https://liujunjie11.github.io/tags/%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Hexo" scheme="https://liujunjie11.github.io/tags/Hexo/"/>
    
      <category term="七牛云" scheme="https://liujunjie11.github.io/tags/%E4%B8%83%E7%89%9B%E4%BA%91/"/>
    
      <category term="腾讯云" scheme="https://liujunjie11.github.io/tags/%E8%85%BE%E8%AE%AF%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>（Mac）Julia的下载及结合notebook使用</title>
    <link href="https://liujunjie11.github.io/2018/11/09/%EF%BC%88Mac%EF%BC%89Julia%E7%9A%84%E4%B8%8B%E8%BD%BD%E5%8F%8A%E7%BB%93%E5%90%88notebook%E4%BD%BF%E7%94%A8/"/>
    <id>https://liujunjie11.github.io/2018/11/09/（Mac）Julia的下载及结合notebook使用/</id>
    <published>2018-11-09T06:50:59.000Z</published>
    <updated>2019-01-02T06:48:54.745Z</updated>
    
    <content type="html"><![CDATA[<p>关于Julia这个语言，这是一个鲜为人知的语言，听说在处理数值分析方面还不错，最近也总是无意间看到，所以想试试看看，就在此顺便记录一下安装的过程以及如何在notebook中运行的过程。</p><a id="more"></a><h1 id="安装Julia"><a href="#安装Julia" class="headerlink" title="安装Julia"></a>安装Julia</h1><ul><li>在这里下载：<a href="https://julialang.org/downloads/" target="_blank" rel="external">https://julialang.org/downloads/</a></li></ul><p>或者是在<code>Mac</code>上可用<code>homebrew</code>命令行:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">brew cask install julia</div></pre></td></tr></table></figure><blockquote><p>可参考：<a href="https://julialang.org/downloads/platform.html#macos" target="_blank" rel="external">https://julialang.org/downloads/platform.html#macos</a></p></blockquote><p>我使用直接下载安装的方式。</p><h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">vi ~/.bash_profile <span class="comment">#打开配置文件</span></div><div class="line"></div><div class="line"><span class="comment">#输入对应目录</span></div><div class="line"><span class="comment">#Julia</span></div><div class="line"><span class="built_in">export</span> PATH=<span class="string">"/Applications/Julia-1.0.app/Contents/Resources/julia/bin:<span class="variable">$&#123;PATH&#125;</span>"</span></div><div class="line"></div><div class="line"><span class="built_in">source</span> ~/.bash_profile <span class="comment">#快速生效</span></div></pre></td></tr></table></figure><p>这样之后在终端直接输入<code>Julia</code>即可使用Julia了。</p><h1 id="notebook中运行"><a href="#notebook中运行" class="headerlink" title="notebook中运行"></a>notebook中运行</h1><p>下载相关的内核就OK了。</p><p>打开Julia终端进程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">using Pkg</div><div class="line">Pkg.add(<span class="string">"IJulia"</span>)</div></pre></td></tr></table></figure><blockquote><p>重启notebook，发现可以了。</p></blockquote><p>可参考：</p><ul><li><p><a href="https://github.com/JuliaLang/IJulia.jl" target="_blank" rel="external">https://github.com/JuliaLang/IJulia.jl</a></p></li><li><p><a href="https://www.youtube.com/watch?v=uRIQXJXRtqg" target="_blank" rel="external">https://www.youtube.com/watch?v=uRIQXJXRtqg</a></p></li></ul><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>附上几个学习链接：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/41802723" target="_blank" rel="external">一个简单的Julia教程（一）</a></li></ul><blockquote><p>这篇文章有介绍用其他运行<code>Julia</code>的方案。</p></blockquote><ul><li><p><a href="http://discourse.juliacn.com" target="_blank" rel="external">Julia中文discourse</a></p></li><li><p><a href="https://www.zhihu.com/question/284356534" target="_blank" rel="external">Julia 解决了 C++/Python/Matlab 的哪些痛点？</a></p></li><li><p><a href="https://www.zhihu.com/question/20072632" target="_blank" rel="external">怎么看待新出的 Julia 语言？它的前景怎么样？</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于Julia这个语言，这是一个鲜为人知的语言，听说在处理数值分析方面还不错，最近也总是无意间看到，所以想试试看看，就在此顺便记录一下安装的过程以及如何在notebook中运行的过程。&lt;/p&gt;
    
    </summary>
    
      <category term="软件使用" scheme="https://liujunjie11.github.io/categories/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/"/>
    
      <category term="Julia" scheme="https://liujunjie11.github.io/categories/Julia/"/>
    
    
      <category term="Jupyter Notebook" scheme="https://liujunjie11.github.io/tags/Jupyter-Notebook/"/>
    
      <category term="Julia" scheme="https://liujunjie11.github.io/tags/Julia/"/>
    
  </entry>
  
  <entry>
    <title>Python结合OCR以及Opencv提取并且实时翻译图片内容</title>
    <link href="https://liujunjie11.github.io/2018/11/08/Python%E7%BB%93%E5%90%88OCR%E4%BB%A5%E5%8F%8AOpencv%E6%8F%90%E5%8F%96%E5%B9%B6%E4%B8%94%E5%AE%9E%E6%97%B6%E7%BF%BB%E8%AF%91%E5%9B%BE%E7%89%87%E5%86%85%E5%AE%B9/"/>
    <id>https://liujunjie11.github.io/2018/11/08/Python结合OCR以及Opencv提取并且实时翻译图片内容/</id>
    <published>2018-11-08T04:09:42.000Z</published>
    <updated>2019-01-02T06:49:04.071Z</updated>
    
    <content type="html"><![CDATA[<p>本文讲述基于python的一些模块进行<code>图片内容的提取</code>、<code>图片内容的翻译</code>。本文主要进行记录一些在实践中的构想以及遇到的问题，并且记录上一些实现的代码，因为技术含量实在是不怎么高的，不过若是自己玩玩，参加那种水比赛也许能获得个不错的名次，或者是应付个学生报告什么的…</p><p>由于时间关系，本文多数只是起到一个构想记录的效用。</p><a id="more"></a><h1 id="基于OCR的图片内容提取"><a href="#基于OCR的图片内容提取" class="headerlink" title="基于OCR的图片内容提取"></a>基于OCR的图片内容提取</h1><p>在python使用到的模块是<code>pytesseract</code>，关于简要的下载介绍什么的可见：<a href="https://zhuanlan.zhihu.com/p/31530755" target="_blank" rel="external">Python–文字识别–Tesseract</a>。</p><p>运行代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pytesseract</div><div class="line"><span class="keyword">import</span> cv2</div><div class="line"></div><div class="line">image = cv2.imread(<span class="string">'/Users/junjieliu/Desktop/1.png'</span>)</div><div class="line">text = pytesseract.image_to_string(image)</div><div class="line">print(text)</div></pre></td></tr></table></figure><p>在此记录一下在使用过程中的出现的问题：</p><h2 id="问题一："><a href="#问题一：" class="headerlink" title="问题一："></a>问题一：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Error: [Errno 2] No such file or directory using pytesser</div></pre></td></tr></table></figure><blockquote><p>之后我参考了：<a href="https://stackoverflow.com/questions/35609773/oserror-errno-2-no-such-file-or-directory-using-pytesser" target="_blank" rel="external">https://stackoverflow.com/questions/35609773/oserror-errno-2-no-such-file-or-directory-using-pytesser</a></p></blockquote><p>我使用了其中的前面的几个答案的方案，结果出现了下面的错误…</p><h2 id="问题二："><a href="#问题二：" class="headerlink" title="问题二："></a>问题二：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">PermissionError: [Errno 13] Permission denied</div></pre></td></tr></table></figure><blockquote><p>之后我参考了：<a href="https://github.com/madmaze/pytesseract/issues/62" target="_blank" rel="external">https://github.com/madmaze/pytesseract/issues/62</a></p></blockquote><p>但是依旧得不到解决。</p><h2 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h2><p>使用命令行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">which</span> tesseract</div></pre></td></tr></table></figure><p>找到了它的位置（没想到Mac自带的一个？）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/<span class="built_in">local</span>/bin/tesseract</div></pre></td></tr></table></figure><p>然后虽然在替换了地址之后可以正常运行代码了(即<code>tesseract_cmd = “/usr/local/bin/tesseract”</code>)，就会变得很麻烦，因为自带的根本难以进行扩展。</p><p>将下载好的加入环境变量替换掉原装的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi ~/.bash_profile</div></pre></td></tr></table></figure><p>写入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#tesseract</span></div><div class="line">export PATH=<span class="string">"/usr/local/Cellar/tesseract/4.0.0/bin:$PATH"</span></div></pre></td></tr></table></figure><p>立即生效：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">source</span> ~/.bash_profile</div></pre></td></tr></table></figure><p>之后再使用命令行<code>which tesseract</code>,就会发现变了位置，更改<code>tesseract_cmd = “/usr/local/Cellar/tesseract/4.0.0/bin/tesseract”</code>，之后程序就能成功运行并且可以得到以后的更多的扩展使用了，比如语言包的选择。</p><h1 id="在线提取图片文字小工具"><a href="#在线提取图片文字小工具" class="headerlink" title="在线提取图片文字小工具"></a>在线提取图片文字小工具</h1><p>提取这一块的具体过程就不多说了，简单记录一下结合其他技术可以实现的想法：</p><blockquote><p>可结合<code>Pyqt5</code>的GUI界面化开发，输入图片的目录地址，下方即出现提取的内容。</p><p>在以上的基础上结合爬虫实现翻译。</p></blockquote><p><strong>可参考我以前写的文章：<a href="https://liujunworld.com/2018/05/07/python3爬虫与GUI-基于有道词典的词典小工具/" target="_blank" rel="external">python3爬虫与GUI-基于有道词典的词典小工具</a></strong></p><p>这样一来这个小工具就能出来了。这里就这样吧，因为时间关系加上实现的过程不是很难，所以就不多说了。</p><ul><li>关于提取的精确度可移步参考更强大的工具：<a href="https://github.com/JinpengLI/deep_ocr" target="_blank" rel="external">deep_ocr</a></li></ul><h1 id="结合OpenCV实时翻译"><a href="#结合OpenCV实时翻译" class="headerlink" title="结合OpenCV实时翻译"></a>结合OpenCV实时翻译</h1><p>这里主要是我在参考了：<a href="https://zhuanlan.zhihu.com/p/40025902" target="_blank" rel="external">用OpenCV和Python识别二维码和条形码</a>这篇文章之后结合本身的需求出现的启发。</p><p>这是我经过修改之后的代码（添加并且修改了几行代码）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> imutils.video <span class="keyword">import</span> VideoStream</div><div class="line"><span class="keyword">from</span> pyzbar <span class="keyword">import</span> pyzbar</div><div class="line"><span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">import</span> imutils</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> cv2</div><div class="line"></div><div class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</div><div class="line">vs = VideoStream(src=<span class="number">0</span>).start()</div><div class="line">time.sleep(<span class="number">2.0</span>)</div><div class="line"></div><div class="line"><span class="comment"># open the output CSV file for writing and initialize the set of</span></div><div class="line"><span class="comment"># barcodes found thus far</span></div><div class="line">csv = open(<span class="string">"barcodes.csv"</span>, <span class="string">"w"</span>)</div><div class="line">found = set()</div><div class="line"></div><div class="line"><span class="comment"># loop over the frames from the video stream</span></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    <span class="comment"># grab the frame from the threaded video stream and resize it to</span></div><div class="line">    <span class="comment"># have a maximum width of 400 pixels</span></div><div class="line">    frame = vs.read()</div><div class="line">    frame = imutils.resize(frame, width=<span class="number">400</span>)</div><div class="line"></div><div class="line">    <span class="comment"># find the barcodes in the frame and decode each of the barcodes</span></div><div class="line">    barcodes = pyzbar.decode(frame)</div><div class="line"></div><div class="line">    <span class="comment"># loop over the detected barcodes</span></div><div class="line">    <span class="keyword">for</span> barcode <span class="keyword">in</span> barcodes:</div><div class="line">        <span class="comment"># extract the bounding box location of the barcode and draw</span></div><div class="line">        <span class="comment"># the bounding box surrounding the barcode on the image</span></div><div class="line">        (x, y, w, h) = barcode.rect</div><div class="line">        cv2.rectangle(frame, (x, y), (x + w, y + h), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</div><div class="line"></div><div class="line">        <span class="comment"># the barcode data is a bytes object so if we want to draw it</span></div><div class="line">        <span class="comment"># on our output image we need to convert it to a string first</span></div><div class="line">        barcodeData = barcode.data.decode(<span class="string">"utf-8"</span>)</div><div class="line">        barcodeType = barcode.type</div><div class="line"></div><div class="line">        <span class="comment"># draw the barcode data and barcode type on the image</span></div><div class="line">        text = <span class="string">"&#123;&#125; (&#123;&#125;)"</span>.format(barcodeData, barcodeType)</div><div class="line">        cv2.putText(frame, text, (x, y - <span class="number">10</span>),</div><div class="line">            cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.5</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</div><div class="line"></div><div class="line">        <span class="comment"># if the barcode text is currently not in our CSV file, write</span></div><div class="line">        <span class="comment"># the timestamp + barcode qto disk and update the set</span></div><div class="line">        <span class="keyword">if</span> barcodeData <span class="keyword">not</span> <span class="keyword">in</span> found:</div><div class="line">            csv.write(<span class="string">"&#123;&#125;,&#123;&#125;\n"</span>.format(datetime.datetime.now(),</div><div class="line">                barcodeData))</div><div class="line">            csv.flush()</div><div class="line">            found.add(barcodeData)</div><div class="line"></div><div class="line">    <span class="comment"># show the output frame</span></div><div class="line">    cv2.imshow(<span class="string">"Barcode Scanner"</span>, frame)</div><div class="line">    key = cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span></div><div class="line"> </div><div class="line">    <span class="comment"># if the `q` key was pressed, break from the loop</span></div><div class="line">    <span class="keyword">if</span> key == ord(<span class="string">"q"</span>):</div><div class="line">        <span class="keyword">break</span></div><div class="line"></div><div class="line"><span class="comment"># close the output CSV file do a bit of cleanup</span></div><div class="line">print(<span class="string">"[INFO] cleaning up..."</span>)</div><div class="line">cap.release()  <span class="comment"># 释放摄像头</span></div><div class="line">csv.close()</div><div class="line">cv2.destroyAllWindows()</div><div class="line">vs.stop()</div></pre></td></tr></table></figure><blockquote><p>性能得到了一点的优化，少写了点代码。效果没变化。</p></blockquote><p>关于实现实时翻译的效果，这里可结合上面的有道爬虫与OpenCV来完成。基本上进行一些修改就行了，实现的过程不算太难。多参考官方文档以及他人的做法即能实现。</p><p>大概的代码样本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding:utf-8</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> imutils.video <span class="keyword">import</span> VideoStream</div><div class="line"><span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">import</span> imutils</div><div class="line"><span class="keyword">import</span> time</div><div class="line"><span class="keyword">import</span> cv2</div><div class="line"><span class="keyword">import</span> hashlib</div><div class="line"><span class="keyword">import</span> requests</div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">import</span> random</div><div class="line"></div><div class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</div><div class="line"><span class="comment"># initialize the video stream and allow the camera sensor to warm up</span></div><div class="line">print(<span class="string">"starting video stream..."</span>)</div><div class="line"><span class="comment"># vs = VideoStream(src=0).start()</span></div><div class="line">vs = VideoStream(src=<span class="number">0</span>).start()</div><div class="line">time.sleep(<span class="number">2.0</span>)</div><div class="line"></div><div class="line">csv = open(<span class="string">"barcodes.csv"</span>, <span class="string">"w"</span>)</div><div class="line">found = set()</div><div class="line"></div><div class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">    <span class="comment"># grab the frame from the threaded video stream and resize it to</span></div><div class="line">    <span class="comment"># have a maximum width of 400 pixels</span></div><div class="line">    frame = vs.read()</div><div class="line">    frame = imutils.resize(frame, width=<span class="number">400</span>)</div><div class="line"></div><div class="line">    word = frame</div><div class="line">    <span class="keyword">for</span> words <span class="keyword">in</span> word:</div><div class="line">        r = str(int(time.time() * <span class="number">1000</span> + random.randint(<span class="number">1</span>, <span class="number">10</span>)))  <span class="comment"># 模仿JS代码的仿写</span></div><div class="line">        S = <span class="string">'fanyideskweb'</span></div><div class="line">        n = words</div><div class="line">        D = <span class="string">"ebSeFb%=XZ%T[KZ)c(sy!"</span>  <span class="comment"># 在完整的JS代码中可找到    </span></div><div class="line">        o = hashlib.md5((S + n + str(r) + D).encode(<span class="string">'utf-8'</span>)).hexdigest()</div><div class="line">        </div><div class="line">        data = &#123;</div><div class="line">            <span class="string">'i'</span>: words,</div><div class="line">            <span class="string">'from'</span>: <span class="string">'AUTO'</span>,</div><div class="line">            <span class="string">'to'</span>: <span class="string">'AUTO'</span>,</div><div class="line">            <span class="string">'smartresult'</span>: <span class="string">'dict'</span>,</div><div class="line">            <span class="string">'client'</span>: S,</div><div class="line">            <span class="string">'salt'</span>: r,</div><div class="line">            <span class="string">'sign'</span>: o,</div><div class="line">            <span class="string">'doctype'</span>: <span class="string">'json'</span>,</div><div class="line">            <span class="string">'version'</span>: <span class="string">'2.1'</span>,</div><div class="line">            <span class="string">'keyfrom'</span>: <span class="string">'fanyi.web'</span>,</div><div class="line">            <span class="string">'action'</span>: <span class="string">'FY_BY_REALTIME'</span>,</div><div class="line">            <span class="string">'typoResult'</span>: <span class="string">'false'</span></div><div class="line">        &#125;</div><div class="line">        url = <span class="string">'http://fanyi.youdao.com/translate_o?smartresult=dict&amp;smartresult=rule'</span></div><div class="line">        </div><div class="line">        <span class="comment"># 在代理中需要加入cookies信息，否则会出现代码错误信息的返回</span></div><div class="line">        header = &#123;</div><div class="line">            <span class="string">'Cookie'</span>: <span class="string">'OUTFOX_SEARCH_USER_ID=432464843@10.168.8.76; _ntes_nnid=25aff2b1480f17471ca1585f6f2f4293,1512024136653; OUTFOX_SEARCH_USER_ID_NCOO=132154936.07902834; JSESSIONID=aaa3TFIg-JJJN4xEog6mw; ___rl__test__cookies=1525691300664'</span>,</div><div class="line">            <span class="string">'Referer'</span>: <span class="string">'http://fanyi.youdao.com/'</span>,</div><div class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36'</span></div><div class="line">        &#125;</div><div class="line">        response = requests.post(url=url, headers=header, data=data)</div><div class="line">        response.encoding = <span class="string">'utf-8'</span></div><div class="line">        </div><div class="line">        translateResult = json.loads(response.text)[<span class="string">"translateResult"</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="string">'tgt'</span>]</div><div class="line">        <span class="comment">#(x, y, w, h) = words.rect</span></div><div class="line">        cv2.rectangle(frame, (<span class="number">10</span>, <span class="number">10</span>), (<span class="number">20</span>, <span class="number">20</span>), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</div><div class="line">        </div><div class="line">               cv2.putText(frame, translateResult, (<span class="number">10</span>, <span class="number">10</span> - <span class="number">10</span>),</div><div class="line">        cv2.FONT_HERSHEY_SIMPLEX, <span class="number">0.5</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</div><div class="line">        </div><div class="line">        <span class="comment"># if the  text is currently not in our CSV file, write</span></div><div class="line">        <span class="comment"># the timestamp + text qto disk and update the set</span></div><div class="line">        <span class="keyword">if</span> translateResult <span class="keyword">not</span> <span class="keyword">in</span> found:</div><div class="line">            csv.write(<span class="string">"&#123;&#125;,&#123;&#125;\n"</span>.format(datetime.datetime.now(),</div><div class="line">                translateResult))</div><div class="line">            csv.flush()</div><div class="line">            found.add(translateResult)</div><div class="line"></div><div class="line">    <span class="comment"># show the output frame</span></div><div class="line">    cv2.imshow(<span class="string">"Translate Discern"</span>, frame)</div><div class="line">    key = cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span></div><div class="line"> </div><div class="line">    <span class="comment"># if the `q` key was pressed, break from the loop</span></div><div class="line">    <span class="keyword">if</span> key == ord(<span class="string">"q"</span>):</div><div class="line">        <span class="keyword">break</span></div><div class="line"></div><div class="line"><span class="comment"># close the output CSV file do a bit of cleanup</span></div><div class="line">print(<span class="string">"cleaning up..."</span>)</div><div class="line">cap.release()  <span class="comment"># 释放摄像头</span></div><div class="line">csv.close()</div><div class="line">cv2.destroyAllWindows()</div><div class="line">vs.stop()</div></pre></td></tr></table></figure><p>可参考：</p><ul><li><p><a href="https://www.jiqizhixin.com/articles/2017-09-21-3" target="_blank" rel="external">深度学习 + OpenCV，Python实现实时视频目标检测</a></p></li><li><p><a href="https://yongyuan.name/pcvwithpython/chapter10.html#sec-10-2-1" target="_blank" rel="external">OpenCV Python接口</a></p></li><li><p><a href="https://www.pyimagesearch.com/2015/04/06/zero-parameter-automatic-canny-edge-detection-with-python-and-opencv/" target="_blank" rel="external">Zero-parameter, automatic Canny edge detection with Python and OpenCV</a></p></li><li><p><a href="https://juejin.im/entry/5b5e694ee51d4535c75631e7" target="_blank" rel="external">Opencv获取身份证号码区域</a></p></li></ul><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>记录一下在下载tesseract之后的提示，有一天可能会用到：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">icu4c is keg-only, which means it was not symlinked into /usr/local,</div><div class="line">because macOS provides libicucore.dylib (but nothing else).</div><div class="line"></div><div class="line">If you need to have icu4c first in your PATH run:</div><div class="line">  echo &apos;export PATH=&quot;/usr/local/opt/icu4c/bin:$PATH&quot;&apos; &gt;&gt; ~/.bash_profile</div><div class="line">  echo &apos;export PATH=&quot;/usr/local/opt/icu4c/sbin:$PATH&quot;&apos; &gt;&gt; ~/.bash_profile</div><div class="line"></div><div class="line">For compilers to find icu4c you may need to set:</div><div class="line">  export LDFLAGS=&quot;-L/usr/local/opt/icu4c/lib&quot;</div><div class="line">  export CPPFLAGS=&quot;-I/usr/local/opt/icu4c/include&quot;</div><div class="line"></div><div class="line">For pkg-config to find icu4c you may need to set:</div><div class="line">  export PKG_CONFIG_PATH=&quot;/usr/local/opt/icu4c/lib/pkgconfig&quot;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文讲述基于python的一些模块进行&lt;code&gt;图片内容的提取&lt;/code&gt;、&lt;code&gt;图片内容的翻译&lt;/code&gt;。本文主要进行记录一些在实践中的构想以及遇到的问题，并且记录上一些实现的代码，因为技术含量实在是不怎么高的，不过若是自己玩玩，参加那种水比赛也许能获得个不错的名次，或者是应付个学生报告什么的…&lt;/p&gt;
&lt;p&gt;由于时间关系，本文多数只是起到一个构想记录的效用。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
      <category term="OCR" scheme="https://liujunjie11.github.io/categories/OCR/"/>
    
      <category term="OpenCV" scheme="https://liujunjie11.github.io/categories/OpenCV/"/>
    
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
      <category term="OCR" scheme="https://liujunjie11.github.io/tags/OCR/"/>
    
      <category term="OpenCV" scheme="https://liujunjie11.github.io/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle比赛：数字识别的多种算法实现</title>
    <link href="https://liujunjie11.github.io/2018/11/07/Kaggle%E6%AF%94%E8%B5%9B%EF%BC%9A%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E7%9A%84%E5%A4%9A%E7%A7%8D%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
    <id>https://liujunjie11.github.io/2018/11/07/Kaggle比赛：数字识别的多种算法实现/</id>
    <published>2018-11-07T07:09:27.000Z</published>
    <updated>2019-01-02T06:49:13.488Z</updated>
    
    <content type="html"><![CDATA[<p>关于<code>Kaggle</code>大赛就不多说了，我打算进一步了解一下入门级的比赛之后再另作参加项目/比赛的打算，在此之前需要更多的实践才行。</p><p>以下是我学习的地址(在一个<code>GitHub</code>大神分享的相关的资源)：</p><blockquote><p><a href="https://github.com/apachecn/kaggle/blob/dev/competitions/getting-started/digit-recognizer/knn算法描述.md" target="_blank" rel="external">https://github.com/apachecn/kaggle/blob/dev/competitions/getting-started/digit-recognizer/knn算法描述.md</a></p></blockquote><p>里面有多种可以实现的算法的代码以及思想，我在此进行进一步的整理，进行一个简单的代码记录，以及会进行一点修改以符合我自身的情况。</p><ul><li>需要的数据下载地址：<a href="https://www.kaggle.com/c/digit-recognizer/data" target="_blank" rel="external">https://www.kaggle.com/c/digit-recognizer/data</a></li></ul><a id="more"></a><h1 id="KNN实现"><a href="#KNN实现" class="headerlink" title="KNN实现"></a>KNN实现</h1><p><img src="http://liu-1258031152.cos.ap-beijing.myqcloud.com/1283539-1820df734cf34260.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于&lt;code&gt;Kaggle&lt;/code&gt;大赛就不多说了，我打算进一步了解一下入门级的比赛之后再另作参加项目/比赛的打算，在此之前需要更多的实践才行。&lt;/p&gt;
&lt;p&gt;以下是我学习的地址(在一个&lt;code&gt;GitHub&lt;/code&gt;大神分享的相关的资源)：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/apachecn/kaggle/blob/dev/competitions/getting-started/digit-recognizer/knn算法描述.md&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/apachecn/kaggle/blob/dev/competitions/getting-started/digit-recognizer/knn算法描述.md&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;里面有多种可以实现的算法的代码以及思想，我在此进行进一步的整理，进行一个简单的代码记录，以及会进行一点修改以符合我自身的情况。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需要的数据下载地址：&lt;a href=&quot;https://www.kaggle.com/c/digit-recognizer/data&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.kaggle.com/c/digit-recognizer/data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Kaggle" scheme="https://liujunjie11.github.io/categories/Kaggle/"/>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="Kaggle" scheme="https://liujunjie11.github.io/tags/Kaggle/"/>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：均值平移(Mean Shift)算法的实现及应用</title>
    <link href="https://liujunjie11.github.io/2018/10/30/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9A%E5%9D%87%E5%80%BC%E5%B9%B3%E7%A7%BB(Mean%20Shift)%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%BA%94%E7%94%A8/"/>
    <id>https://liujunjie11.github.io/2018/10/30/python机器学习系列：均值平移(Mean Shift)算法的实现及应用/</id>
    <published>2018-10-30T12:54:58.000Z</published>
    <updated>2019-01-02T06:49:24.074Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/3ERPpzrDkVg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><blockquote><p>这里是对应的课程地址：<a href="https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/?completed=/k-means-from-scratch-2-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/?completed=/k-means-from-scratch-2-machine-learning-tutorial/</a></p></blockquote><p>关于这个算法更像是<code>无监督学习</code>，它相较于<code>K-Means</code>算法不用指定<code>K</code>的个数，可以自动的通过求解一个向量，使得圆心一直往数据集密度最大的方向移动。说的再简单一点，就是每次迭代的时候，都是找到圆里面点的平均位置作为新的圆心位置。</p><blockquote><p>可参考：<a href="https://blog.csdn.net/hjimce/article/details/45718593" target="_blank" rel="external">机器学习（十）Mean Shift 聚类算法</a>、<br><a href="https://zh.wikipedia.org/wiki/%E7%88%AC%E5%B1%B1%E7%AE%97%E6%B3%95" target="_blank" rel="external">爬山算法</a></p></blockquote><p>在原作者的原代码上进行一些符合当今实际情况的修改。</p><a id="more"></a><h1 id="均值平移-Mean-Shift-的实现"><a href="#均值平移-Mean-Shift-的实现" class="headerlink" title="均值平移(Mean Shift)的实现"></a>均值平移(Mean Shift)的实现</h1><p>首先通过代码来理解看看他是个什么情况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> MeanShift</div><div class="line"><span class="keyword">from</span> sklearn.datasets.samples_generator <span class="keyword">import</span> make_blobs</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">centers = [[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>], [<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>], [<span class="number">3</span>,<span class="number">10</span>,<span class="number">10</span>]]</div><div class="line"></div><div class="line"><span class="comment">#样本以及聚类型</span></div><div class="line">X, label = make_blobs(n_samples=<span class="number">100</span>, centers=centers, cluster_std=<span class="number">1.5</span>) <span class="comment">#样本数量，中心点，方差设置</span></div><div class="line"></div><div class="line">ms = MeanShift()</div><div class="line">ms.fit(X)</div><div class="line">labels = ms.labels_</div><div class="line">cluster_centers = ms.cluster_centers_</div><div class="line">n_clusters = len(np.unique(labels))</div><div class="line">print(labels,cluster_centers)</div><div class="line"></div><div class="line">colors = [<span class="string">'r'</span>,<span class="string">'g'</span>,<span class="string">'k'</span>]</div><div class="line">fig = plt.figure()</div><div class="line">ax = fig.add_subplot(<span class="number">111</span>, projection = <span class="string">'3d'</span>)</div><div class="line"></div><div class="line"><span class="comment">#画出所有的样本点</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</div><div class="line">    ax.scatter(X[i][<span class="number">0</span>], X[i][<span class="number">1</span>], X[i][<span class="number">2</span>], c=colors[labels[i]], marker=<span class="string">'o'</span>)</div><div class="line"></div><div class="line"><span class="comment">#画出中心点</span></div><div class="line">ax.scatter(cluster_centers[:,<span class="number">0</span>], cluster_centers[:,<span class="number">1</span>], cluster_centers[:,<span class="number">2</span>],marker=<span class="string">'x'</span>, color=<span class="string">'k'</span>, s=<span class="number">150</span>, linewidths=<span class="number">5</span>, zorder=<span class="number">1</span>) <span class="comment">#zorder参数的数值越小表示越早画上去，在图表在叠加状态下时有一定的调整作用，比如不让画出来的交叉图分不清等问题</span></div><div class="line"><span class="comment"># ax.scatter(cluster_centers[0], cluster_centers[1], cluster_centers[2],marker='x', color='k', s=150, linewidths=5, zorder=10)还是跟上面的有区别的，自行检查。</span></div><div class="line">print(cluster_centers[:,<span class="number">0</span>])</div><div class="line"></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>结果展示：</p><ul><li>直接移步这里看吧：<a href="https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/</a></li></ul><blockquote><p>对我来说，作者的关于<code>均值平移(Mean Shift)算法</code>的教程文章实在是看不下去了…</p></blockquote><h2 id="关于原作者的均值平移-Mean-Shift-算法的实现"><a href="#关于原作者的均值平移-Mean-Shift-算法的实现" class="headerlink" title="关于原作者的均值平移(Mean Shift)算法的实现"></a>关于原作者的均值平移(Mean Shift)算法的实现</h2><ul><li>直接移步这里吧：<a href="https://pythonprogramming.net/weighted-bandwidth-mean-shift-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/weighted-bandwidth-mean-shift-machine-learning-tutorial/</a></li></ul><blockquote><p>原作者的代码不怎么合意，并且不能怎么真正的展现出来实现的意义，我不怎么认同，所以只贴上链接在此。</p></blockquote><h2 id="关于均值平移-Mean-Shift-算法的项目应用"><a href="#关于均值平移-Mean-Shift-算法的项目应用" class="headerlink" title="关于均值平移(Mean Shift)算法的项目应用"></a>关于均值平移(Mean Shift)算法的项目应用</h2><p>在原作者中是关于上次中的<code>titanic</code>数据集。</p><blockquote><p>数据地址：<a href="https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls" target="_blank" rel="external">https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls</a></p></blockquote><ul><li>这里是实现的地址：<a href="https://pythonprogramming.net/mean-shift-titanic-dataset-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/mean-shift-titanic-dataset-machine-learning-tutorial/</a></li></ul><p>对我来说，这个算法应用到这个数据集上是有一点牵强的，没必要的…因为选择这样的数据集来进行试验品实在有点晦涩难懂不合适。</p><h2 id="铺助理解链接"><a href="#铺助理解链接" class="headerlink" title="铺助理解链接"></a>铺助理解链接</h2><ul><li><p><a href="https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.array_equal.html" target="_blank" rel="external">numpy.array_equal</a></p></li><li><p><a href="https://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html" target="_blank" rel="external">mplot3d tutorial</a></p></li><li><p><a href="https://blog.csdn.net/ichuzhen/article/details/51768934" target="_blank" rel="external">sklearn 中 make_blobs模块使用</a></p></li><li><p><a href="https://blog.csdn.net/hjimce/article/details/45718593" target="_blank" rel="external">机器学习（十）Mean Shift 聚类算法</a></p></li><li><p><a href="https://www.zhihu.com/question/56091756/answer/191164507" target="_blank" rel="external">matplotlib.pyplot.plot()函数中参数zorder</a></p></li></ul><p>就这样吧，其实我也很期待写下<code>神经网络</code>的记录教程～</p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/3ERPpzrDkVg&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;blockquote&gt;
&lt;p&gt;这里是对应的课程地址：&lt;a href=&quot;https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/?completed=/k-means-from-scratch-2-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://pythonprogramming.net/hierarchical-clustering-mean-shift-machine-learning-tutorial/?completed=/k-means-from-scratch-2-machine-learning-tutorial/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;关于这个算法更像是&lt;code&gt;无监督学习&lt;/code&gt;，它相较于&lt;code&gt;K-Means&lt;/code&gt;算法不用指定&lt;code&gt;K&lt;/code&gt;的个数，可以自动的通过求解一个向量，使得圆心一直往数据集密度最大的方向移动。说的再简单一点，就是每次迭代的时候，都是找到圆里面点的平均位置作为新的圆心位置。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;可参考：&lt;a href=&quot;https://blog.csdn.net/hjimce/article/details/45718593&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;机器学习（十）Mean Shift 聚类算法&lt;/a&gt;、&lt;br&gt;&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E7%88%AC%E5%B1%B1%E7%AE%97%E6%B3%95&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;爬山算法&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在原作者的原代码上进行一些符合当今实际情况的修改。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：K-均值算法(K-Means)的实现及应用</title>
    <link href="https://liujunjie11.github.io/2018/10/26/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9AK-%E5%9D%87%E5%80%BC%E7%AE%97%E6%B3%95(K-Means)%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%BA%94%E7%94%A8/"/>
    <id>https://liujunjie11.github.io/2018/10/26/python机器学习系列：K-均值算法(K-Means)的实现及应用/</id>
    <published>2018-10-26T13:22:11.000Z</published>
    <updated>2019-01-02T06:49:35.141Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/ZueoXMgCd1c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><ul><li>对应的课程地址：<a href="https://pythonprogramming.net/machine-learning-clustering-introduction-machine-learning-tutorial/?completed=/support-vector-machine-parameters-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/machine-learning-clustering-introduction-machine-learning-tutorial/?completed=/support-vector-machine-parameters-machine-learning-tutorial/</a></li></ul><p>K-均值算法(K-Means)属于无监督学习、聚类算法。即将无标签的数据集进行分类，并且无训练过程(监督学习的数据集才存在训练一说)等，又可理解为<code>自动分类器</code>。</p><p>本文对于原作者的代码进行了一点修改以符合当今情况。</p><a id="more"></a><h1 id="K-均值算法-K-Means-的实现"><a href="#K-均值算法-K-Means-的实现" class="headerlink" title="K-均值算法(K-Means)的实现"></a>K-均值算法(K-Means)的实现</h1><p>这个算法不算是很难理解，实际上很容易理解，在此就不多废话了。</p><p>简单说说等下代码实现的思想原理以及相关的需要注意的一些东西。关于这个实现的过程中，会想从前一样，使用自制的数据集样本，在其中会选择两个作为最初的中心点(亦可通过洗牌后进行选择)，然后将剩下的数据集与这两个中心点进行计算，通过得出的距离大小使得离得哪个中心点近就归属于那个中心点的分类处(非0即1的分类)，接着会从这些已经各就各位的点中得出平均点。我们会设置一个最大迭代次数以及一个固定公差数(迭代次数在此不够严谨，仅仅起到学习认知的作用)，关于这个公差数是起到一个监督的作用，若是在未得出平均点之前的数据点与中心点之间的公差数值大于固定公差数阈值，就说明优化失败了，之后这次的优化就忽略，直接进行下一次的优化过程(得出最佳平均点就是一次又一次优化的过程，最终目标就是得出最佳的平均点，最具代表性的点)。最终我们会通过数据可视化来进行图表结果的展示。</p><p>以下是实现代码。</p><h2 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"> 自制训练数据集</div><div class="line">X = np.array([[<span class="number">1</span>,<span class="number">2</span>],</div><div class="line">             [<span class="number">1.5</span>,<span class="number">1.8</span>],</div><div class="line">             [<span class="number">5</span>,<span class="number">8</span>],</div><div class="line">             [<span class="number">8</span>,<span class="number">8</span>],</div><div class="line">             [<span class="number">1</span>,<span class="number">0.6</span>],</div><div class="line">             [<span class="number">9</span>,<span class="number">11</span>],</div><div class="line">             [<span class="number">1</span>,<span class="number">3</span>],</div><div class="line">             [<span class="number">8</span>,<span class="number">9</span>],</div><div class="line">             [<span class="number">0</span>,<span class="number">3</span>],</div><div class="line">             [<span class="number">5</span>,<span class="number">4</span>],</div><div class="line">             [<span class="number">6</span>,<span class="number">4</span>]])</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">K_Means</span><span class="params">()</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, k=<span class="number">2</span>, tol=<span class="number">0.001</span>, max_iter=<span class="number">300</span>)</span>:</span></div><div class="line">        self.k = k</div><div class="line">        self.tol = tol</div><div class="line">        self.max_iter = max_iter <span class="comment">#最大迭代次数</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></div><div class="line">        </div><div class="line">        self.centroids = &#123;&#125; <span class="comment">#质点圆心</span></div><div class="line">        </div><div class="line">        <span class="comment">#取两个作为中心点</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.k):</div><div class="line">            self.centroids[i] = data[i]</div><div class="line">            </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.max_iter):</div><div class="line">            self.classifications = &#123;&#125;</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(self.k):</div><div class="line">                self.classifications[i] = []</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> data:</div><div class="line">                <span class="comment">#计算点与点之间的距离,分配数据集进入各自合适的阵营</span></div><div class="line">                distances = [np.linalg.norm(featureset-self.centroids[centroid]) <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids]</div><div class="line">                classification = distances.index(min(distances)) <span class="comment">#取最小的距离索引位置点</span></div><div class="line">                self.classifications[classification].append(featureset)</div><div class="line">        </div><div class="line">            prev_centroids = dict(self.centroids) <span class="comment">#保留现在的原数据，之后计算公差要用到</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> classification <span class="keyword">in</span> self.classifications:</div><div class="line">                <span class="comment">#得出平均点</span></div><div class="line">                self.centroids[classification] = np.average(self.classifications[classification], axis=<span class="number">0</span>)</div><div class="line">            </div><div class="line">            optimized = <span class="keyword">True</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> self.centroids:</div><div class="line">                original_centroid = prev_centroids[c]</div><div class="line">                current_centroid = self.centroids[c]</div><div class="line">                <span class="keyword">if</span> np.sum((current_centroid - original_centroid)/original_centroid*<span class="number">100.0</span>) &gt; self.tol:</div><div class="line">                    print(np.sum((current_centroid - original_centroid)/original_centroid*<span class="number">100</span>))</div><div class="line">                    optimized = <span class="keyword">False</span></div><div class="line">                </div><div class="line">            <span class="keyword">if</span> optimized:</div><div class="line">                <span class="keyword">break</span></div><div class="line">                </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, data)</span>:</span></div><div class="line">        <span class="comment">#代入数据集与圆心点进行距离计算，并且进行分类0/1</span></div><div class="line">        distances = [np.linalg.norm(data-self.centroids[centroid]) <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids]</div><div class="line">        classification = distances.index(min(distances)) </div><div class="line">        <span class="keyword">return</span> classification</div></pre></td></tr></table></figure><p>下面是训练过程以及图表展示相关的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">colors = [<span class="string">'g'</span>, <span class="string">'r'</span>, <span class="string">'c'</span>, <span class="string">'b'</span>, <span class="string">'k'</span>] </div><div class="line"></div><div class="line">clf = K_Means()</div><div class="line">clf.fit(X)</div><div class="line"></div><div class="line"><span class="comment"># 可视化中心原点</span></div><div class="line"><span class="keyword">for</span> centroid <span class="keyword">in</span> clf.centroids:</div><div class="line">    plt.scatter(clf.centroids[centroid][<span class="number">0</span>], clf.centroids[centroid][<span class="number">1</span>], marker=<span class="string">'o'</span>, color=<span class="string">'k'</span>, s=<span class="number">150</span>, linewidths=<span class="number">5</span>)</div><div class="line"></div><div class="line"><span class="comment">#可视化已分类好的各就各位的点</span></div><div class="line"><span class="keyword">for</span> classification <span class="keyword">in</span> clf.classifications:</div><div class="line">    color = colors[classification]</div><div class="line">    <span class="keyword">for</span> featrueset <span class="keyword">in</span> clf.classifications[classification]:</div><div class="line">        plt.scatter(featrueset[<span class="number">0</span>], featrueset[<span class="number">1</span>], marker=<span class="string">'x'</span>, color=color, s=<span class="number">150</span>, linewidths=<span class="number">5</span>)</div><div class="line"></div><div class="line">plt.show()</div></pre></td></tr></table></figure><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="comment"># 自制训练数据集</span></div><div class="line">X = np.array([[<span class="number">1</span>,<span class="number">2</span>],</div><div class="line">             [<span class="number">1.5</span>,<span class="number">1.8</span>],</div><div class="line">             [<span class="number">5</span>,<span class="number">8</span>],</div><div class="line">             [<span class="number">8</span>,<span class="number">8</span>],</div><div class="line">             [<span class="number">1</span>,<span class="number">0.6</span>],</div><div class="line">             [<span class="number">9</span>,<span class="number">11</span>],</div><div class="line">             [<span class="number">1</span>,<span class="number">3</span>],</div><div class="line">             [<span class="number">8</span>,<span class="number">9</span>],</div><div class="line">             [<span class="number">0</span>,<span class="number">3</span>],</div><div class="line">             [<span class="number">5</span>,<span class="number">4</span>],</div><div class="line">             [<span class="number">6</span>,<span class="number">4</span>]])</div><div class="line"></div><div class="line">colors = [<span class="string">'g'</span>, <span class="string">'r'</span>, <span class="string">'c'</span>, <span class="string">'b'</span>, <span class="string">'k'</span>] </div><div class="line">print(colors)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">K_Means</span><span class="params">()</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, k=<span class="number">2</span>, tol=<span class="number">0.001</span>, max_iter=<span class="number">300</span>)</span>:</span></div><div class="line">        self.k = k</div><div class="line">        self.tol = tol</div><div class="line">        self.max_iter = max_iter <span class="comment">#最大迭代次数</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></div><div class="line">        </div><div class="line">        self.centroids = &#123;&#125; <span class="comment">#质点圆心</span></div><div class="line">        </div><div class="line">        <span class="comment">#取两个作为中心点</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.k):</div><div class="line">            self.centroids[i] = data[i]</div><div class="line">            </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.max_iter):</div><div class="line">            self.classifications = &#123;&#125;</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(self.k):</div><div class="line">                self.classifications[i] = []</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> data:</div><div class="line">                <span class="comment">#计算点与点之间的距离,分配数据集进入各自合适的阵营</span></div><div class="line">                distances = [np.linalg.norm(featureset-self.centroids[centroid]) <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids]</div><div class="line">                classification = distances.index(min(distances)) <span class="comment">#取最小的距离索引位置点</span></div><div class="line">                self.classifications[classification].append(featureset)</div><div class="line">        </div><div class="line">            prev_centroids = dict(self.centroids) <span class="comment">#保留现在的原数据，之后计算公差要用到</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> classification <span class="keyword">in</span> self.classifications:</div><div class="line">                <span class="comment">#得出平均点</span></div><div class="line">                self.centroids[classification] = np.average(self.classifications[classification], axis=<span class="number">0</span>)</div><div class="line">            </div><div class="line">            optimized = <span class="keyword">True</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> self.centroids:</div><div class="line">                original_centroid = prev_centroids[c]</div><div class="line">                current_centroid = self.centroids[c]</div><div class="line">                <span class="keyword">if</span> np.sum((current_centroid - original_centroid)/original_centroid*<span class="number">100.0</span>) &gt; self.tol:</div><div class="line">                    print(np.sum((current_centroid - original_centroid)/original_centroid*<span class="number">100</span>))</div><div class="line">                    optimized = <span class="keyword">False</span></div><div class="line">                </div><div class="line">            <span class="keyword">if</span> optimized:</div><div class="line">                <span class="keyword">break</span></div><div class="line">                </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, data)</span>:</span></div><div class="line">        <span class="comment">#代入数据集与圆心点进行距离计算，并且进行分类0/1</span></div><div class="line">        distances = [np.linalg.norm(data-self.centroids[centroid]) <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids]</div><div class="line">        classification = distances.index(min(distances)) </div><div class="line">        <span class="keyword">return</span> classification</div><div class="line">            </div><div class="line"></div><div class="line">clf = K_Means()</div><div class="line">clf.fit(X)</div><div class="line"></div><div class="line"><span class="comment"># 可视化中心原点</span></div><div class="line"><span class="keyword">for</span> centroid <span class="keyword">in</span> clf.centroids:</div><div class="line">    plt.scatter(clf.centroids[centroid][<span class="number">0</span>], clf.centroids[centroid][<span class="number">1</span>], marker=<span class="string">'o'</span>, color=<span class="string">'k'</span>, s=<span class="number">150</span>, linewidths=<span class="number">5</span>)</div><div class="line"></div><div class="line"><span class="comment">#可视化已分类好的各就各位的点</span></div><div class="line"><span class="keyword">for</span> classification <span class="keyword">in</span> clf.classifications:</div><div class="line">    color = colors[classification]</div><div class="line">    <span class="keyword">for</span> featrueset <span class="keyword">in</span> clf.classifications[classification]:</div><div class="line">        plt.scatter(featrueset[<span class="number">0</span>], featrueset[<span class="number">1</span>], marker=<span class="string">'x'</span>, color=color, s=<span class="number">150</span>, linewidths=<span class="number">5</span>)</div><div class="line"></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>铺助理解链接：</p><ul><li><p><a href="https://cloud.tencent.com/developer/ask/42899" target="_blank" rel="external">np.mean()和Python NumPy中的np.average()有什么区别？</a></p></li><li><p><a href="https://blog.csdn.net/JohinieLi/article/details/78350999" target="_blank" rel="external">关于numpy mean函数的axis参数</a></p></li><li><p><a href="https://matplotlib.org/2.1.1/api/_as_gen/matplotlib.pyplot.plot.html" target="_blank" rel="external">matplotlib.pyplot.plot</a></p></li><li><p><a href="https://www.cnblogs.com/zsr0401/p/6405677.html" target="_blank" rel="external">Python-Matplotlib 9 颜色和样式</a></p></li></ul><h2 id="展示结果"><a href="#展示结果" class="headerlink" title="展示结果"></a>展示结果</h2><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-30%20%E4%B8%8B%E5%8D%889.32.06.png" alt=""></p><blockquote><p>这样在这里就完成了实现的过程。这个算法真的不怎么难，至少相较于上次的<code>SVM</code>来说。</p></blockquote><h1 id="项目应用"><a href="#项目应用" class="headerlink" title="项目应用"></a>项目应用</h1><h2 id="sklearn的K-Means模型训练"><a href="#sklearn的K-Means模型训练" class="headerlink" title="sklearn的K-Means模型训练"></a>sklearn的K-Means模型训练</h2><p>这次用到的数据是再熟悉不过的<code>titanic</code>数据集，就是预测生死的那个<code>kaggle</code>入门级比赛的那个，哈哈。</p><blockquote><p>数据地址：<a href="https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls" target="_blank" rel="external">https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls</a></p></blockquote><p>在利用这个数据时，先将数据集进行简单的数据预处理，以及将非数值数据进行简单的数值转换(即将非数值型数值转换为数值型数据)，之后代入现成的<code>sklearn</code>对应的K-Means模型进行训练，最后得出预测准确性。</p><p>下面是代码实现部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">df = pd.read_excel(<span class="string">'titanic.xls'</span>)</div><div class="line"></div><div class="line"><span class="comment">#简单的数据预处理</span></div><div class="line">df.drop([<span class="string">'body'</span>,<span class="string">'name'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">df.fillna(<span class="number">0</span>, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment">#处理非数值数据</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_non_numerical_data</span><span class="params">(df)</span>:</span></div><div class="line">    columns = df.columns.values</div><div class="line">    </div><div class="line">    <span class="keyword">for</span> column <span class="keyword">in</span> columns: <span class="comment">#取出各个列名作为遍历的基调</span></div><div class="line">        text_digit_vals = &#123;&#125;</div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">convert_to_int</span><span class="params">(val)</span>:</span></div><div class="line">            <span class="keyword">return</span> text_digit_vals[val]</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> df[column].dtype != np.int64 <span class="keyword">and</span> df[column].dtype != np.float64:</div><div class="line">            column_contents = df[column].values.tolist() <span class="comment">#转换为列表类型以便下方处理</span></div><div class="line">            unique_elements = set(column_contents) <span class="comment">#去掉重复值</span></div><div class="line">            x = <span class="number">0</span></div><div class="line">            <span class="keyword">for</span> unique <span class="keyword">in</span> unique_elements:</div><div class="line">                <span class="keyword">if</span> unique <span class="keyword">not</span> <span class="keyword">in</span> text_digit_vals:</div><div class="line">                    text_digit_vals[unique] = x <span class="comment">#即在此将非数值的数据改为了数值型数据集</span></div><div class="line">                    x+=<span class="number">1</span></div><div class="line">                    </div><div class="line">            df[column] = list(map(convert_to_int, df[column])) <span class="comment">#将列名替代掉上面的unique非数值列名</span></div><div class="line">            </div><div class="line">    <span class="keyword">return</span> df</div><div class="line"></div><div class="line">df = handle_non_numerical_data(df)</div><div class="line"></div><div class="line">df.drop([<span class="string">'sex'</span>,<span class="string">'boat'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">X = np.array(df.drop([<span class="string">'survived'</span>], <span class="number">1</span>).astype(float))</div><div class="line">X = preprocessing.scale(X) <span class="comment">#进行缩放，标准化</span></div><div class="line">y = np.array(df[<span class="string">'survived'</span>])</div><div class="line"></div><div class="line">clf = KMeans(n_clusters=<span class="number">2</span>) <span class="comment">#得出0/1</span></div><div class="line">clf.fit(X)</div><div class="line"></div><div class="line">correct = <span class="number">0</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</div><div class="line">    predict_me = np.array(X[i].astype(float))</div><div class="line">    predict_me = predict_me.reshape(<span class="number">-1</span>, len(predict_me)) <span class="comment">#得出每排的数据集</span></div><div class="line">    prediction = clf.predict(predict_me)</div><div class="line">    <span class="keyword">if</span> prediction[<span class="number">0</span>] == y[i]: </div><div class="line">        correct += <span class="number">1</span></div><div class="line">        </div><div class="line">print(correct/len(X))</div></pre></td></tr></table></figure><p>铺助理解链接：</p><ul><li><p><a href="http://sklearn.apachecn.org/cn/stable/index.html" target="_blank" rel="external">sklearn中文主页</a></p></li><li><p><a href="http://www.runoob.com/python/python-func-map.html" target="_blank" rel="external">Python map() 函数</a></p></li><li><p><a href="https://blog.csdn.net/Dream_angel_Z/article/details/49406573" target="_blank" rel="external">Scikit-learn Preprocessing 预处理</a></p></li><li><p><a href="https://blog.csdn.net/nuaadot/article/details/78304642" target="_blank" rel="external">python进行数据处理——pandas的drop函数</a></p></li></ul><p>下面是得出的结果：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-30%20%E4%B8%8B%E5%8D%8810.04.28.png" alt=""></p><blockquote><p>由于数据简单的预处理了一下，所以准确性在0.3～0.7之间。</p></blockquote><h2 id="sklearn的K-Means模型自制数据集训练"><a href="#sklearn的K-Means模型自制数据集训练" class="headerlink" title="sklearn的K-Means模型自制数据集训练"></a>sklearn的K-Means模型自制数据集训练</h2><p>这是用自制的数据集进行的模型训练，最后将结果进行图表展示，可以更好的理解这个在<code>sklearn</code>模块中的现成<code>K-Means</code>模型的运作情况。</p><p>以下是相关的代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">X = np.array([[<span class="number">1</span>,<span class="number">2</span>],</div><div class="line">             [<span class="number">1.5</span>,<span class="number">1.8</span>],</div><div class="line">             [<span class="number">5</span>,<span class="number">8</span>],</div><div class="line">             [<span class="number">8</span>,<span class="number">8</span>],</div><div class="line">             [<span class="number">1</span>,<span class="number">0.6</span>],</div><div class="line">             [<span class="number">9</span>,<span class="number">11</span>]])</div><div class="line"></div><div class="line">clf = KMeans(n_clusters=<span class="number">2</span>) <span class="comment">#聚点设置，必须小于数据集的长度</span></div><div class="line">clf.fit(X)</div><div class="line"></div><div class="line">centroids = clf.cluster_centers_ <span class="comment">#聚类中心坐标</span></div><div class="line">labels = clf.labels_ <span class="comment">#标签</span></div><div class="line"></div><div class="line">colors = [<span class="string">'g.'</span>,<span class="string">'r.'</span>,<span class="string">'c.'</span>,<span class="string">'b.'</span>] <span class="comment">#点加颜色配合</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</div><div class="line">    plt.plot(X[i][<span class="number">0</span>], X[i][<span class="number">1</span>], colors[labels[i]], markersize = <span class="number">25</span>)</div><div class="line"></div><div class="line">plt.scatter(centroids[:,<span class="number">0</span>], centroids[:,<span class="number">1</span>], marker=<span class="string">'x'</span>, s=<span class="number">150</span>, linewidths=<span class="number">5</span>) </div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>结果图表展示：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-30%20%E4%B8%8B%E5%8D%889.51.36.png" alt=""></p><blockquote><p>还是不错的，有助于理解学习。</p></blockquote><h2 id="用手动实现的K-Means算法训练数据集"><a href="#用手动实现的K-Means算法训练数据集" class="headerlink" title="用手动实现的K-Means算法训练数据集"></a>用手动实现的K-Means算法训练数据集</h2><p>在此将要使用上面实现的K-Means算法来训练上面的<code>titanic</code>数据集，将会输出预测准确性。</p><p>下面是实现的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">K_Means</span><span class="params">()</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, k=<span class="number">2</span>, tol=<span class="number">0.001</span>, max_iter=<span class="number">300</span>)</span>:</span></div><div class="line">        self.k = k</div><div class="line">        self.tol = tol</div><div class="line">        self.max_iter = max_iter <span class="comment">#最大迭代次数</span></div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></div><div class="line">        </div><div class="line">        self.centroids = &#123;&#125; <span class="comment">#质点圆心</span></div><div class="line">        </div><div class="line">        <span class="comment">#取两个作为中心点</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.k):</div><div class="line">            self.centroids[i] = data[i]</div><div class="line">            </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.max_iter):</div><div class="line">            self.classifications = &#123;&#125;</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(self.k):</div><div class="line">                self.classifications[i] = []</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> data:</div><div class="line">                <span class="comment">#计算点与点之间的距离,分配数据集进入各自合适的阵营</span></div><div class="line">                distances = [np.linalg.norm(featureset-self.centroids[centroid]) <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids]</div><div class="line">                classification = distances.index(min(distances)) <span class="comment">#取最小的距离索引位置点</span></div><div class="line">                self.classifications[classification].append(featureset)</div><div class="line">        </div><div class="line">            prev_centroids = dict(self.centroids) <span class="comment">#保留现在的原数据，之后计算公差要用到</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> classification <span class="keyword">in</span> self.classifications:</div><div class="line">                <span class="comment">#得出平均点</span></div><div class="line">                self.centroids[classification] = np.average(self.classifications[classification], axis=<span class="number">0</span>)</div><div class="line">            </div><div class="line">            optimized = <span class="keyword">True</span></div><div class="line">            </div><div class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> self.centroids:</div><div class="line">                original_centroid = prev_centroids[c]</div><div class="line">                current_centroid = self.centroids[c]</div><div class="line">                <span class="keyword">if</span> np.sum((current_centroid - original_centroid)/original_centroid*<span class="number">100.0</span>) &gt; self.tol:</div><div class="line">                    print(np.sum((current_centroid - original_centroid)/original_centroid*<span class="number">100</span>))</div><div class="line">                    optimized = <span class="keyword">False</span></div><div class="line">                </div><div class="line">            <span class="keyword">if</span> optimized:</div><div class="line">                <span class="keyword">break</span></div><div class="line">                </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, data)</span>:</span></div><div class="line">        <span class="comment">#代入数据集与圆心点进行距离计算，并且进行分类0/1</span></div><div class="line">        distances = [np.linalg.norm(data-self.centroids[centroid]) <span class="keyword">for</span> centroid <span class="keyword">in</span> self.centroids]</div><div class="line">        classification = distances.index(min(distances)) </div><div class="line">        <span class="keyword">return</span> classification</div><div class="line"></div><div class="line">df = pd.read_excel(<span class="string">'titanic.xls'</span>)</div><div class="line"></div><div class="line"><span class="comment">#简单的数据预处理</span></div><div class="line">df.drop([<span class="string">'body'</span>,<span class="string">'name'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">df.fillna(<span class="number">0</span>, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment">#处理非数值数据</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_non_numerical_data</span><span class="params">(df)</span>:</span></div><div class="line">    columns = df.columns.values</div><div class="line">    </div><div class="line">    <span class="keyword">for</span> column <span class="keyword">in</span> columns: <span class="comment">#取出各个列名作为遍历的基调</span></div><div class="line">        text_digit_vals = &#123;&#125;</div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">convert_to_int</span><span class="params">(val)</span>:</span></div><div class="line">            <span class="keyword">return</span> text_digit_vals[val]</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> df[column].dtype != np.int64 <span class="keyword">and</span> df[column].dtype != np.float64:</div><div class="line">            column_contents = df[column].values.tolist() <span class="comment">#转换为列表类型以便下方处理</span></div><div class="line">            unique_elements = set(column_contents) <span class="comment">#去掉重复值</span></div><div class="line">            x = <span class="number">0</span></div><div class="line">            <span class="keyword">for</span> unique <span class="keyword">in</span> unique_elements:</div><div class="line">                <span class="keyword">if</span> unique <span class="keyword">not</span> <span class="keyword">in</span> text_digit_vals:</div><div class="line">                    text_digit_vals[unique] = x <span class="comment">#即在此将非数值的数据改为了数值型数据集</span></div><div class="line">                    x+=<span class="number">1</span></div><div class="line">                    </div><div class="line">            df[column] = list(map(convert_to_int, df[column])) <span class="comment">#将列名替代掉上面的unique非数值列名</span></div><div class="line">            </div><div class="line">    <span class="keyword">return</span> df</div><div class="line"></div><div class="line">df = handle_non_numerical_data(df)</div><div class="line"></div><div class="line">df.drop([<span class="string">'sex'</span>,<span class="string">'boat'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">X = np.array(df.drop([<span class="string">'survived'</span>], <span class="number">1</span>).astype(float))</div><div class="line">X = preprocessing.scale(X) <span class="comment">#进行缩放，标准化</span></div><div class="line">y = np.array(df[<span class="string">'survived'</span>])</div><div class="line"></div><div class="line">clf = K_Means()</div><div class="line">clf.fit(X)</div><div class="line"></div><div class="line">correct = <span class="number">0</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</div><div class="line">    predic_me = np.array(X[i].astype(float))</div><div class="line">    predic_me = predic_me.reshape(<span class="number">-1</span>, len(predic_me))</div><div class="line">    prediction = clf.predict(predic_me)</div><div class="line">    <span class="keyword">if</span> prediction == y[i]:</div><div class="line">        correct += <span class="number">1</span></div><div class="line"></div><div class="line">print(correct/len(X))</div></pre></td></tr></table></figure><p>只是上面代码的连接罢了，代码本身也不难理解。</p><p>下面是输出的预测准确性：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-30%20%E4%B8%8B%E5%8D%889.31.38.png" alt=""></p><blockquote><p>额…效果不咋地…</p></blockquote><p>这样一来这篇文章可以接近尾声了…不懂的地方可以去对应的课程去看看，还有的是，多看书，利用好搜索引擎。</p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/ZueoXMgCd1c&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;ul&gt;
&lt;li&gt;对应的课程地址：&lt;a href=&quot;https://pythonprogramming.net/machine-learning-clustering-introduction-machine-learning-tutorial/?completed=/support-vector-machine-parameters-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://pythonprogramming.net/machine-learning-clustering-introduction-machine-learning-tutorial/?completed=/support-vector-machine-parameters-machine-learning-tutorial/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;K-均值算法(K-Means)属于无监督学习、聚类算法。即将无标签的数据集进行分类，并且无训练过程(监督学习的数据集才存在训练一说)等，又可理解为&lt;code&gt;自动分类器&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;本文对于原作者的代码进行了一点修改以符合当今情况。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>关于在Mac下的python文字转语音库pyttsx3</title>
    <link href="https://liujunjie11.github.io/2018/10/23/%E5%85%B3%E4%BA%8E%E5%9C%A8Mac%E4%B8%8B%E7%9A%84python%E6%96%87%E5%AD%97%E8%BD%AC%E8%AF%AD%E9%9F%B3%E5%BA%93pyttsx3/"/>
    <id>https://liujunjie11.github.io/2018/10/23/关于在Mac下的python文字转语音库pyttsx3/</id>
    <published>2018-10-23T13:29:17.000Z</published>
    <updated>2019-01-02T06:49:44.883Z</updated>
    
    <content type="html"><![CDATA[<p>最近写python机器学习教程有点累了..就玩一些其他的东西，就包括了这个文字转语音的python3库<em>pyttsx3</em>。</p><p>其中也遇到了一些问题，在此记录一下。</p><a id="more"></a><h1 id="关于下载运行的问题"><a href="#关于下载运行的问题" class="headerlink" title="关于下载运行的问题"></a>关于下载运行的问题</h1><p>在使用命令行<code>pip install pyttsx3</code>下载之后，我在终端写下了如下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pyttsx3</div><div class="line">engine = pyttsx3.init()</div></pre></td></tr></table></figure><p>结果出现了<code>No module named &#39;Foundation&#39;</code>的错误问题。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>下载模块<code>pyobjc</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install pyobjc</div></pre></td></tr></table></figure><p>估计是跟调用系统一些模块有关，毕竟这个库是跟macOS关系还是挺深的…自行了解，没想到这个库可以调用Objective-C的库来进行macOS上的应用程序开发…</p><p>以下是WiKi的解释：</p><blockquote><p>PyObjC是Python和Objective-C编程语言之间的双向桥梁，允许程序员使用Python扩展现有的Objective-C库，例如Apple的Cocoa框架。 PyObjC用于在纯Python中开发macOS应用程序。 对GNUstep的支持也很有限，GNUstep是Cocoa的开源，跨平台实现。</p></blockquote><p>下载完成这个库之后，再运行上面的代码就没有出错了。</p><ul><li>参考链接：<a href="https://blog.csdn.net/noway5456/article/details/78905275" target="_blank" rel="external">https://blog.csdn.net/noway5456/article/details/78905275</a></li></ul><h1 id="关于pyttsx3读中文字的问题"><a href="#关于pyttsx3读中文字的问题" class="headerlink" title="关于pyttsx3读中文字的问题"></a>关于pyttsx3读中文字的问题</h1><p>这个问题其实是跟系统的语音设置相关的，看下图吧。</p><p>我在系统默认的语音类型(在图中两者之间切换)：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-23%20%E4%B8%8B%E5%8D%889.24.59.png" alt=""></p><p>然后又用代码查看<em>pyttsx3</em>的对应默认声音：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-23%20%E4%B8%8B%E5%8D%889.24.30.png" alt=""></p><p>发现了其实pyttsx3的语音是根据本地语音相关的，这又一步说明为何要安装<code>pyobjc</code>这个铺助模块的意义。</p><p>在读取英文或中文时，设置一下本地的默认语音即可。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近写python机器学习教程有点累了..就玩一些其他的东西，就包括了这个文字转语音的python3库&lt;em&gt;pyttsx3&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;其中也遇到了一些问题，在此记录一下。&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://liujunjie11.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
      <category term="问题记录笔记" scheme="https://liujunjie11.github.io/tags/%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Pyttsx3" scheme="https://liujunjie11.github.io/tags/Pyttsx3/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：支持向量机(SVM)的应用以及实现</title>
    <link href="https://liujunjie11.github.io/2018/10/23/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9A%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM-%E7%9A%84%E5%BA%94%E7%94%A8%E4%BB%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0/"/>
    <id>https://liujunjie11.github.io/2018/10/23/python机器学习系列：支持向量机-SVM-的应用以及实现/</id>
    <published>2018-10-23T01:44:10.000Z</published>
    <updated>2019-01-02T06:49:54.496Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/HHUqhVzctQE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>我记录下的这些东西，如果是有哪些不懂得地方，我强烈建议参考我在<a href="http://liujunworld.com/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/" target="_blank" rel="external">这里的书籍</a>。另外还有<a href="https://github.com/apachecn/AiLearning" target="_blank" rel="external">《机器学习实战》</a>，<a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">《深度学习》</a>这本花书等，利用好搜索引擎也是一大好利器。</p><p>关于这篇文章，我还是和以前记录相关的机器学习知识之类篇章一样的风格。</p><p>不懂可进入<a href="https://pythonprogramming.net/support-vector-machine-intro-machine-learning-tutorial/?completed=/final-thoughts-knn-machine-learning-tutorial/" target="_blank" rel="external">这里的对应的教程</a>，看不懂可借助翻译插件/软件(实际上借助这些看起来轻松多了，看英文头疼的厉害，如果是对于初学者)。</p><a id="more"></a><h1 id="SVM的实现"><a href="#SVM的实现" class="headerlink" title="SVM的实现"></a>SVM的实现</h1><p>SVM算法是有一点难理解的，但是坚持看一些文章和上面说的那些书籍之后就会发现其实也就那么回事。</p><p>关于SVM的实现(仅作通俗说明，以二维为例)：由于这个算法是根据支持向量得出两个函数，而我们取的是这两条线性函数的距离的中间值，从而得到了决策边界函数，这样任务也就完成了。但是由于参数的不同，取这个决策边界是可以有多个甚至是无穷个的，那么取得最优的参数是可以利用梯度下降算法的(符合凸二次规划)。得到了最优的参数就可以得出决策边界的函数了。</p><blockquote><p>涉及到不少的数学知识…我想我大概是说对了吧，哈哈…</p></blockquote><p>为了实现这个算法，必须要提前了解这算法相关的知识，不然真的是寸步难行啊。</p><p>下面是铺助理解链接，不懂还要翻书看吴恩达老师的教程：</p><ul><li><p><a href="https://zh.wikipedia.org/wiki/二次规划" target="_blank" rel="external">二次规划</a></p></li><li><p><a href="http://www.sohu.com/a/206572358_160850" target="_blank" rel="external">干货 | 从超平面到SVM（一）</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/26514613" target="_blank" rel="external">浅谈最优化问题的KKT条件</a></p></li></ul><p>以下就是完整的实现代码了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Support_Vector_Machine</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, visualization=True)</span>:</span></div><div class="line">        self.visualization = visualization</div><div class="line">        self.colors = &#123;<span class="number">1</span>:<span class="string">'r'</span>, <span class="number">-1</span>:<span class="string">'b'</span>&#125;</div><div class="line">        <span class="keyword">if</span> self.visualization:</div><div class="line">            self.fig = plt.figure()</div><div class="line">            self.ax = self.fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></div><div class="line">        self.data = data</div><div class="line">        opt_dict = &#123;&#125;</div><div class="line">        </div><div class="line">        transforms = [[<span class="number">1</span>,<span class="number">1</span>],</div><div class="line">                      [<span class="number">-1</span>,<span class="number">1</span>],</div><div class="line">                      [<span class="number">-1</span>,<span class="number">-1</span>],</div><div class="line">                      [<span class="number">1</span>,<span class="number">-1</span>]]</div><div class="line">        </div><div class="line">        all_data = []</div><div class="line">        <span class="keyword">for</span> yi <span class="keyword">in</span> self.data:</div><div class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> self.data[yi]:</div><div class="line">                <span class="keyword">for</span> feature <span class="keyword">in</span> featureset:</div><div class="line">                    all_data.append(feature)</div><div class="line">        </div><div class="line">        self.max_feature_value = max(all_data)</div><div class="line">        self.min_feature_value = min(all_data)</div><div class="line">        all_data = <span class="keyword">None</span></div><div class="line">        </div><div class="line">        <span class="comment">#指定梯度下降的步子大小</span></div><div class="line">        step_sizes = [self.max_feature_value * <span class="number">0.1</span>,</div><div class="line">                      self.max_feature_value * <span class="number">0.01</span>,</div><div class="line">                      self.max_feature_value * <span class="number">0.001</span>,]</div><div class="line">        </div><div class="line">        <span class="comment">#b的假设大小，最为重要的是参数w，而不是参数b </span></div><div class="line">        b_range_multiple = <span class="number">2</span></div><div class="line">        b_multiple =<span class="number">5</span></div><div class="line">        latest_optimum = self.max_feature_value*<span class="number">10</span> <span class="comment">#最大的步子</span></div><div class="line">        </div><div class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> step_sizes:</div><div class="line">            w = np.array([latest_optimum, latest_optimum])</div><div class="line">            optimized = <span class="keyword">False</span></div><div class="line">            <span class="keyword">while</span> <span class="keyword">not</span> optimized:</div><div class="line">                <span class="keyword">for</span> b <span class="keyword">in</span> np.arange(<span class="number">-1</span>*(self.max_feature_value * b_range_multiple),</div><div class="line">                                   self.max_feature_value * b_range_multiple,</div><div class="line">                                   step * b_multiple):</div><div class="line">                    <span class="keyword">for</span> transformation <span class="keyword">in</span> transforms:</div><div class="line">                        w_t = w*transformation</div><div class="line">                        found_option = <span class="keyword">True</span></div><div class="line">                        </div><div class="line">                        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</div><div class="line">                            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</div><div class="line">                                yi = i</div><div class="line">                                <span class="keyword">if</span> <span class="keyword">not</span> yi*(np.dot(w_t, xi)+b) &gt;= <span class="number">1</span>:</div><div class="line">                                    found_option = <span class="keyword">False</span></div><div class="line">                        </div><div class="line">                        <span class="comment">#如果约束优化条件成立</span></div><div class="line">                        <span class="keyword">if</span> found_option:</div><div class="line">                            opt_dict[np.linalg.norm(w_t)] = [w_t, b]</div><div class="line">                </div><div class="line">                <span class="comment">#若是值为负数则停止进一步的优化步子</span></div><div class="line">                <span class="keyword">if</span> w[<span class="number">0</span>] &lt;<span class="number">0</span>:</div><div class="line">                    optimized = <span class="keyword">True</span></div><div class="line">                    print(<span class="string">'Optimized a step.'</span>)</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    w = w - step</div><div class="line">            norms = sorted([n <span class="keyword">for</span> n <span class="keyword">in</span> opt_dict])</div><div class="line">            </div><div class="line">            opt_choice = opt_dict[norms[<span class="number">0</span>]]</div><div class="line">            self.w = opt_choice[<span class="number">0</span>]</div><div class="line">            self.b = opt_choice[<span class="number">1</span>]</div><div class="line">            latest_optimum = opt_choice[<span class="number">0</span>][<span class="number">0</span>]+step*<span class="number">2</span></div><div class="line">            </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</div><div class="line">            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</div><div class="line">                yi = i</div><div class="line">                print(xi, <span class="string">':'</span>, yi*(np.dot(self.w, xi)+self.b))</div><div class="line">            </div><div class="line">    <span class="comment">#预测部分</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, features)</span>:</span></div><div class="line">        classification = np.sign(np.dot(np.array(features), self.w)+self.b)</div><div class="line">        <span class="keyword">if</span> classification != <span class="number">0</span> <span class="keyword">and</span> self.visualization:</div><div class="line">            self.ax.scatter(features[<span class="number">0</span>], features[<span class="number">1</span>], s=<span class="number">200</span>, marker=<span class="string">'*'</span>, c=self.colors[classification])</div><div class="line">        </div><div class="line">        <span class="keyword">return</span> classification</div><div class="line">    </div><div class="line">    <span class="comment">#可视化部分</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(self)</span>:</span></div><div class="line">        [[self.ax.scatter(x[<span class="number">0</span>], x[<span class="number">1</span>], s=<span class="number">100</span>, color=self.colors[i]) <span class="keyword">for</span> x <span class="keyword">in</span> data_dict[i]] <span class="keyword">for</span> i <span class="keyword">in</span> data_dict]</div><div class="line">        </div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">hyperplane</span><span class="params">(x, w, b, v)</span>:</span></div><div class="line">            <span class="keyword">return</span> (-w[<span class="number">0</span>]*x-b+v) / w[<span class="number">1</span>]</div><div class="line">        </div><div class="line">        datarange = (self.min_feature_value*<span class="number">0.9</span>, self.max_feature_value*<span class="number">1.1</span>)</div><div class="line">        hyp_x_min = datarange[<span class="number">0</span>]</div><div class="line">        hyp_x_max = datarange[<span class="number">1</span>]</div><div class="line">        </div><div class="line">        psv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">1</span>)</div><div class="line">        psv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">1</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [psv1,psv2], <span class="string">'k'</span>)</div><div class="line">        </div><div class="line">        nsv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">-1</span>)</div><div class="line">        nsv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">-1</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [nsv1,nsv2], <span class="string">'k'</span>)</div><div class="line">        </div><div class="line">        db1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">0</span>)</div><div class="line">        db2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">0</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [db1, db2], <span class="string">'y--'</span>)</div><div class="line">        </div><div class="line">        plt.show()</div></pre></td></tr></table></figure><p>铺助理解链接：</p><ul><li><p><a href="https://blog.csdn.net/qianwenhong/article/details/41414809" target="_blank" rel="external">Python 中的range(),arange()函数</a></p></li><li><p><a href="https://www.cnblogs.com/hezhiyao/p/8649231.html" target="_blank" rel="external">python中np.multiply（）、np.dot（）和星号（*）三种乘法运算的区别（转）</a></p></li></ul><h2 id="简要数据集预测以及结果可视化"><a href="#简要数据集预测以及结果可视化" class="headerlink" title="简要数据集预测以及结果可视化"></a>简要数据集预测以及结果可视化</h2><p>以下是完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Support_Vector_Machine</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, visualization=True)</span>:</span></div><div class="line">        self.visualization = visualization</div><div class="line">        self.colors = &#123;<span class="number">1</span>:<span class="string">'r'</span>, <span class="number">-1</span>:<span class="string">'b'</span>&#125;</div><div class="line">        <span class="keyword">if</span> self.visualization:</div><div class="line">            self.fig = plt.figure()</div><div class="line">            self.ax = self.fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, data)</span>:</span></div><div class="line">        self.data = data</div><div class="line">        opt_dict = &#123;&#125;</div><div class="line">        </div><div class="line">        transforms = [[<span class="number">1</span>,<span class="number">1</span>],</div><div class="line">                      [<span class="number">-1</span>,<span class="number">1</span>],</div><div class="line">                      [<span class="number">-1</span>,<span class="number">-1</span>],</div><div class="line">                      [<span class="number">1</span>,<span class="number">-1</span>]]</div><div class="line">        </div><div class="line">        all_data = []</div><div class="line">        <span class="keyword">for</span> yi <span class="keyword">in</span> self.data:</div><div class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> self.data[yi]:</div><div class="line">                <span class="keyword">for</span> feature <span class="keyword">in</span> featureset:</div><div class="line">                    all_data.append(feature)</div><div class="line">        </div><div class="line">        self.max_feature_value = max(all_data)</div><div class="line">        self.min_feature_value = min(all_data)</div><div class="line">        all_data = <span class="keyword">None</span></div><div class="line">        </div><div class="line">        <span class="comment">#指定梯度下降的步子大小</span></div><div class="line">        step_sizes = [self.max_feature_value * <span class="number">0.1</span>,</div><div class="line">                      self.max_feature_value * <span class="number">0.01</span>,</div><div class="line">                      self.max_feature_value * <span class="number">0.001</span>,]</div><div class="line">        </div><div class="line">        <span class="comment">#b的假设大小，最为重要的是参数w，而不是参数b </span></div><div class="line">        b_range_multiple = <span class="number">2</span></div><div class="line">        b_multiple =<span class="number">5</span></div><div class="line">        latest_optimum = self.max_feature_value*<span class="number">10</span> <span class="comment">#最大的步子</span></div><div class="line">        </div><div class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> step_sizes:</div><div class="line">            w = np.array([latest_optimum, latest_optimum])</div><div class="line">            optimized = <span class="keyword">False</span></div><div class="line">            <span class="keyword">while</span> <span class="keyword">not</span> optimized:</div><div class="line">                <span class="keyword">for</span> b <span class="keyword">in</span> np.arange(<span class="number">-1</span>*(self.max_feature_value * b_range_multiple),</div><div class="line">                                   self.max_feature_value * b_range_multiple,</div><div class="line">                                   step * b_multiple):</div><div class="line">                    <span class="keyword">for</span> transformation <span class="keyword">in</span> transforms:</div><div class="line">                        w_t = w*transformation</div><div class="line">                        found_option = <span class="keyword">True</span></div><div class="line">                        </div><div class="line">                        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</div><div class="line">                            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</div><div class="line">                                yi = i</div><div class="line">                                <span class="keyword">if</span> <span class="keyword">not</span> yi*(np.dot(w_t, xi)+b) &gt;= <span class="number">1</span>:</div><div class="line">                                    found_option = <span class="keyword">False</span></div><div class="line">                        </div><div class="line">                        <span class="comment">#如果约束优化条件成立</span></div><div class="line">                        <span class="keyword">if</span> found_option:</div><div class="line">                            opt_dict[np.linalg.norm(w_t)] = [w_t, b]</div><div class="line">                </div><div class="line">                <span class="comment">#若是值为负数则停止进一步的优化步子</span></div><div class="line">                <span class="keyword">if</span> w[<span class="number">0</span>] &lt;<span class="number">0</span>:</div><div class="line">                    optimized = <span class="keyword">True</span></div><div class="line">                    print(<span class="string">'Optimized a step.'</span>)</div><div class="line">                <span class="keyword">else</span>:</div><div class="line">                    w = w - step</div><div class="line">            norms = sorted([n <span class="keyword">for</span> n <span class="keyword">in</span> opt_dict])</div><div class="line">            </div><div class="line">            opt_choice = opt_dict[norms[<span class="number">0</span>]]</div><div class="line">            self.w = opt_choice[<span class="number">0</span>]</div><div class="line">            self.b = opt_choice[<span class="number">1</span>]</div><div class="line">            latest_optimum = opt_choice[<span class="number">0</span>][<span class="number">0</span>]+step*<span class="number">2</span></div><div class="line">            </div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</div><div class="line">            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</div><div class="line">                yi = i</div><div class="line">                print(xi, <span class="string">':'</span>, yi*(np.dot(self.w, xi)+self.b))</div><div class="line">            </div><div class="line">    <span class="comment">#预测部分</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, features)</span>:</span></div><div class="line">        classification = np.sign(np.dot(np.array(features), self.w)+self.b)</div><div class="line">        <span class="keyword">if</span> classification != <span class="number">0</span> <span class="keyword">and</span> self.visualization:</div><div class="line">            self.ax.scatter(features[<span class="number">0</span>], features[<span class="number">1</span>], s=<span class="number">200</span>, marker=<span class="string">'*'</span>, c=self.colors[classification])</div><div class="line">        </div><div class="line">        <span class="keyword">return</span> classification</div><div class="line">    </div><div class="line">    <span class="comment">#可视化部分</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(self)</span>:</span></div><div class="line">        [[self.ax.scatter(x[<span class="number">0</span>], x[<span class="number">1</span>], s=<span class="number">100</span>, color=self.colors[i]) <span class="keyword">for</span> x <span class="keyword">in</span> data_dict[i]] <span class="keyword">for</span> i <span class="keyword">in</span> data_dict]</div><div class="line">        </div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">hyperplane</span><span class="params">(x, w, b, v)</span>:</span></div><div class="line">            <span class="keyword">return</span> (-w[<span class="number">0</span>]*x-b+v) / w[<span class="number">1</span>]</div><div class="line">        </div><div class="line">        datarange = (self.min_feature_value*<span class="number">0.9</span>, self.max_feature_value*<span class="number">1.1</span>)</div><div class="line">        hyp_x_min = datarange[<span class="number">0</span>]</div><div class="line">        hyp_x_max = datarange[<span class="number">1</span>]</div><div class="line">        </div><div class="line">        psv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">1</span>)</div><div class="line">        psv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">1</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [psv1,psv2], <span class="string">'k'</span>)</div><div class="line">        </div><div class="line">        nsv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">-1</span>)</div><div class="line">        nsv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">-1</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [nsv1,nsv2], <span class="string">'k'</span>)</div><div class="line">        </div><div class="line">        db1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">0</span>)</div><div class="line">        db2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">0</span>)</div><div class="line">        self.ax.plot([hyp_x_min, hyp_x_max], [db1, db2], <span class="string">'y--'</span>)</div><div class="line">        </div><div class="line">        plt.show()</div><div class="line"></div><div class="line"><span class="comment">#训练数据集</span></div><div class="line">data_dict = &#123;<span class="number">-1</span>:np.array([[<span class="number">1</span>,<span class="number">7</span>],</div><div class="line">                          [<span class="number">2</span>,<span class="number">8</span>],</div><div class="line">                          [<span class="number">3</span>,<span class="number">8</span>],]),</div><div class="line">             </div><div class="line">             <span class="number">1</span>:np.array([[<span class="number">5</span>,<span class="number">1</span>],</div><div class="line">                         [<span class="number">6</span>,<span class="number">-1</span>],</div><div class="line">                         [<span class="number">7</span>,<span class="number">3</span>],])&#125;</div><div class="line"></div><div class="line">svm = Support_Vector_Machine()</div><div class="line">svm.fit(data=data_dict)</div><div class="line"></div><div class="line"><span class="comment">#预测数据集</span></div><div class="line">predict_us = [[<span class="number">0</span>,<span class="number">10</span>],</div><div class="line">              [<span class="number">1</span>,<span class="number">3</span>],</div><div class="line">              [<span class="number">3</span>,<span class="number">4</span>],</div><div class="line">              [<span class="number">3</span>,<span class="number">5</span>],</div><div class="line">              [<span class="number">5</span>,<span class="number">5</span>],</div><div class="line">              [<span class="number">5</span>,<span class="number">6</span>],</div><div class="line">              [<span class="number">6</span>,<span class="number">-5</span>],</div><div class="line">              [<span class="number">5</span>,<span class="number">8</span>]]</div><div class="line"></div><div class="line"><span class="keyword">for</span> p <span class="keyword">in</span> predict_us:</div><div class="line">    svm.predict(p)</div><div class="line"></div><div class="line">svm.visualize()</div></pre></td></tr></table></figure><p>这样一来就完成了算法的实现了，可视化的图表如下：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-26%20%E4%B8%8B%E5%8D%887.49.15.png" alt=""></p><blockquote><p>实际上这只是算法的简单实现，许多的细节并没有照顾到。而且这个算法的基础必须要牢固，不然很难理解上面的代码。</p></blockquote><h1 id="SVM进阶"><a href="#SVM进阶" class="headerlink" title="SVM进阶"></a>SVM进阶</h1><p>相关到<code>核函数</code>，<code>硬间隔最大化</code>，<code>软间隔最大化</code>等知识，其中的<code>核函数</code>，<code>软间隔最大化</code>针对于非线性数据(即线性不可分)，<code>硬间隔最大化</code>针对于线性可分数据类型，这需要自行去了解、理解。在上面说的书籍中可以找到相关的知识。</p><p>以下是关于<code>核函数</code>，<code>软间隔最大化</code>的针对于非线性数据python代码的实现，可以理解为SVM的底层实现的一部分，可以更好的理解内部实现的于原理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Mathieu Blondel, September 2010</span></div><div class="line"><span class="comment"># License: BSD 3 clause</span></div><div class="line"><span class="comment"># http://www.mblondel.org/journal/2010/09/19/support-vector-machines-in-python/</span></div><div class="line"></div><div class="line"><span class="comment"># visualizing what translating to another dimension does</span></div><div class="line"><span class="comment"># and bringing back to 2D:</span></div><div class="line"><span class="comment"># https://www.youtube.com/watch?v=3liCbRZPrZA</span></div><div class="line"></div><div class="line"><span class="comment"># Docs: http://cvxopt.org/userguide/coneprog.html#quadratic-programming</span></div><div class="line"><span class="comment"># Docs qp example: http://cvxopt.org/examples/tutorial/qp.html</span></div><div class="line"></div><div class="line"><span class="comment"># Nice tutorial:</span></div><div class="line"><span class="comment"># https://courses.csail.mit.edu/6.867/wiki/images/a/a7/Qp-cvxopt.pdf</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg</div><div class="line"><span class="keyword">import</span> cvxopt</div><div class="line"><span class="keyword">import</span> cvxopt.solvers</div><div class="line">             </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear_kernel</span><span class="params">(x1, x2)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.dot(x1, x2)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">polynomial_kernel</span><span class="params">(x, y, p=<span class="number">3</span>)</span>:</span></div><div class="line">    <span class="keyword">return</span> (<span class="number">1</span> + np.dot(x, y)) ** p</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian_kernel</span><span class="params">(x, y, sigma=<span class="number">5.0</span>)</span>:</span></div><div class="line">    <span class="keyword">return</span> np.exp(-linalg.norm(x-y)**<span class="number">2</span> / (<span class="number">2</span> * (sigma ** <span class="number">2</span>)))</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SVM</span><span class="params">(object)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, kernel=linear_kernel, C=None)</span>:</span></div><div class="line">        self.kernel = kernel</div><div class="line">        self.C = C</div><div class="line">        <span class="keyword">if</span> self.C <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>: self.C = float(self.C)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, y)</span>:</span></div><div class="line">        n_samples, n_features = X.shape</div><div class="line"></div><div class="line">        <span class="comment"># Gram matrix</span></div><div class="line">        K = np.zeros((n_samples, n_samples))</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n_samples):</div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(n_samples):</div><div class="line">                K[i,j] = self.kernel(X[i], X[j])</div><div class="line"></div><div class="line">        P = cvxopt.matrix(np.outer(y,y) * K)</div><div class="line">        q = cvxopt.matrix(np.ones(n_samples) * <span class="number">-1</span>)</div><div class="line">        A = cvxopt.matrix(y, (<span class="number">1</span>,n_samples))</div><div class="line">        b = cvxopt.matrix(<span class="number">0.0</span>)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> self.C <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            G = cvxopt.matrix(np.diag(np.ones(n_samples) * <span class="number">-1</span>))</div><div class="line">            h = cvxopt.matrix(np.zeros(n_samples))</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            tmp1 = np.diag(np.ones(n_samples) * <span class="number">-1</span>)</div><div class="line">            tmp2 = np.identity(n_samples)</div><div class="line">            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))</div><div class="line">            tmp1 = np.zeros(n_samples)</div><div class="line">            tmp2 = np.ones(n_samples) * self.C</div><div class="line">            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))</div><div class="line"></div><div class="line">        <span class="comment"># solve QP problem</span></div><div class="line">        solution = cvxopt.solvers.qp(P, q, G, h, A, b)</div><div class="line"></div><div class="line">        <span class="comment"># Lagrange multipliers</span></div><div class="line">        a = np.ravel(solution[<span class="string">'x'</span>])</div><div class="line"></div><div class="line">        <span class="comment"># Support vectors have non zero lagrange multipliers</span></div><div class="line">        sv = a &gt; <span class="number">1e-5</span></div><div class="line">        ind = np.arange(len(a))[sv]</div><div class="line">        self.a = a[sv]</div><div class="line">        self.sv = X[sv]</div><div class="line">        self.sv_y = y[sv]</div><div class="line">        print(<span class="string">"%d support vectors out of %d points"</span> % (len(self.a), n_samples))</div><div class="line"></div><div class="line">        <span class="comment"># Intercept</span></div><div class="line">        self.b = <span class="number">0</span></div><div class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> range(len(self.a)):</div><div class="line">            self.b += self.sv_y[n]</div><div class="line">            self.b -= np.sum(self.a * self.sv_y * K[ind[n],sv])</div><div class="line">        self.b /= len(self.a)</div><div class="line"></div><div class="line">        <span class="comment"># Weight vector</span></div><div class="line">        <span class="keyword">if</span> self.kernel == linear_kernel:</div><div class="line">            self.w = np.zeros(n_features)</div><div class="line">            <span class="keyword">for</span> n <span class="keyword">in</span> range(len(self.a)):</div><div class="line">                self.w += self.a[n] * self.sv_y[n] * self.sv[n]</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            self.w = <span class="keyword">None</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">project</span><span class="params">(self, X)</span>:</span></div><div class="line">        <span class="keyword">if</span> self.w <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span> np.dot(X, self.w) + self.b</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            y_predict = np.zeros(len(X))</div><div class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(X)):</div><div class="line">                s = <span class="number">0</span></div><div class="line">                <span class="keyword">for</span> a, sv_y, sv <span class="keyword">in</span> zip(self.a, self.sv_y, self.sv):</div><div class="line">                    s += a * sv_y * self.kernel(X[i], sv)</div><div class="line">                y_predict[i] = s</div><div class="line">            <span class="keyword">return</span> y_predict + self.b</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></div><div class="line">        <span class="keyword">return</span> np.sign(self.project(X))</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    <span class="keyword">import</span> pylab <span class="keyword">as</span> pl</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gen_lin_separable_data</span><span class="params">()</span>:</span></div><div class="line">        <span class="comment"># generate training data in the 2-d case</span></div><div class="line">        mean1 = np.array([<span class="number">0</span>, <span class="number">2</span>])</div><div class="line">        mean2 = np.array([<span class="number">2</span>, <span class="number">0</span>])</div><div class="line">        cov = np.array([[<span class="number">0.8</span>, <span class="number">0.6</span>], [<span class="number">0.6</span>, <span class="number">0.8</span>]])</div><div class="line">        X1 = np.random.multivariate_normal(mean1, cov, <span class="number">100</span>)</div><div class="line">        y1 = np.ones(len(X1))</div><div class="line">        X2 = np.random.multivariate_normal(mean2, cov, <span class="number">100</span>)</div><div class="line">        y2 = np.ones(len(X2)) * <span class="number">-1</span></div><div class="line">        <span class="keyword">return</span> X1, y1, X2, y2</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gen_non_lin_separable_data</span><span class="params">()</span>:</span></div><div class="line">        mean1 = [<span class="number">-1</span>, <span class="number">2</span>]</div><div class="line">        mean2 = [<span class="number">1</span>, <span class="number">-1</span>]</div><div class="line">        mean3 = [<span class="number">4</span>, <span class="number">-4</span>]</div><div class="line">        mean4 = [<span class="number">-4</span>, <span class="number">4</span>]</div><div class="line">        cov = [[<span class="number">1.0</span>,<span class="number">0.8</span>], [<span class="number">0.8</span>, <span class="number">1.0</span>]]</div><div class="line">        X1 = np.random.multivariate_normal(mean1, cov, <span class="number">50</span>)</div><div class="line">        X1 = np.vstack((X1, np.random.multivariate_normal(mean3, cov, <span class="number">50</span>)))</div><div class="line">        y1 = np.ones(len(X1))</div><div class="line">        X2 = np.random.multivariate_normal(mean2, cov, <span class="number">50</span>)</div><div class="line">        X2 = np.vstack((X2, np.random.multivariate_normal(mean4, cov, <span class="number">50</span>)))</div><div class="line">        y2 = np.ones(len(X2)) * <span class="number">-1</span></div><div class="line">        <span class="keyword">return</span> X1, y1, X2, y2</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gen_lin_separable_overlap_data</span><span class="params">()</span>:</span></div><div class="line">        <span class="comment"># generate training data in the 2-d case</span></div><div class="line">        mean1 = np.array([<span class="number">0</span>, <span class="number">2</span>])</div><div class="line">        mean2 = np.array([<span class="number">2</span>, <span class="number">0</span>])</div><div class="line">        cov = np.array([[<span class="number">1.5</span>, <span class="number">1.0</span>], [<span class="number">1.0</span>, <span class="number">1.5</span>]])</div><div class="line">        X1 = np.random.multivariate_normal(mean1, cov, <span class="number">100</span>)</div><div class="line">        y1 = np.ones(len(X1))</div><div class="line">        X2 = np.random.multivariate_normal(mean2, cov, <span class="number">100</span>)</div><div class="line">        y2 = np.ones(len(X2)) * <span class="number">-1</span></div><div class="line">        <span class="keyword">return</span> X1, y1, X2, y2</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">split_train</span><span class="params">(X1, y1, X2, y2)</span>:</span></div><div class="line">        X1_train = X1[:<span class="number">90</span>]</div><div class="line">        y1_train = y1[:<span class="number">90</span>]</div><div class="line">        X2_train = X2[:<span class="number">90</span>]</div><div class="line">        y2_train = y2[:<span class="number">90</span>]</div><div class="line">        X_train = np.vstack((X1_train, X2_train))</div><div class="line">        y_train = np.hstack((y1_train, y2_train))</div><div class="line">        <span class="keyword">return</span> X_train, y_train</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">split_test</span><span class="params">(X1, y1, X2, y2)</span>:</span></div><div class="line">        X1_test = X1[<span class="number">90</span>:]</div><div class="line">        y1_test = y1[<span class="number">90</span>:]</div><div class="line">        X2_test = X2[<span class="number">90</span>:]</div><div class="line">        y2_test = y2[<span class="number">90</span>:]</div><div class="line">        X_test = np.vstack((X1_test, X2_test))</div><div class="line">        y_test = np.hstack((y1_test, y2_test))</div><div class="line">        <span class="keyword">return</span> X_test, y_test</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot_margin</span><span class="params">(X1_train, X2_train, clf)</span>:</span></div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x, w, b, c=<span class="number">0</span>)</span>:</span></div><div class="line">            <span class="comment"># given x, return y such that [x,y] in on the line</span></div><div class="line">            <span class="comment"># w.x + b = c</span></div><div class="line">            <span class="keyword">return</span> (-w[<span class="number">0</span>] * x - b + c) / w[<span class="number">1</span>]</div><div class="line"></div><div class="line">        pl.plot(X1_train[:,<span class="number">0</span>], X1_train[:,<span class="number">1</span>], <span class="string">"ro"</span>)</div><div class="line">        pl.plot(X2_train[:,<span class="number">0</span>], X2_train[:,<span class="number">1</span>], <span class="string">"bo"</span>)</div><div class="line">        pl.scatter(clf.sv[:,<span class="number">0</span>], clf.sv[:,<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">"g"</span>)</div><div class="line"></div><div class="line">        <span class="comment"># w.x + b = 0</span></div><div class="line">        a0 = <span class="number">-4</span>; a1 = f(a0, clf.w, clf.b)</div><div class="line">        b0 = <span class="number">4</span>; b1 = f(b0, clf.w, clf.b)</div><div class="line">        pl.plot([a0,b0], [a1,b1], <span class="string">"k"</span>)</div><div class="line"></div><div class="line">        <span class="comment"># w.x + b = 1</span></div><div class="line">        a0 = <span class="number">-4</span>; a1 = f(a0, clf.w, clf.b, <span class="number">1</span>)</div><div class="line">        b0 = <span class="number">4</span>; b1 = f(b0, clf.w, clf.b, <span class="number">1</span>)</div><div class="line">        pl.plot([a0,b0], [a1,b1], <span class="string">"k--"</span>)</div><div class="line"></div><div class="line">        <span class="comment"># w.x + b = -1</span></div><div class="line">        a0 = <span class="number">-4</span>; a1 = f(a0, clf.w, clf.b, <span class="number">-1</span>)</div><div class="line">        b0 = <span class="number">4</span>; b1 = f(b0, clf.w, clf.b, <span class="number">-1</span>)</div><div class="line">        pl.plot([a0,b0], [a1,b1], <span class="string">"k--"</span>)</div><div class="line"></div><div class="line">        pl.axis(<span class="string">"tight"</span>)</div><div class="line">        pl.show()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot_contour</span><span class="params">(X1_train, X2_train, clf)</span>:</span></div><div class="line">        pl.plot(X1_train[:,<span class="number">0</span>], X1_train[:,<span class="number">1</span>], <span class="string">"ro"</span>)</div><div class="line">        pl.plot(X2_train[:,<span class="number">0</span>], X2_train[:,<span class="number">1</span>], <span class="string">"bo"</span>)</div><div class="line">        pl.scatter(clf.sv[:,<span class="number">0</span>], clf.sv[:,<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">"g"</span>)</div><div class="line"></div><div class="line">        X1, X2 = np.meshgrid(np.linspace(<span class="number">-6</span>,<span class="number">6</span>,<span class="number">50</span>), np.linspace(<span class="number">-6</span>,<span class="number">6</span>,<span class="number">50</span>))</div><div class="line">        X = np.array([[x1, x2] <span class="keyword">for</span> x1, x2 <span class="keyword">in</span> zip(np.ravel(X1), np.ravel(X2))])</div><div class="line">        Z = clf.project(X).reshape(X1.shape)</div><div class="line">        pl.contour(X1, X2, Z, [<span class="number">0.0</span>], colors=<span class="string">'k'</span>, linewidths=<span class="number">1</span>, origin=<span class="string">'lower'</span>)</div><div class="line">        pl.contour(X1, X2, Z + <span class="number">1</span>, [<span class="number">0.0</span>], colors=<span class="string">'grey'</span>, linewidths=<span class="number">1</span>, origin=<span class="string">'lower'</span>)</div><div class="line">        pl.contour(X1, X2, Z - <span class="number">1</span>, [<span class="number">0.0</span>], colors=<span class="string">'grey'</span>, linewidths=<span class="number">1</span>, origin=<span class="string">'lower'</span>)</div><div class="line"></div><div class="line">        pl.axis(<span class="string">"tight"</span>)</div><div class="line">        pl.show()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_linear</span><span class="params">()</span>:</span></div><div class="line">        X1, y1, X2, y2 = gen_lin_separable_data()</div><div class="line">        X_train, y_train = split_train(X1, y1, X2, y2)</div><div class="line">        X_test, y_test = split_test(X1, y1, X2, y2)</div><div class="line"></div><div class="line">        clf = SVM()</div><div class="line">        clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">        y_predict = clf.predict(X_test)</div><div class="line">        correct = np.sum(y_predict == y_test)</div><div class="line">        print(<span class="string">"%d out of %d predictions correct"</span> % (correct, len(y_predict)))</div><div class="line"></div><div class="line">        plot_margin(X_train[y_train==<span class="number">1</span>], X_train[y_train==<span class="number">-1</span>], clf)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_non_linear</span><span class="params">()</span>:</span></div><div class="line">        X1, y1, X2, y2 = gen_non_lin_separable_data()</div><div class="line">        X_train, y_train = split_train(X1, y1, X2, y2)</div><div class="line">        X_test, y_test = split_test(X1, y1, X2, y2)</div><div class="line"></div><div class="line">        clf = SVM(polynomial_kernel)</div><div class="line">        clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">        y_predict = clf.predict(X_test)</div><div class="line">        correct = np.sum(y_predict == y_test)</div><div class="line">        print(<span class="string">"%d out of %d predictions correct"</span> % (correct, len(y_predict)))</div><div class="line"></div><div class="line">        plot_contour(X_train[y_train==<span class="number">1</span>], X_train[y_train==<span class="number">-1</span>], clf)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_soft</span><span class="params">()</span>:</span></div><div class="line">        X1, y1, X2, y2 = gen_lin_separable_overlap_data()</div><div class="line">        X_train, y_train = split_train(X1, y1, X2, y2)</div><div class="line">        X_test, y_test = split_test(X1, y1, X2, y2)</div><div class="line"></div><div class="line">        clf = SVM(C=<span class="number">1000.1</span>)</div><div class="line">        clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">        y_predict = clf.predict(X_test)</div><div class="line">        correct = np.sum(y_predict == y_test)</div><div class="line">        print(<span class="string">"%d out of %d predictions correct"</span> % (correct, len(y_predict)))</div><div class="line"></div><div class="line">        plot_contour(X_train[y_train==<span class="number">1</span>], X_train[y_train==<span class="number">-1</span>], clf)</div><div class="line"></div><div class="line">        </div><div class="line">    <span class="comment">#test_linear()</span></div><div class="line">    <span class="comment">#test_non_linear()</span></div><div class="line">    test_soft()</div></pre></td></tr></table></figure><blockquote><p><strong>具体相关说明可见<a href="https://pythonprogramming.net/soft-margin-kernel-cvxopt-svm-machine-learning-tutorial/?completed=/soft-margin-svm-machine-learning-tutorial/" target="_blank" rel="external">对应的课程地址</a>。</strong></p></blockquote><p>更多的铺助链接：</p><ul><li><p><a href="https://cvxopt.org/userguide/intro.html" target="_blank" rel="external">pythonC最优化模块库：VXOPT二次编程文档</a></p></li><li><p><a href="https://courses.csail.mit.edu/6.867/wiki/images/a/a7/Qp-cvxopt.pdf" target="_blank" rel="external">CVXOPT进行二次编程的更深入的示例</a></p></li><li><p><a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/" target="_blank" rel="external">用于支持向量机优化的库</a></p></li></ul><h1 id="SVM的应用"><a href="#SVM的应用" class="headerlink" title="SVM的应用"></a>SVM的应用</h1><p>还是利用了在上个文章<a href="http://liujunworld.com/2018/10/21/python机器学习系列：K近邻算法(KNN" target="_blank" rel="external">python机器学习系列：K近邻算法(KNN)的实现及应用</a>的实现及应用/)的实际数据集。只是将<code>sklearn</code>模块中的现成的拿来用了。</p><p>代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing, neighbors, svm</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'breast-cancer-wisconsin.data'</span>)</div><div class="line"></div><div class="line">df.replace(<span class="string">'?'</span>,<span class="number">-99999</span>,inplace=<span class="keyword">True</span>) <span class="comment">#替换异常值为-99999，inplace=True表示文件中也将进行同步更改</span></div><div class="line"></div><div class="line"><span class="comment">#去除不相关的特征列</span></div><div class="line">df.drop([<span class="string">'Id'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'Class'</span>], <span class="number">1</span>)) <span class="comment">#去除标签列，自制数据集</span></div><div class="line">y = np.array(df[<span class="string">'Class'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line"></div><div class="line">clf = svm.SVC() <span class="comment">#分类SVM</span></div><div class="line">clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">accuracy = clf.score(X_test, y_test) <span class="comment">#得出准确值</span></div><div class="line">print(accuracy)</div><div class="line"></div><div class="line"><span class="comment">#创建数据集来进行简单的预测</span></div><div class="line">example_maasurse = np.array([[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>]])</div><div class="line"></div><div class="line">example_maasurse = example_maasurse.reshape(len(example_maasurse),<span class="number">-1</span>) <span class="comment">#重朔,其中的-1可理解为，只想输出2行的情况下，后面的列我写上-1由numpy自行得出对应相符的数组，有点抽象...其实也就那么回事</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">prediction = clf.predict(example_maasurse)</div><div class="line">print(prediction)</div></pre></td></tr></table></figure><p>结果跟上篇介绍的用<code>KNN</code>的结果几乎一样，就不展示了。</p><p>关于现成算法的参数的使用可移步：</p><ul><li><a href="http://sklearn.apachecn.org/cn/stable/index.html" target="_blank" rel="external">sklearn中文主页</a></li></ul><p>这样这篇文章基本上就这样了，需要更新的话再来补充。</p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/HHUqhVzctQE&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;我记录下的这些东西，如果是有哪些不懂得地方，我强烈建议参考我在&lt;a href=&quot;http://liujunworld.com/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里的书籍&lt;/a&gt;。另外还有&lt;a href=&quot;https://github.com/apachecn/AiLearning&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《机器学习实战》&lt;/a&gt;，&lt;a href=&quot;https://github.com/exacity/deeplearningbook-chinese&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《深度学习》&lt;/a&gt;这本花书等，利用好搜索引擎也是一大好利器。&lt;/p&gt;
&lt;p&gt;关于这篇文章，我还是和以前记录相关的机器学习知识之类篇章一样的风格。&lt;/p&gt;
&lt;p&gt;不懂可进入&lt;a href=&quot;https://pythonprogramming.net/support-vector-machine-intro-machine-learning-tutorial/?completed=/final-thoughts-knn-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;这里的对应的教程&lt;/a&gt;，看不懂可借助翻译插件/软件(实际上借助这些看起来轻松多了，看英文头疼的厉害，如果是对于初学者)。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>解决eclipse中运行Django时出现错误Django not found</title>
    <link href="https://liujunjie11.github.io/2018/10/21/%E8%A7%A3%E5%86%B3eclipse%E4%B8%AD%E8%BF%90%E8%A1%8CDjango%E6%97%B6%E5%87%BA%E7%8E%B0%E9%94%99%E8%AF%AFDjango-not-found/"/>
    <id>https://liujunjie11.github.io/2018/10/21/解决eclipse中运行Django时出现错误Django-not-found/</id>
    <published>2018-10-21T12:07:13.000Z</published>
    <updated>2019-01-02T06:50:03.868Z</updated>
    
    <content type="html"><![CDATA[<p>打算在<em>eclipse</em>中运行<em>Django</em>项目，结果发现出现了错误Django not found，如下图(网上找的一张，忘记截图了..)：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/20151111171637700.png" alt=""></p><blockquote><p>图片来源：<a href="https://blog.csdn.net/wlsyn/article/details/49784263?utm_source=blogxgwz2" target="_blank" rel="external">https://blog.csdn.net/wlsyn/article/details/49784263?utm_source=blogxgwz2</a></p></blockquote><p>试了一些网上所谓的重新嵌入解释器目录的方法，还有重装<em>Django</em>的方法，都没有什么用。</p><a id="more"></a><p>但是我真的不想放弃啊，eclipse那么好用，而且在其中运行Django是那么的方便…</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><h2 id="git下载GitHub上的Django"><a href="#git下载GitHub上的Django" class="headerlink" title="git下载GitHub上的Django"></a>git下载GitHub上的Django</h2><p>使用命令行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> https://github.com/django/django.git</div></pre></td></tr></table></figure><blockquote><p>参考：<a href="https://www.djangoproject.com/download/" target="_blank" rel="external">https://www.djangoproject.com/download/</a></p></blockquote><h2 id="移动安装包"><a href="#移动安装包" class="headerlink" title="移动安装包"></a>移动安装包</h2><p>之后将下载好的移动到要用到的python版本中的<code>site-packages</code>中，如我的目录<code>/anaconda3/lib/python3.6/site-packages/</code>。</p><h2 id="eclipse配置"><a href="#eclipse配置" class="headerlink" title="eclipse配置"></a>eclipse配置</h2><p>之后打开eclipse配置界面，看图吧，一图胜千言。</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-21%20%E4%B8%8B%E5%8D%888.16.27.png" alt=""></p><p>之后应用、关闭。</p><p>然后再建立Django项目时就不会再出现错误Django not found了。</p><p>测试和建立项目过程不妨可以参考以下链接：</p><blockquote><p><a href="http://www.cnblogs.com/lanxuezaipiao/p/3283932.html" target="_blank" rel="external">http://www.cnblogs.com/lanxuezaipiao/p/3283932.html</a></p></blockquote><p>我就不重复制造轮子了。</p><p>测试成功之后：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-21%20%E4%B8%8B%E5%8D%888.04.02.png" alt=""></p><p>Yes,it`s successful!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;打算在&lt;em&gt;eclipse&lt;/em&gt;中运行&lt;em&gt;Django&lt;/em&gt;项目，结果发现出现了错误Django not found，如下图(网上找的一张，忘记截图了..)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://liu-1258031152.cos.ap-beijing.myqcloud.com/20151111171637700.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;图片来源：&lt;a href=&quot;https://blog.csdn.net/wlsyn/article/details/49784263?utm_source=blogxgwz2&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://blog.csdn.net/wlsyn/article/details/49784263?utm_source=blogxgwz2&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;试了一些网上所谓的重新嵌入解释器目录的方法，还有重装&lt;em&gt;Django&lt;/em&gt;的方法，都没有什么用。&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://liujunjie11.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="软件使用" scheme="https://liujunjie11.github.io/categories/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/"/>
    
      <category term="Eclipse" scheme="https://liujunjie11.github.io/categories/Eclipse/"/>
    
      <category term="Django" scheme="https://liujunjie11.github.io/categories/Django/"/>
    
    
      <category term="Eclipse" scheme="https://liujunjie11.github.io/tags/Eclipse/"/>
    
      <category term="问题记录笔记" scheme="https://liujunjie11.github.io/tags/%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Django" scheme="https://liujunjie11.github.io/tags/Django/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：K近邻算法(KNN)的实现及应用</title>
    <link href="https://liujunjie11.github.io/2018/10/21/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9AK%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95(KNN)%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%BA%94%E7%94%A8/"/>
    <id>https://liujunjie11.github.io/2018/10/21/python机器学习系列：K近邻算法(KNN)的实现及应用/</id>
    <published>2018-10-21T05:43:00.000Z</published>
    <updated>2019-01-02T06:50:13.346Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/r_D5TTV9-2c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>还是老样子，这篇文章不适合纯粹的小白，仅仅注重实践，基础知识说的比较浅，基本上一笔带过。</p><p>我在作者的原代码和数据上进行了一点修改以符合当今的实际情况。</p><p>此篇文章将实现K近邻算法的基本原理，以及实现K邻近算法并且应用到实际数据集之中，之后会有一个实战项目。<br><a id="more"></a></p><h1 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h1><h2 id="欧几里得原理以及代码实现"><a href="#欧几里得原理以及代码实现" class="headerlink" title="欧几里得原理以及代码实现"></a>欧几里得原理以及代码实现</h2><p>欧几里得公式：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/euclidean-distance.png" alt=""></p><blockquote><p>实际上很简单，想想求解两点值之间的距离的问题吧…</p></blockquote><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</div><div class="line"></div><div class="line"><span class="comment">#数据自制</span></div><div class="line">feature_1 = [<span class="number">1</span>,<span class="number">3</span>]</div><div class="line">feature_2 = [<span class="number">2</span>,<span class="number">6</span>]</div><div class="line"></div><div class="line">euclidean_distance = sqrt((variable_2[<span class="number">0</span>]-variable_1[<span class="number">0</span>])**<span class="number">2</span> + (variable_2[<span class="number">1</span>]-variable_1[<span class="number">1</span>])**<span class="number">2</span>)</div><div class="line">print(euclidean_distance)</div></pre></td></tr></table></figure><blockquote><p>这里是中文相关一节的地址：<a href="https://www.yxgapp.com/video/c8426884-2b56-494f-a274-0aa3105503f1.html" target="_blank" rel="external">https://www.yxgapp.com/video/c8426884-2b56-494f-a274-0aa3105503f1.html</a></p></blockquote><h2 id="实现KNN"><a href="#实现KNN" class="headerlink" title="实现KNN"></a>实现KNN</h2><p>KNN的工作机制(来自志华哥的《机器学习》)：</p><blockquote><p>给定测试样本，基于某种距离度量找出训练集中与其最近的k个训练样本，然后基于这k个“邻居”的信息来进行预测，通常，在分类任务中可使用“投票法”(在本文当中明显就是分类问题)，即选择这k个样本中出现最多的类别标记作为预测结果；在回归任务中可使用“平均法”，即将这k个样本的实值输出标记的平均值作为预测结果；还可基于距离远近进行加权平均或加权投票，距离越近的样本权重越大。</p></blockquote><p>这样就能好理解之后写的算法了，这毕竟不是给纯粹的小白写的。</p><p>简单说说下面写的代码的原理：通过原有的数值与新的数值代入欧几里得原理得出各点与新数值的距离，然后对这些数值进行从小到大排序并且选取前面K个数值(即所谓的K近邻)作为选择值，之后选择第一个最近的(距离最小的)作为新数据的标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> warnings</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</div><div class="line"></div><div class="line"><span class="comment">#自制数据集</span></div><div class="line">dataset = &#123;<span class="string">'k'</span>:[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">1</span>]], <span class="string">'r'</span>:[[<span class="number">6</span>,<span class="number">5</span>],[<span class="number">7</span>,<span class="number">7</span>],[<span class="number">8</span>,<span class="number">6</span>]]&#125; <span class="comment">#这个字典的key值为何这样命名看到下面就知道了，作为color参数的输入</span></div><div class="line">new_features = [<span class="number">5</span>,<span class="number">7</span>]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_nearest_neighbors</span><span class="params">(data, predict_feature, k=<span class="number">3</span>)</span>:</span> <span class="comment">#特别说明：k值在sklearn中的模型默认为5</span></div><div class="line">    <span class="keyword">if</span> len(data) &gt;= k:</div><div class="line">        warnings.warn(<span class="string">'你这样就没有意义了...笨猪！'</span>)</div><div class="line">    distances = []</div><div class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> data:</div><div class="line">        <span class="keyword">for</span> features <span class="keyword">in</span> data[group]: <span class="comment">#这两段代码与for group, features in dateset.items():意义一致</span></div><div class="line">            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict_feature)) <span class="comment">#使用numpy的相关的模块会显得更加的快速以及更加的高级</span></div><div class="line">            distances.append([euclidean_distance, group])</div><div class="line">            </div><div class="line">    votes = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> sorted(distances)[:k]] <span class="comment">#从小到大的排序，选择出现在前面的K个样本作为投票得出的结果</span></div><div class="line">    vote_result = Counter(votes).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> vote_result</div><div class="line"></div><div class="line">result = k_nearest_neighbors(dataset, new_features, k=<span class="number">3</span>)</div><div class="line">print(result)</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="comment">#可通过图表展示出结果信息</span></div><div class="line">[[plt.scatter(ii[<span class="number">0</span>],ii[<span class="number">1</span>], s=<span class="number">20</span>, color=i) <span class="keyword">for</span> ii <span class="keyword">in</span> dateset[i]] <span class="keyword">for</span> i <span class="keyword">in</span> dateset] <span class="comment">#color输出为'r'，可见上面作者命名的含义</span></div><div class="line"></div><div class="line">result = k_nearest_neighbors(dataset, new_features)</div><div class="line">plt.scatter(new_features[<span class="number">0</span>], new_features[<span class="number">1</span>], s=<span class="number">20</span>, color = result) <span class="comment">#color输出为'r'，可见上面作者命名的含义</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>可帮助理解的链接：</p><ul><li><p><a href="http://www.pythoner.com/205.html" target="_blank" rel="external">Python标准库——collections模块的Counter类</a></p></li><li><p><a href="https://blog.csdn.net/hqh131360239/article/details/79061535" target="_blank" rel="external">np.linalg.norm(求范数)</a></p></li></ul><blockquote><p>看完并且理解了上面的代码之后，你就会发现<strong>KNN算法为何对于异常值不敏感了吧，因为异常值太大，得出的距离也很大，所以一般在投票选择排序时就被out了。</strong></p></blockquote><h2 id="展示图表以及运行结果"><a href="#展示图表以及运行结果" class="headerlink" title="展示图表以及运行结果"></a>展示图表以及运行结果</h2><p>如图：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-22%20%E4%B8%8B%E5%8D%885.55.39.png" alt=""></p><p>这样就一目了然了。</p><h1 id="项目实践"><a href="#项目实践" class="headerlink" title="项目实践"></a>项目实践</h1><ul><li>数据来源：<a href="https://archive.ics.uci.edu/ml/datasets.html" target="_blank" rel="external">https://archive.ics.uci.edu/ml/datasets.html</a>﻿</li></ul><p>这是加州大学的一个用于机器学习数据的仓库，基本上是开放数据给我们使用的。</p><ul><li><p>项目使用的数据下载页面：<a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic" target="_blank" rel="external">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic</a>)</p></li><li><p>项目使用的数据下载链接：<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/" target="_blank" rel="external">https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/</a></p></li></ul><p>下载其中的<code>breast-cancer-wisconsin.data</code>，查看特征系数情况查看<code>breast-cancer-wisconsin.names</code>。</p><p>因为需要对数据进行一些特征增加的修改，所以我贴上修改后的数据在下，也可查看上面的作者的YouTube教程来进行修改。</p><ul><li>修改后的数据集：<a href="https://pan.baidu.com/s/1J-G6ESB-JXFfBk8yTl8lmw" target="_blank" rel="external">https://pan.baidu.com/s/1J-G6ESB-JXFfBk8yTl8lmw</a></li></ul><blockquote><p>也就是添加了特征名而已。</p></blockquote><p>这是一个关于乳腺癌判断的数据集。从<code>breast-cancer-wisconsin.names</code>中可得知缺失的数据由<code>&#39;?&#39;</code>来表示。</p><blockquote><ol><li><p>Missing attribute values: 16</p><p>There are 16 instances in Groups 1 to 6 that contain a single missing (i.e., unavailable) attribute value, now denoted by “?”.  </p></li></ol></blockquote><p>这样一来就能开始整个项目了。</p><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>数据集中的特征意喻：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">Attribute Information: (class attribute has been moved to last column)</div><div class="line"></div><div class="line">   <span class="comment">#  Attribute                     Domain</span></div><div class="line">   -- -----------------------------------------</div><div class="line">   1. Sample code number            id number</div><div class="line">   2. Clump Thickness               1 - 10</div><div class="line">   3. Uniformity of Cell Size       1 - 10</div><div class="line">   4. Uniformity of Cell Shape      1 - 10</div><div class="line">   5. Marginal Adhesion             1 - 10</div><div class="line">   6. Single Epithelial Cell Size   1 - 10</div><div class="line">   7. Bare Nuclei                   1 - 10</div><div class="line">   8. Bland Chromatin               1 - 10</div><div class="line">   9. Normal Nucleoli               1 - 10</div><div class="line">  10. Mitoses                       1 - 10</div><div class="line">  11. Class:                        (2 <span class="keyword">for</span> benign(良性), 4 <span class="keyword">for</span> malignant(恶性))</div></pre></td></tr></table></figure><p>因为缺失的数据并不多，并且在我修改了那几个缺失值测试了好几次用于训练之后发现差距基本上可以忽略，所以这里的关于缺失值改为异常值来处理，因为基本上对于模型训练基本上没有什么影响。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'breast-cancer-wisconsin.data'</span>)</div><div class="line"></div><div class="line">df.replace(<span class="string">'?'</span>,<span class="number">-99999</span>,inplace=<span class="keyword">True</span>) <span class="comment">#替换异常值为-99999，inplace=True表示文件中也将进行同步更改</span></div><div class="line"><span class="comment">#去除不相关的特征列</span></div><div class="line">df.drop([<span class="string">'Id'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure><p>数据量本身也就是那么点…所以数据预处理也就这样了…<strong>KNN算法对于异常值不敏感。</strong></p><h2 id="模型训练及预测"><a href="#模型训练及预测" class="headerlink" title="模型训练及预测"></a>模型训练及预测</h2><p>分割数据集，进行训练，并且制作简易数据集来进行预测。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,neighbors</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'Class'</span>], <span class="number">1</span>)) <span class="comment">#去除标签列，自制数据集</span></div><div class="line">y = np.array(df[<span class="string">'Class'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line"></div><div class="line">clf = neighbors.KNeighborsClassifier()</div><div class="line">clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">accuracy = clf.score(X_test, y_test) <span class="comment">#得出准确值</span></div><div class="line">print(accuracy)</div><div class="line"></div><div class="line"><span class="comment">#创建数据集来进行简单的预测</span></div><div class="line">example_maasurse = np.array([[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>]])</div><div class="line">example_maasurse = example_maasurse.reshape(len(example_maasurse),<span class="number">-1</span>) <span class="comment">#重朔,其中的-1可理解为，只想输出2行的情况下，后面的列我写上-1由numpy自行得出对应相符的数组，有点抽象...其实也就那么回事</span></div><div class="line"></div><div class="line"></div><div class="line">prediction = clf.predict(example_maasurse)</div><div class="line">print(prediction)</div></pre></td></tr></table></figure><p>输出如下：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-21%20%E4%B8%8B%E5%8D%884.10.36.png" alt=""></p><p>如果还是对于这条代码<code>example_maasurse.reshape(len(example_maasurse),-1)</code>中的<code>-1</code>还是不理解，可参考如下链接或者是官网：</p><ul><li><p><a href="https://www.zhihu.com/question/52684594" target="_blank" rel="external">Python中reshape函数参数-1的意思？</a></p></li><li><p><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html#numpy-reshape" target="_blank" rel="external">numpy.reshape</a></p></li><li><p><a href="">Python Numpy中reshape函数参数-1的含义</a></p></li></ul><p>其实也就那么回事…</p><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,neighbors</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'breast-cancer-wisconsin.data'</span>)</div><div class="line"></div><div class="line">df.replace(<span class="string">'?'</span>,<span class="number">-99999</span>,inplace=<span class="keyword">True</span>) </div><div class="line">df.drop([<span class="string">'Id'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'Class'</span>], <span class="number">1</span>)) </div><div class="line">y = np.array(df[<span class="string">'Class'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line"></div><div class="line">clf = neighbors.KNeighborsClassifier()</div><div class="line">clf.fit(X_train, y_train)</div><div class="line"></div><div class="line">accuracy = clf.score(X_test, y_test) </div><div class="line">print(accuracy)</div><div class="line"></div><div class="line">example_maasurse = np.array([[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>]])</div><div class="line">example_maasurse = example_maasurse.reshape(len(example_maasurse),<span class="number">-1</span>)</div><div class="line"></div><div class="line">prediction = clf.predict(example_maasurse)</div><div class="line">print(prediction)</div></pre></td></tr></table></figure><h2 id="用手动实现的KNN训练此数据集"><a href="#用手动实现的KNN训练此数据集" class="headerlink" title="用手动实现的KNN训练此数据集"></a>用手动实现的KNN训练此数据集</h2><p>代入以上的实际数据，转换数据类型打乱整体(俗称“洗牌”)的数据集并且分割对应标签制作成可代入上面写的算法中的数据集形式，然后根据计算出的距离结合<code>K</code>的取值得出最终的测试数据集的整体预测标签(计算在训练数据集与测试数据集之间进行)，然后将预测得出的标签与实际的结果进行比较，最终即可得出整体的算法准确性(Accuracy)。</p><p>下面是实现的整体代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> warnings</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_nearest_neighbors</span><span class="params">(data, predict_feature, k=<span class="number">3</span>)</span>:</span> <span class="comment">#特别说明：k值在sklearn中的模型默认为5</span></div><div class="line">    <span class="keyword">if</span> len(data) &gt;= k:</div><div class="line">        warnings.warn(<span class="string">'你这样就没有意义了...笨猪！'</span>)</div><div class="line">    distances = []</div><div class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> data:</div><div class="line">        <span class="keyword">for</span> features <span class="keyword">in</span> data[group]: <span class="comment">#这两段代码与for group, features in dateset.items():意义一致</span></div><div class="line">            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict_feature)) <span class="comment">#使用numpy的相关的模块会显得更加的快速以及更加的高级</span></div><div class="line">            distances.append([euclidean_distance, group])</div><div class="line">            </div><div class="line">    votes = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> sorted(distances)[:k]] <span class="comment">#从小到大的排序，选择出现在前面的K个样本作为投票得出的结果</span></div><div class="line">    vote_result = Counter(votes).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</div><div class="line">    confidence = Counter(votes).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">1</span>] / k <span class="comment">#在预测的样本中正确预测的比例，但是数据量小，一般不靠谱，所以不采用，当然可写入代码中以便学习</span></div><div class="line"></div><div class="line"></div><div class="line">    <span class="keyword">return</span> vote_result, confidence</div><div class="line"></div><div class="line">df = pd.read_csv(<span class="string">'breast-cancer-wisconsin.data'</span>)</div><div class="line">df.replace(<span class="string">'?'</span>, <span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">df.drop([<span class="string">'Id'</span>], <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">full_data = df.astype(float).values.tolist() <span class="comment">#转化为float、列表类型以便下面的随机打乱</span></div><div class="line"></div><div class="line">random.shuffle(full_data) <span class="comment">#随机打乱所有数据,洗牌函数</span></div><div class="line">test_size = <span class="number">0.2</span></div><div class="line">train_set = &#123;<span class="number">2</span>:[], <span class="number">4</span>:[]&#125;</div><div class="line">test_set = &#123;<span class="number">2</span>:[], <span class="number">4</span>:[]&#125;</div><div class="line"><span class="comment">#取训练数据集比例0.8:0.2</span></div><div class="line">train_data = full_data[:-int(test_size*len(full_data))]</div><div class="line">test_data = full_data[-int(test_size*len(full_data)):]</div><div class="line"></div><div class="line"><span class="comment">#数据分割对应</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> train_data:</div><div class="line">    train_set[i[<span class="number">-1</span>]].append(i[:<span class="number">-1</span>]) <span class="comment">#模版套入对应数据即可</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> test_data:</div><div class="line">    test_set[i[<span class="number">-1</span>]].append(i[:<span class="number">-1</span>])</div><div class="line">    </div><div class="line">correct = <span class="number">0</span></div><div class="line">total = <span class="number">0</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> group <span class="keyword">in</span> test_set:</div><div class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_set[group]: <span class="comment">#亦可理解为for group, data in test_set.items():</span></div><div class="line">        vote, confidence = k_nearest_neighbors(train_set, data, k=<span class="number">5</span>) </div><div class="line">        <span class="keyword">if</span> group == vote:</div><div class="line">            correct += <span class="number">1</span> <span class="comment">#若是准确预测了则加1</span></div><div class="line">        total += <span class="number">1</span></div><div class="line">print(<span class="string">'Accuracy:'</span>, correct/total)</div></pre></td></tr></table></figure><blockquote><p>铺助理解：<a href="http://www.runoob.com/python3/python3-func-number-shuffle.html" target="_blank" rel="external">Python3 shuffle() 函数</a></p></blockquote><p>运行可得预测准确性：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-22%20%E4%B8%8B%E5%8D%886.51.22.png" alt=""></p><p>其中有必要说明一下：<code>Accuracy</code>与<code>confidence</code>的关系，就相当于<code>查准率(Precision)</code>(<strong>预测正确的样本数与总体使用样本数的比例</strong>)和<code>查全率(Recall)</code>(<strong>预测正确样本数与全部使用数据数量的比例</strong>)的关系。另外补充一点关于平常常用的<code>score</code>参数的计算公式：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-22%20%E4%B8%8B%E5%8D%887.27.46.png" alt=""></p><blockquote><p>这些知识都是基础知识，可在网友整理的吴恩达老师的<a href="http://www.ai-start.com/ml2014/html/week6.html#header-n168" target="_blank" rel="external">机器学习笔记</a>中找到，也可完整的学习相关的知识，吴恩达老师的必看啊。</p></blockquote><h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>以上的算法没有完全的实现，仅仅是实现基础的构想，还需要改进的地方有很多，比如数据量大了一点之后，需要用到的多线程等。</p><p>另外，KNN算法的优缺点值得去了解，上面我也说过一点，比如数据量大了之后它的效率会受到影响，但是它对于异常值处理的都很好，基本上不受异常值之类的影响等，自行翻书了解去吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/r_D5TTV9-2c&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;还是老样子，这篇文章不适合纯粹的小白，仅仅注重实践，基础知识说的比较浅，基本上一笔带过。&lt;/p&gt;
&lt;p&gt;我在作者的原代码和数据上进行了一点修改以符合当今的实际情况。&lt;/p&gt;
&lt;p&gt;此篇文章将实现K近邻算法的基本原理，以及实现K邻近算法并且应用到实际数据集之中，之后会有一个实战项目。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：线性回归算法的实现</title>
    <link href="https://liujunjie11.github.io/2018/10/19/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <id>https://liujunjie11.github.io/2018/10/19/python机器学习系列：线性回归算法的实现/</id>
    <published>2018-10-19T03:08:43.000Z</published>
    <updated>2019-01-02T06:50:22.432Z</updated>
    
    <content type="html"><![CDATA[<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/V59bYfIomVk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><p>本来不想写太多关于这方面的基础知识的，但是为了加强理解，我想不妨直接写博文记录也是一个好的选择，也可以顺便帮助需要的人，何乐而不为呢？</p><p>那么开始吧。我在原课程的基础上进行那么一点点修改。</p><blockquote><p>这是我学习的相应的课程地址：<a href="https://pythonprogramming.net/how-to-program-best-fit-line-machine-learning-tutorial/?completed=/how-to-program-best-fit-line-slope-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/how-to-program-best-fit-line-machine-learning-tutorial/?completed=/how-to-program-best-fit-line-slope-machine-learning-tutorial/</a></p></blockquote><p>这不是一个小白教程，需要自行取了解一些基础知识，基础知识我仅仅是一笔带过。</p><a id="more"></a><h1 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h1><p>众所周知，线性回归算法是以一条直线来将一些散点进行分类的算法，而这条直线通常可理解为<code>y(x)=mx+b</code>/<code>y=mx+b</code>这样的函数(这是最简单的线性回归算法实例)，其中<code>m</code>为直线的斜率，而<code>y</code>为直线的截距，而<code>x</code>为直线的自变量。</p><p>如下图，我们要将图1的散点，通过图2一条直线进行适当良好的分类开来：</p><ul><li>图1</li></ul><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/linear-regression-tutorial.png" alt=""></p><ul><li>图2</li></ul><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/linear-regression-python-tutorial.png" alt=""></p><h2 id="求解m"><a href="#求解m" class="headerlink" title="求解m:"></a>求解<code>m</code>:</h2><p>如图：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/best-fit-slope.png" alt=""></p><h2 id="求解b"><a href="#求解b" class="headerlink" title="求解b:"></a>求解<code>b</code>:</h2><p>如图：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/best-fit-y-intercept.png" alt=""></p><p>实际上这与所谓的<code>感知机</code>是一样的原理(相关的知识可见李航老师的书籍《统计需诶下方法》)。再者，经过python实现编写对应的公式再进行可视化验证即可完成任务了。</p><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><p>因为仅仅是为了说明算法的实现，所以数值就随便取的来用了。</p><h3 id="数值取值："><a href="#数值取值：" class="headerlink" title="数值取值："></a>数值取值：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line">xs = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],dtype=np.float64)</div><div class="line">ys = np.array([<span class="number">5</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],dtype=np.float64)</div></pre></td></tr></table></figure><h3 id="代码实现公式原理"><a href="#代码实现公式原理" class="headerlink" title="代码实现公式原理"></a>代码实现公式原理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_fit_slope_and_intercept</span><span class="params">(xs,ys)</span>:</span></div><div class="line">    </div><div class="line">    <span class="comment">#实现m参数，两种实现方法</span></div><div class="line"><span class="comment">#m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)*mean(xs) - mean(xs*xs))</span></div><div class="line">    m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)**<span class="number">2</span> - mean(xs**<span class="number">2</span>))</div><div class="line">    <span class="comment">#实现b参数</span></div><div class="line">    b = mean(ys)-m*mean(xs)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> m,b</div></pre></td></tr></table></figure><h3 id="画图预测展示"><a href="#画图预测展示" class="headerlink" title="画图预测展示"></a>画图预测展示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">m,b = best_fit_slope_and_intercept(xs,ys)</div><div class="line"></div><div class="line">regression_line = [(m*x)+b <span class="keyword">for</span> x <span class="keyword">in</span> xs] <span class="comment">#y(x)的实现</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#趋势直线点向</span></div><div class="line">predict_x = <span class="number">9</span></div><div class="line">predict_y = (m*predict_x)+b</div><div class="line"></div><div class="line"><span class="comment">#散点图</span></div><div class="line">plt.scatter(xs,ys)</div><div class="line">plt.scatter(predict_x,predict_y)</div><div class="line">plt.plot(xs,regression_line) <span class="comment">#直线描绘</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>如图：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/Figure_1.png" alt=""></p><p>这样就完成任务了。</p><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">xs = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],dtype=np.float64)</div><div class="line">ys = np.array([<span class="number">5</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],dtype=np.float64)</div><div class="line"><span class="comment"># print(xs,ys)</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_fit_slope_and_intercept</span><span class="params">(xs,ys)</span>:</span></div><div class="line">    </div><div class="line"></div><div class="line"><span class="comment">#m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)*mean(xs) - mean(xs*xs))</span></div><div class="line">    m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)**<span class="number">2</span> - mean(xs**<span class="number">2</span>))</div><div class="line">    b = mean(ys)-m*mean(xs)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> m,b</div><div class="line"></div><div class="line">m,b = best_fit_slope_and_intercept(xs,ys)</div><div class="line"></div><div class="line">regression_line = [(m*x)+b <span class="keyword">for</span> x <span class="keyword">in</span> xs] <span class="comment">#y(x)的实现</span></div><div class="line"></div><div class="line">predict_x = <span class="number">9</span></div><div class="line">predict_y = (m*predict_x)+b</div><div class="line"></div><div class="line"></div><div class="line">plt.scatter(xs,ys)</div><div class="line">plt.scatter(predict_x,predict_y)</div><div class="line">plt.plot(xs,regression_line) <span class="comment">#直线描绘</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure><h2 id="铺助理解链接"><a href="#铺助理解链接" class="headerlink" title="铺助理解链接"></a>铺助理解链接</h2><ul><li><p><a href="http://www.runoob.com/python/python-operators.html" target="_blank" rel="external">Python 运算符</a></p></li><li><p><a href="https://pythoncaff.com/docs/pymotw/statistics-statistical-calculations/106" target="_blank" rel="external">statistics — 统计学计算</a></p></li></ul><h1 id="补充R平方理论以及检验假设"><a href="#补充R平方理论以及检验假设" class="headerlink" title="补充R平方理论以及检验假设"></a>补充R平方理论以及检验假设</h1><p>强烈建议查看书籍学习了解相关的统计知识：</p><blockquote><p>商务与经济统计：<a href="https://pan.baidu.com/s/1O9G7l4QbeqOPsPs_90lFGA" target="_blank" rel="external">https://pan.baidu.com/s/1O9G7l4QbeqOPsPs_90lFGA</a></p></blockquote><p>这是一本好书。</p><h2 id="关于R平方理论"><a href="#关于R平方理论" class="headerlink" title="关于R平方理论"></a>关于R平方理论</h2><p>又称<em>决定系数/判定系数</em>。这是检验一个线性回归中<code>y</code>变量的变差与<code>x</code>变量的变差比例的系数，比例越大说明这个线性方程的拟合效果越好(可简单的理解为，它就是衡量一个线性回归算法的拟合精确度的)。它与相关系数也是有关系的。</p><blockquote><p><a href="https://wenku.baidu.com/view/2cad65f24afe04a1b171de05.html" target="_blank" rel="external">可查看百度文库的解释</a></p></blockquote><p>就不再多说了，这篇文章不是给小白看的教程，只注重实践部分。</p><h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><p>图一：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/coefficient-of-determination-r-squared.png" alt=""></p><p>这个公式还可变换为：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/v2-254f5004fb3ceaf68a6366ec593c1a63_hd.jpg" alt=""></p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/v2-dd32ad2965e1bdeeefa3431c96c89357_hd.jpg" alt=""></p><p>其中<code>r^2 = SSR/SST = 1 - SSE/SST</code>亦成立，所以这里的<code>r^2 = SSR/SST = 1 - SSE/SST</code>公式即对应着图一的公式，这样就好理解下面写的代码了。</p><p>目的是检验上方的<code>ys</code>取值(即测试数据点的坐标y轴线的取值点)与训练得出的<code>y(x)</code>(即上方程序中的<code>regression_line</code>)的拟合效果如何(会有一个量化值出现)。</p><blockquote><p>可参考：</p><p><a href="https://zhuanlan.zhihu.com/p/32335608" target="_blank" rel="external">线性回归中的相关度和决定系数</a></p><p><a href="https://ww2.mathworks.cn/help/stats/coefficient-of-determination-r-squared.html" target="_blank" rel="external">Coefficient of Determination (R-Squared)</a></p></blockquote><h3 id="代码实现演示"><a href="#代码实现演示" class="headerlink" title="代码实现演示"></a>代码实现演示</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#平方误差函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_error</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    <span class="keyword">return</span> sum((ys_line-ys_orig)**<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">coefficient_of_determination</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    y_mean_line = [mean(ys_orig) <span class="keyword">for</span> y <span class="keyword">in</span> ys_orig]</div><div class="line">    squared_error_regr = squared_error(ys_orig, ys_line) <span class="comment">#SSE</span></div><div class="line">    squared_error_y_mean = squared_error(y_mean_line, ys_orig) <span class="comment">#SST</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1</span> - (squared_error_regr / squared_error_y_mean)</div><div class="line">    print(y_mean_line)</div><div class="line"></div><div class="line">r_squared = coefficient_of_determination(ys, regression_line)</div><div class="line">print(r_squared)</div></pre></td></tr></table></figure><p>代入以上完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">xs = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],dtype=np.float64)</div><div class="line">ys = np.array([<span class="number">5</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],dtype=np.float64)</div><div class="line"><span class="comment"># print(xs,ys)</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_fit_slope_and_intercept</span><span class="params">(xs,ys)</span>:</span></div><div class="line">    </div><div class="line"></div><div class="line"><span class="comment">#m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)*mean(xs) - mean(xs*xs))</span></div><div class="line">    m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)**<span class="number">2</span> - mean(xs**<span class="number">2</span>))</div><div class="line">    b = mean(ys)-m*mean(xs)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> m,b</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_error</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    <span class="keyword">return</span> sum((ys_line-ys_orig)**<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">coefficient_of_determination</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    y_mean_line = [mean(ys_orig) <span class="keyword">for</span> y <span class="keyword">in</span> ys_orig]</div><div class="line">    squared_error_regr = squared_error(ys_orig, ys_line) <span class="comment">#SSE</span></div><div class="line">    squared_error_y_mean = squared_error(y_mean_line, ys_orig) <span class="comment">#SST</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1</span> - (squared_error_regr / squared_error_y_mean)</div><div class="line">    print(y_mean_line)</div><div class="line"></div><div class="line">m,b = best_fit_slope_and_intercept(xs,ys)</div><div class="line"></div><div class="line">regression_line = [(m*x)+b <span class="keyword">for</span> x <span class="keyword">in</span> xs] <span class="comment">#y(x)的实现</span></div><div class="line"></div><div class="line">r_squared = coefficient_of_determination(ys, regression_line)</div><div class="line">print(r_squared)</div><div class="line"></div><div class="line"><span class="comment">#predict_x = 9</span></div><div class="line"><span class="comment">#predict_y = (m*predict_x)+b</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#plt.scatter(xs,ys)</span></div><div class="line"><span class="comment">#plt.scatter(predict_x,predict_y)</span></div><div class="line"><span class="comment">#plt.plot(xs,regression_line) #直线描绘</span></div><div class="line"><span class="comment">#plt.show()</span></div></pre></td></tr></table></figure><blockquote><p>将会输出一个<code>R</code>的平方值，用以衡量拟合效果如何。</p></blockquote><h2 id="关于检验假设"><a href="#关于检验假设" class="headerlink" title="关于检验假设"></a>关于检验假设</h2><p>关于检验假设，这是一个可检验数据是否符合相关算法的一个验证，也可理解为先假设，然后去验证对不对(验证假设对不对)。这可与关于R平方理论(输出效果量化值)结合，从而可得出算法对于多类不同数据的拟合效果如何。</p><p>在此之后将通过伪随机生成器(可理解只要是计算机生成的随机数都是伪随机数)来进行一段实例演示。</p><blockquote><p><a href="https://blog.csdn.net/czc1997/article/details/78167705" target="_blank" rel="external">随机数：真随机数和伪随机数</a></p></blockquote><h3 id="代码实现演示-1"><a href="#代码实现演示-1" class="headerlink" title="代码实现演示"></a>代码实现演示</h3><p>这里既是一个简单的随机数据生成器，与相关性、方差有关，为其中的参数选择。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> random</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#数据量的多少，方差，平均每个点步骤(与相关性的取值有关)，相关性设定,默认无相关性</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">(hm, variance, step=<span class="number">2</span>, correlation=False)</span>:</span></div><div class="line">    val = <span class="number">1</span> <span class="comment">#初始值</span></div><div class="line">    ys = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(hm):</div><div class="line">        y = val + random.randrange(-variance,variance)</div><div class="line">        ys.append(y)</div><div class="line">        <span class="comment">#若为正相关</span></div><div class="line">        <span class="keyword">if</span> correlation <span class="keyword">and</span> correlation == <span class="string">'pos'</span>:</div><div class="line">            val += step</div><div class="line">        <span class="keyword">elif</span> correlation <span class="keyword">and</span> correlation ==<span class="string">'neg'</span>:</div><div class="line">            val -= step</div><div class="line">    xs = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(len(ys))] <span class="comment">#xs为平常的顺序取值数</span></div><div class="line">    </div><div class="line">    <span class="keyword">return</span> np.array(xs, dtype=np.float64), np.array(ys, dtype=np.float64)</div><div class="line"></div><div class="line">xs, ys = create_dataset(<span class="number">40</span>, <span class="number">40</span>, <span class="number">2</span>, correlation=<span class="string">'pos'</span>)</div></pre></td></tr></table></figure><h2 id="完整代码-1"><a href="#完整代码-1" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> random</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="comment"># xs = np.array([1,2,3,4,5,6],dtype=np.float64)</span></div><div class="line"><span class="comment"># ys = np.array([5,4,6,5,6,7],dtype=np.float64)</span></div><div class="line"></div><div class="line"><span class="comment">#数据量的多少，方差，平均每个点步骤(与相关性的取值有关)，相关性设定,默认无相关性</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">(hm, variance, step=<span class="number">2</span>, correlation=False)</span>:</span></div><div class="line">    val = <span class="number">1</span> <span class="comment">#初始值</span></div><div class="line">    ys = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(hm):</div><div class="line">        y = val + random.randrange(-variance,variance)</div><div class="line">        ys.append(y)</div><div class="line">        <span class="comment">#若为正相关</span></div><div class="line">        <span class="keyword">if</span> correlation <span class="keyword">and</span> correlation == <span class="string">'pos'</span>:</div><div class="line">            val += step</div><div class="line">        <span class="keyword">elif</span> correlation <span class="keyword">and</span> correlation ==<span class="string">'neg'</span>:</div><div class="line">            val -= step</div><div class="line">    xs = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(len(ys))] <span class="comment">#xs为平常的顺序取值数</span></div><div class="line">    </div><div class="line">    <span class="keyword">return</span> np.array(xs, dtype=np.float64), np.array(ys, dtype=np.float64)</div><div class="line">            </div><div class="line">    </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">best_fit_slope_and_intercept</span><span class="params">(xs,ys)</span>:</span></div><div class="line">    </div><div class="line">    <span class="comment">#实现m参数</span></div><div class="line">    <span class="comment">#m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)*mean(xs) - mean(xs*xs))</span></div><div class="line">    m = (mean(xs)*mean(ys) - mean(xs*ys)) / (mean(xs)**<span class="number">2</span> - mean(xs**<span class="number">2</span>))</div><div class="line">    <span class="comment">#实现b参数</span></div><div class="line">    b = mean(ys)-m*mean(xs)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> m,b</div><div class="line"></div><div class="line"><span class="comment">#平方误差函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">squared_error</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    <span class="keyword">return</span> sum((ys_line-ys_orig)**<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">coefficient_of_determination</span><span class="params">(ys_orig, ys_line)</span>:</span></div><div class="line">    y_mean_line = [mean(ys_orig) <span class="keyword">for</span> y <span class="keyword">in</span> ys_orig]</div><div class="line">    squared_error_regr = squared_error(ys_orig, ys_line) <span class="comment">#SSE</span></div><div class="line">    squared_error_y_mean = squared_error(y_mean_line, ys_orig) <span class="comment">#SST</span></div><div class="line">    <span class="keyword">return</span> <span class="number">1</span> - (squared_error_regr / squared_error_y_mean)</div><div class="line">    print(y_mean_line)</div><div class="line"></div><div class="line">xs, ys = create_dataset(<span class="number">40</span>, <span class="number">40</span>, <span class="number">2</span>, correlation=<span class="string">'pos'</span>)</div><div class="line">    </div><div class="line">m,b = best_fit_slope_and_intercept(xs,ys)</div><div class="line"></div><div class="line">regression_line = [(m*x)+b <span class="keyword">for</span> x <span class="keyword">in</span> xs] <span class="comment">#y(x)的实现</span></div><div class="line"></div><div class="line">r_squared = coefficient_of_determination(ys, regression_line)</div><div class="line">print(r_squared)</div><div class="line"></div><div class="line"><span class="comment">#趋势点向</span></div><div class="line">predict_x = <span class="number">9</span></div><div class="line">predict_y = (m*predict_x)+b</div><div class="line"></div><div class="line"><span class="comment">#散点图</span></div><div class="line">plt.scatter(xs,ys)</div><div class="line">plt.scatter(predict_x,predict_y)</div><div class="line">plt.plot(xs,regression_line) <span class="comment">#直线描绘</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure><blockquote><p><a href="http://www.runoob.com/python/func-number-randrange.html" target="_blank" rel="external">Python randrange() 函数</a></p></blockquote><h2 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h2><p>会输出一个<code>R</code>平方值和一张由于随机数据为基础的训练图表。</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-20%20%E4%B8%8B%E5%8D%8810.03.18.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/V59bYfIomVk&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;本来不想写太多关于这方面的基础知识的，但是为了加强理解，我想不妨直接写博文记录也是一个好的选择，也可以顺便帮助需要的人，何乐而不为呢？&lt;/p&gt;
&lt;p&gt;那么开始吧。我在原课程的基础上进行那么一点点修改。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这是我学习的相应的课程地址：&lt;a href=&quot;https://pythonprogramming.net/how-to-program-best-fit-line-machine-learning-tutorial/?completed=/how-to-program-best-fit-line-slope-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://pythonprogramming.net/how-to-program-best-fit-line-machine-learning-tutorial/?completed=/how-to-program-best-fit-line-slope-machine-learning-tutorial/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这不是一个小白教程，需要自行取了解一些基础知识，基础知识我仅仅是一笔带过。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>python机器学习系列：预测房价并且可视化</title>
    <link href="https://liujunjie11.github.io/2018/10/18/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%9A%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7%E5%B9%B6%E4%B8%94%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    <id>https://liujunjie11.github.io/2018/10/18/python机器学习系列：预测房价并且可视化/</id>
    <published>2018-10-18T10:38:51.000Z</published>
    <updated>2019-01-02T06:50:32.118Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章不是给纯粹的小白看的，需要一定的基础，需要小白补充一定的基础知识，在我的博客有<a href="http://liujunworld.com/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/" target="_blank" rel="external">相关的资源</a>介绍。</p><p>在这里记录下这篇文章时因为很实用，并且也希望以此帮助需要的人。</p><p>这是我在<em>YouTube</em>上学习到的。</p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/QLVMqwpOLPk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe><ul><li>中文地址(不全)：<a href="https://www.yxgapp.com/channel/349.html" target="_blank" rel="external">https://www.yxgapp.com/channel/349.html</a></li></ul><blockquote><p>对应的网页课程地址在此：<a href="https://pythonprogramming.net/forecasting-predicting-machine-learning-tutorial/" target="_blank" rel="external">https://pythonprogramming.net/forecasting-predicting-machine-learning-tutorial/</a></p></blockquote><p>在作者的基础上进行了一点点的改动。说明一下：<strong>相关的库自行安装，就不一一废话了。</strong></p><a id="more"></a><h1 id="项目开始"><a href="#项目开始" class="headerlink" title="项目开始"></a>项目开始</h1><p><strong>项目过程：从开放的数据接口拿到数据，并且做简单的数据处理，自行做好数据标签用于算法训练，之后在利用相关的模块做好预测得到的数值与相应的时间值的对接，得出数据的图表(包括预测部分)，项目完成。</strong></p><h2 id="获取数据以及简单数据处理"><a href="#获取数据以及简单数据处理" class="headerlink" title="获取数据以及简单数据处理"></a>获取数据以及简单数据处理</h2><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> quandl,math</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"></div><div class="line"><span class="comment">#获取公共数据接口</span></div><div class="line">df = quandl.get(<span class="string">"WIKI/GOOGL"</span>)</div><div class="line"></div><div class="line"><span class="comment">#简单的数据特征处理、整理，目的是得出“标签”特征列（因为仅仅是做到实践的效果，所以就不多说了，看代码便知）。</span></div><div class="line">df = df[[<span class="string">'Adj. Open'</span>, <span class="string">'Adj. High'</span>, <span class="string">'Adj. Low'</span>, <span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>]]  <span class="comment">#取用时需要用大括号</span></div><div class="line">df[<span class="string">'HL_PCT'</span>] = (df[<span class="string">'Adj. High'</span>] - df[<span class="string">'Adj. Close'</span>]) / df[<span class="string">'Adj. Close'</span>] * <span class="number">100.0</span></div><div class="line">df[<span class="string">'PCT_change'</span>] = (df[<span class="string">'Adj. Close'</span>] - df[<span class="string">'Adj. Open'</span>]) /df[<span class="string">'Adj. Open'</span>] * <span class="number">100.0</span></div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>,<span class="string">'HL_PCT'</span>,<span class="string">'PCT_change'</span>]]</div><div class="line"></div><div class="line">forecast_col = <span class="string">'Adj. Close'</span></div><div class="line">df.fillna(value=<span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">forecast_out = int(math.ceil(<span class="number">0.01</span> * len(df)))</div><div class="line"><span class="comment">#得出标签特征列，以便直接用于训练</span></div><div class="line">df[<span class="string">'label'</span>] = df[forecast_col].shift(-forecast_out)</div></pre></td></tr></table></figure><blockquote><p>关于<a href="https://www.quandl.com" target="_blank" rel="external">quandl</a>,是个公开的数据网站，有免费的，也有收费的，它有很好的支持python的数据接口。可用<code>pip install quandl</code>下载相关的支持模块。<strong>如果有时获取数据出错了，重新运行直到没错误出现为止。</strong></p></blockquote><h2 id="算法预测"><a href="#算法预测" class="headerlink" title="算法预测"></a>算法预测</h2><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">X = np.array(df.drop([<span class="string">'label'</span>], <span class="number">1</span>))</div><div class="line">X = preprocessing.scale(X)</div><div class="line"></div><div class="line"><span class="comment">#这里是取数据的后面一小部分用于预测得出的数值使用</span></div><div class="line">X_lately = X[-forecast_out:]</div><div class="line">X = X[:-forecast_out]</div><div class="line"></div><div class="line">df.dropna(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">y = np.array(df[<span class="string">'label'</span>])</div><div class="line"></div><div class="line"><span class="comment">#数据分割</span></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line">clf = LinearRegression(n_jobs=<span class="number">-1</span>)</div><div class="line">clf.fit(X_train, y_train)</div><div class="line"><span class="comment">#预测准确性</span></div><div class="line">confidence = clf.score(X_test, y_test)</div><div class="line"></div><div class="line"><span class="comment">#最后预测的数值部分</span></div><div class="line">forecast_set = clf.predict(X_lately)</div></pre></td></tr></table></figure><blockquote><p>这里是简单的预测部分了，其中有一些简单的数据处理部分。</p></blockquote><h2 id="时间与预测值的对应以及图表的描绘"><a href="#时间与预测值的对应以及图表的描绘" class="headerlink" title="时间与预测值的对应以及图表的描绘"></a>时间与预测值的对应以及图表的描绘</h2><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> datetime</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"><span class="comment">#matplotlib的美化图表风格</span></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line"><span class="comment">#预测标签</span></div><div class="line">df[<span class="string">'Forecast'</span>] = np.nan</div><div class="line"></div><div class="line"><span class="comment">#获取源数据最后一天日期</span></div><div class="line">last_date = df.iloc[<span class="number">-1</span>].name</div><div class="line">last_unix = last_date.timestamp()</div><div class="line">one_day = <span class="number">86400</span> <span class="comment">#一天的时间戳</span></div><div class="line">next_unix = last_unix + one_day</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    <span class="comment">#将此日期对应的前面五列不相干的均设为nan，而仅仅加上预测的数值，即仅仅有相应的时间对应相应的预测数值</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i] <span class="comment">#如果这里不理解的话，可以查看df的head和tail部分试试，就能一目了然了</span></div><div class="line"></div><div class="line"><span class="comment">#图表描绘</span></div><div class="line">df[<span class="string">'Adj. Close'</span>].plot()</div><div class="line">df[<span class="string">'Forecast'</span>].plot()</div><div class="line">plt.legend(loc=<span class="number">4</span>)</div><div class="line">plt.xlabel(<span class="string">'Date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Price'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><blockquote><p>这里有些难理解，但是其实很好理解，只是一些代码根本没见到过，所以导致阅读障碍。</p></blockquote><p>估计有人不理解这段<code>df.loc[next_date] = [np.nan for _ in range(len(df.columns)-1)]+[i]</code>代码，我来简单说明一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i]</div><div class="line"></div><div class="line">print(df.head())   </div><div class="line"></div><div class="line">输出：</div><div class="line"></div><div class="line">         Adj. Close  Adj. Volume   HL_PCT  PCT_change   label      Forecast</div><div class="line">Date                                                                          </div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-19</span>   <span class="number">50.322842</span>   <span class="number">44659000.0</span>  <span class="number">3.712563</span>    <span class="number">0.324968</span>  <span class="number">69.078238</span>       NaN</div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-20</span>   <span class="number">54.322689</span>   <span class="number">22834300.0</span>  <span class="number">0.710922</span>    <span class="number">7.227007</span>  <span class="number">67.839414</span>       NaN</div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-23</span>   <span class="number">54.869377</span>   <span class="number">18256100.0</span>  <span class="number">3.729433</span>   <span class="number">-1.227880</span>  <span class="number">68.912727</span>       NaN</div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-24</span>   <span class="number">52.597363</span>   <span class="number">15247300.0</span>  <span class="number">6.417469</span>   <span class="number">-5.726357</span>  <span class="number">70.668146</span>       NaN</div><div class="line"><span class="number">2004</span><span class="number">-08</span><span class="number">-25</span>   <span class="number">53.164113</span>    <span class="number">9188600.0</span>  <span class="number">1.886792</span>    <span class="number">1.183658</span>  <span class="number">71.219849</span>       NaN </div><div class="line"></div><div class="line"></div><div class="line">print(df.tail())</div><div class="line"></div><div class="line">输出：</div><div class="line"></div><div class="line">                     Adj. Close  Adj. Volume  HL_PCT  PCT_change  label  \</div><div class="line">Date                                                                      </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-08</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-09</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-10</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-11</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>         NaN          NaN     NaN         NaN    NaN   </div><div class="line"></div><div class="line">                        Forecast  </div><div class="line">Date                              </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-08</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1113.922012</span>  </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-09</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1071.104993</span>  </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-10</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1043.810593</span>  </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-11</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1073.778780</span>  </div><div class="line"><span class="number">2018</span><span class="number">-03</span><span class="number">-12</span> <span class="number">08</span>:<span class="number">00</span>:<span class="number">00</span>  <span class="number">1022.639186</span></div></pre></td></tr></table></figure><blockquote><p>就是这样，已经很明了了，就是仅仅为了让预测的时间对应预测的房价数值而已。</p></blockquote><h3 id="什么是时间戳"><a href="#什么是时间戳" class="headerlink" title="什么是时间戳?"></a>什么是时间戳?</h3><p>简单说说：时间戳是自1970年1月1日（00:00:00 UTC/GMT）以来的秒数。它也被称为Unix时间戳（Unix Timestam、Unix epoch、POSIX time、Unix timestamp）是从1970年1月1日（UTC/GMT的午夜）开始所经过的秒数，不考虑闰秒。</p><p>  UNIX时间戳的0按照ISO 8601规范为：1970-01-01T00:00:00Z</p><p>  一个小时表示为UNIX时间戳格式为：3600秒；一天表示为UNIX时间戳为86400秒，闰秒不计算。</p><blockquote><p>来自：<a href="http://www.htmer.com/article/420.htm" target="_blank" rel="external">http://www.htmer.com/article/420.htm</a></p></blockquote><h2 id="完整代码："><a href="#完整代码：" class="headerlink" title="完整代码："></a>完整代码：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> quandl,math,datetime</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,svm</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">df = quandl.get(<span class="string">"WIKI/GOOGL"</span>)</div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Open'</span>, <span class="string">'Adj. High'</span>, <span class="string">'Adj. Low'</span>, <span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>]] <span class="comment">#取用时需要用大括号</span></div><div class="line">df[<span class="string">'HL_PCT'</span>] = (df[<span class="string">'Adj. High'</span>] - df[<span class="string">'Adj. Close'</span>]) / df[<span class="string">'Adj. Close'</span>] * <span class="number">100.0</span></div><div class="line">df[<span class="string">'PCT_change'</span>] = (df[<span class="string">'Adj. Close'</span>] - df[<span class="string">'Adj. Open'</span>]) /df[<span class="string">'Adj. Open'</span>] * <span class="number">100.0</span></div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>,<span class="string">'HL_PCT'</span>,<span class="string">'PCT_change'</span>]]</div><div class="line"></div><div class="line">forecast_col = <span class="string">'Adj. Close'</span></div><div class="line"></div><div class="line">df.fillna(value=<span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">forecast_out = int(math.ceil(<span class="number">0.01</span> * len(df)))</div><div class="line">df[<span class="string">'label'</span>] = df[forecast_col].shift(-forecast_out)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'label'</span>], <span class="number">1</span>))</div><div class="line">X = preprocessing.scale(X)</div><div class="line">X_lately = X[-forecast_out:]</div><div class="line">X = X[:-forecast_out]</div><div class="line"></div><div class="line">df.dropna(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">y = np.array(df[<span class="string">'label'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line">clf = LinearRegression(n_jobs=<span class="number">-1</span>)</div><div class="line">clf.fit(X_train, y_train)</div><div class="line">confidence = clf.score(X_test, y_test)</div><div class="line"></div><div class="line">forecast_set = clf.predict(X_lately)</div><div class="line">df[<span class="string">'Forecast'</span>] = np.nan</div><div class="line"></div><div class="line">last_date = df.iloc[<span class="number">-1</span>].name</div><div class="line">last_unix = last_date.timestamp()</div><div class="line">one_day = <span class="number">86400</span></div><div class="line">next_unix = last_unix + one_day</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i]</div><div class="line"></div><div class="line">df[<span class="string">'Adj. Close'</span>].plot()</div><div class="line">df[<span class="string">'Forecast'</span>].plot()</div><div class="line">plt.legend(loc=<span class="number">4</span>)</div><div class="line">plt.xlabel(<span class="string">'Date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Price'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><h2 id="最终效果展示"><a href="#最终效果展示" class="headerlink" title="最终效果展示"></a>最终效果展示</h2><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/Oct-18-2018%2020-13-50.gif" alt=""></p><blockquote><p>可以查看到预测的部分展示。</p></blockquote><h2 id="补助链接"><a href="#补助链接" class="headerlink" title="补助链接"></a>补助链接</h2><p>这里是帮助理解的链接。</p><ul><li><p><a href="https://blog.csdn.net/brucewong0516/article/details/80157639" target="_blank" rel="external">python pandas库常用函数之shift详解</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/37891729" target="_blank" rel="external">样式美化matplotlib.pyplot.style.use定制画布风格</a></p></li><li><p><a href="http://www.wklken.me/posts/2015/03/03/python-base-datetime.html#6-huo-qu-ben-zhou-ben-yue-shang-yue-zui-hou-yi-tian" target="_blank" rel="external">PYTHON-基础-时间日期处理小结</a></p></li><li><p><a href="https://morvanzhou.github.io/tutorials/data-manipulation/np-pd/3-2-pd-indexing/" target="_blank" rel="external">Pandas 选择数据</a></p></li><li><p><a href="https://morvanzhou.github.io/tutorials/data-manipulation/plt/2-5-lagend/" target="_blank" rel="external">Legend 图例</a></p></li></ul><p>值得说明一下<em>Legend 图例</em>的一些知识：</p><p>使用<code>plt.legend(loc=n)</code>中<code>n</code>的选择代表什么：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="string">'best'</span> : <span class="number">0</span>,          </div><div class="line"><span class="string">'upper right'</span>  : <span class="number">1</span>,</div><div class="line"><span class="string">'upper left'</span>   : <span class="number">2</span>,</div><div class="line"><span class="string">'lower left'</span>   : <span class="number">3</span>,</div><div class="line"><span class="string">'lower right'</span>  : <span class="number">4</span>,</div><div class="line"><span class="string">'right'</span>        : <span class="number">5</span>,</div><div class="line"><span class="string">'center left'</span>  : <span class="number">6</span>,</div><div class="line"><span class="string">'center right'</span> : <span class="number">7</span>,</div><div class="line"><span class="string">'lower center'</span> : <span class="number">8</span>,</div><div class="line"><span class="string">'upper center'</span> : <span class="number">9</span>,</div><div class="line"><span class="string">'center'</span>       : <span class="number">10</span>。</div></pre></td></tr></table></figure><h1 id="补充添加序列化保存预测模型"><a href="#补充添加序列化保存预测模型" class="headerlink" title="补充添加序列化保存预测模型"></a>补充添加序列化保存预测模型</h1><p>添加了如何将预测代码序列化的过程加相关的代码。</p><p>序列化可简单理解为：先保存了这个预测的模型(序列化的过程)，然后我们可以拿出这个模型直接进行以后的预测(反序列化的过程)。</p><p>加上代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pickle</div><div class="line"></div><div class="line"><span class="keyword">with</span> open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">   <span class="comment">#下载模型</span></div><div class="line">   pickle.dump(clf,f)</div><div class="line"></div><div class="line">pickle_in = open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'rb'</span>)</div><div class="line">clf = pickle.load(pickle_in) <span class="comment">#加载模型</span></div></pre></td></tr></table></figure><p>完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> quandl,math,datetime</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,svm</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> pickle</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">df = quandl.get(<span class="string">"WIKI/GOOGL"</span>)</div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Open'</span>, <span class="string">'Adj. High'</span>, <span class="string">'Adj. Low'</span>, <span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>]] <span class="comment">#取用时需要用大括号</span></div><div class="line">df[<span class="string">'HL_PCT'</span>] = (df[<span class="string">'Adj. High'</span>] - df[<span class="string">'Adj. Close'</span>]) / df[<span class="string">'Adj. Close'</span>] * <span class="number">100.0</span></div><div class="line">df[<span class="string">'PCT_change'</span>] = (df[<span class="string">'Adj. Close'</span>] - df[<span class="string">'Adj. Open'</span>]) /df[<span class="string">'Adj. Open'</span>] * <span class="number">100.0</span></div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>,<span class="string">'HL_PCT'</span>,<span class="string">'PCT_change'</span>]]</div><div class="line"></div><div class="line">forecast_col = <span class="string">'Adj. Close'</span></div><div class="line"></div><div class="line">df.fillna(value=<span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">forecast_out = int(math.ceil(<span class="number">0.01</span> * len(df)))</div><div class="line">df[<span class="string">'label'</span>] = df[forecast_col].shift(-forecast_out)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'label'</span>], <span class="number">1</span>))</div><div class="line">X = preprocessing.scale(X)</div><div class="line">X_lately = X[-forecast_out:]</div><div class="line">X = X[:-forecast_out]</div><div class="line"></div><div class="line">df.dropna(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">y = np.array(df[<span class="string">'label'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line">clf = LinearRegression(n_jobs=<span class="number">-1</span>)</div><div class="line">clf.fit(X_train, y_train)</div><div class="line"></div><div class="line"><span class="keyword">with</span> open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">   <span class="comment">#下载模型</span></div><div class="line">   pickle.dump(clf,f)</div><div class="line"></div><div class="line">pickle_in = open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'rb'</span>)</div><div class="line">clf = pickle.load(pickle_in) <span class="comment">#加载模型</span></div><div class="line"></div><div class="line">confidence = clf.score(X_test, y_test)</div><div class="line"></div><div class="line">forecast_set = clf.predict(X_lately)</div><div class="line">df[<span class="string">'Forecast'</span>] = np.nan</div><div class="line"></div><div class="line">last_date = df.iloc[<span class="number">-1</span>].name</div><div class="line">last_unix = last_date.timestamp()</div><div class="line">one_day = <span class="number">86400</span></div><div class="line">next_unix = last_unix + one_day</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i]</div><div class="line"></div><div class="line">df[<span class="string">'Adj. Close'</span>].plot()</div><div class="line">df[<span class="string">'Forecast'</span>].plot()</div><div class="line">plt.legend(loc=<span class="number">4</span>)</div><div class="line">plt.xlabel(<span class="string">'Date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Price'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><p>在运行一遍以上的代码之后，就可以直接从保存的文件来加载模型来预测数据啦，如下可测试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> quandl,math,datetime</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing,svm</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> pickle</div><div class="line"></div><div class="line">plt.style.use(<span class="string">'ggplot'</span>)</div><div class="line"></div><div class="line">df = quandl.get(<span class="string">"WIKI/GOOGL"</span>)</div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Open'</span>, <span class="string">'Adj. High'</span>, <span class="string">'Adj. Low'</span>, <span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>]] <span class="comment">#取用时需要用大括号</span></div><div class="line">df[<span class="string">'HL_PCT'</span>] = (df[<span class="string">'Adj. High'</span>] - df[<span class="string">'Adj. Close'</span>]) / df[<span class="string">'Adj. Close'</span>] * <span class="number">100.0</span></div><div class="line">df[<span class="string">'PCT_change'</span>] = (df[<span class="string">'Adj. Close'</span>] - df[<span class="string">'Adj. Open'</span>]) /df[<span class="string">'Adj. Open'</span>] * <span class="number">100.0</span></div><div class="line"></div><div class="line">df = df[[<span class="string">'Adj. Close'</span>, <span class="string">'Adj. Volume'</span>,<span class="string">'HL_PCT'</span>,<span class="string">'PCT_change'</span>]]</div><div class="line"></div><div class="line">forecast_col = <span class="string">'Adj. Close'</span></div><div class="line"></div><div class="line">df.fillna(value=<span class="number">-99999</span>, inplace=<span class="keyword">True</span>)</div><div class="line">forecast_out = int(math.ceil(<span class="number">0.01</span> * len(df)))</div><div class="line">df[<span class="string">'label'</span>] = df[forecast_col].shift(-forecast_out)</div><div class="line"></div><div class="line">X = np.array(df.drop([<span class="string">'label'</span>], <span class="number">1</span>))</div><div class="line">X = preprocessing.scale(X)</div><div class="line">X_lately = X[-forecast_out:]</div><div class="line">X = X[:-forecast_out]</div><div class="line"></div><div class="line">df.dropna(inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">y = np.array(df[<span class="string">'label'</span>])</div><div class="line"></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>)</div><div class="line"><span class="comment">#clf = LinearRegression(n_jobs=-1)</span></div><div class="line"><span class="comment">#clf.fit(X_train, y_train)</span></div><div class="line"></div><div class="line"><span class="comment">#with open('houseforecastmodel.pickle','wb') as f:</span></div><div class="line">   <span class="comment">#下载模型</span></div><div class="line">   <span class="comment">#pickle.dump(clf,f)</span></div><div class="line"></div><div class="line">pickle_in = open(<span class="string">'houseforecastmodel.pickle'</span>,<span class="string">'rb'</span>)</div><div class="line">clf = pickle.load(pickle_in) <span class="comment">#加载模型</span></div><div class="line"></div><div class="line">confidence = clf.score(X_test, y_test)</div><div class="line"></div><div class="line">forecast_set = clf.predict(X_lately)</div><div class="line">df[<span class="string">'Forecast'</span>] = np.nan</div><div class="line"></div><div class="line">last_date = df.iloc[<span class="number">-1</span>].name</div><div class="line">last_unix = last_date.timestamp()</div><div class="line">one_day = <span class="number">86400</span></div><div class="line">next_unix = last_unix + one_day</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> forecast_set:</div><div class="line">    next_date = datetime.datetime.fromtimestamp(next_unix)</div><div class="line">    next_unix += <span class="number">86400</span></div><div class="line">    df.loc[next_date] = [np.nan <span class="keyword">for</span> _ <span class="keyword">in</span> range(len(df.columns)<span class="number">-1</span>)]+[i]</div><div class="line"></div><div class="line">df[<span class="string">'Adj. Close'</span>].plot()</div><div class="line">df[<span class="string">'Forecast'</span>].plot()</div><div class="line">plt.legend(loc=<span class="number">4</span>)</div><div class="line">plt.xlabel(<span class="string">'Date'</span>)</div><div class="line">plt.ylabel(<span class="string">'Price'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure><blockquote><p>得出的结果与上方展示的一致。</p></blockquote><h2 id="了解pickle"><a href="#了解pickle" class="headerlink" title="了解pickle"></a>了解pickle</h2><ul><li><p><a href="https://morvanzhou.github.io/tutorials/python-basic/basic/13-08-pickle/" target="_blank" rel="external">pickle 保存数据</a></p></li><li><p><a href="https://docs.python.org/3/library/pickle.html" target="_blank" rel="external">pickle — Python object serialization</a></p></li><li><p><a href="https://www.jianshu.com/p/113f33ab6f31" target="_blank" rel="external">scikit-learn系列之如何存储和导入机器学习模型</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章不是给纯粹的小白看的，需要一定的基础，需要小白补充一定的基础知识，在我的博客有&lt;a href=&quot;http://liujunworld.com/2018/09/16/%E5%88%9D%E5%AD%A6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;相关的资源&lt;/a&gt;介绍。&lt;/p&gt;
&lt;p&gt;在这里记录下这篇文章时因为很实用，并且也希望以此帮助需要的人。&lt;/p&gt;
&lt;p&gt;这是我在&lt;em&gt;YouTube&lt;/em&gt;上学习到的。&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube-nocookie.com/embed/QLVMqwpOLPk&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;ul&gt;
&lt;li&gt;中文地址(不全)：&lt;a href=&quot;https://www.yxgapp.com/channel/349.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://www.yxgapp.com/channel/349.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;对应的网页课程地址在此：&lt;a href=&quot;https://pythonprogramming.net/forecasting-predicting-machine-learning-tutorial/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://pythonprogramming.net/forecasting-predicting-machine-learning-tutorial/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在作者的基础上进行了一点点的改动。说明一下：&lt;strong&gt;相关的库自行安装，就不一一废话了。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/categories/Python/"/>
    
      <category term="数据分析" scheme="https://liujunjie11.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="数据挖掘" scheme="https://liujunjie11.github.io/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Python" scheme="https://liujunjie11.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Mac下安装lightGBM</title>
    <link href="https://liujunjie11.github.io/2018/10/16/Mac%E4%B8%8B%E5%AE%89%E8%A3%85lightGBM/"/>
    <id>https://liujunjie11.github.io/2018/10/16/Mac下安装lightGBM/</id>
    <published>2018-10-16T05:13:23.000Z</published>
    <updated>2019-01-02T06:50:40.234Z</updated>
    
    <content type="html"><![CDATA[<p>最近需要这个算法做点东西，在此记录一下安装的过程。</p><a id="more"></a><h1 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h1><p>用homebrew安装相关的插件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">brew install cmake</div><div class="line">brew install gcc --without-multilib</div></pre></td></tr></table></figure><blockquote><p>在安装之后如果在使用<code>cmake ..</code>命令行出现了关于在下载的<em>cmake</em>的相关的问题时，可以考虑<code>brew uninstall cmake</code>，然后重新下载。这种问题我就遇上了…</p></blockquote><p>下载好gcc之后，我配置了一下环境问题，如图：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8B%E5%8D%881.25.10.png" alt=""></p><blockquote><p>使用命令行<code>vi ~/.bash_profile</code>配置环境变量问题。</p></blockquote><p>接下来是git下载相关的GitHub资源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> --recursive https://github.com/Microsoft/LightGBM</div></pre></td></tr></table></figure><p>依次使用下方命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> LightGBM</div><div class="line"><span class="built_in">export</span> CXX=g++-8 CC=gcc-8</div><div class="line">mkdir build </div><div class="line"><span class="built_in">cd</span> build</div><div class="line">cmake ..</div><div class="line">make -j4</div></pre></td></tr></table></figure><blockquote><p>这样只要相关的插件下载完全了，一般就没什么问题出现了。</p></blockquote><p>之后可以使用pip命令下载了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install --no-binary :all: lightgbm</div></pre></td></tr></table></figure><blockquote><p>由于不是很懂这个命令，我又使用了<code>pip install lightgbm</code>。</p></blockquote><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>如图：</p><p><img src="https://liu-1258031152.cos.ap-beijing.myqcloud.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-16%20%E4%B8%8B%E5%8D%881.23.55.png" alt=""></p><blockquote><p>用的是anaconda默认的python3环境。</p></blockquote><h1 id="遇到的错误问题"><a href="#遇到的错误问题" class="headerlink" title="遇到的错误问题"></a>遇到的错误问题</h1><p>如下类似问题：</p><pre><code>OSError: dlopen(/usr/local/lib/python3.6/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/gcc/lib/gcc/7/libgomp.1.dylib  Referenced from: /usr/local/lib/python3.6/site-packages/lightgbm/lib_lightgbm.so  Reason: image not found</code></pre><blockquote><p>解决方案：<a href="https://github.com/Microsoft/LightGBM/issues/1369" target="_blank" rel="external">https://github.com/Microsoft/LightGBM/issues/1369</a></p></blockquote><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><p><a href="http://lightgbm.apachecn.org/cn/latest/Installation-Guide.html" target="_blank" rel="external">http://lightgbm.apachecn.org/cn/latest/Installation-Guide.html</a></p></li><li><p><a href="https://blog.csdn.net/fitzgerald0/article/details/78321527?utm_source=blogxgwz4" target="_blank" rel="external">https://blog.csdn.net/fitzgerald0/article/details/78321527?utm_source=blogxgwz4</a></p></li><li><p><a href="https://github.com/Microsoft/LightGBM/issues/1369smartjpa.com" target="_blank" rel="external">https://github.com/Microsoft/LightGBM/issues/1369smartjpa.com</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近需要这个算法做点东西，在此记录一下安装的过程。&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://liujunjie11.github.io/categories/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Mac" scheme="https://liujunjie11.github.io/categories/Mac/"/>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="LightGBM" scheme="https://liujunjie11.github.io/categories/LightGBM/"/>
    
    
      <category term="教程笔记" scheme="https://liujunjie11.github.io/tags/%E6%95%99%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
      <category term="机器学习" scheme="https://liujunjie11.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Mac" scheme="https://liujunjie11.github.io/tags/Mac/"/>
    
      <category term="LightGBM" scheme="https://liujunjie11.github.io/tags/LightGBM/"/>
    
  </entry>
  
</feed>
